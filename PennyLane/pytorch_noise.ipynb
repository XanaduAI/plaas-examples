{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "> **Note**\n",
        ">\n",
        "> Saved changes to this file will not presist between instances. To retain your edits,\n",
        "> please save the file to your main directory.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch and noisy devices\n",
        "=========================\n",
        "\n",
        "*Author: PennyLane dev team. Last updated: 16 Jun 2021.*\n",
        "\n",
        "Let's revisit the original [qubit rotation](https://pennylane.ai/qml/demos/tutorial_qubit_rotation.html#qubit-rotation)\n",
        "tutorial, but instead of using the default NumPy/autograd QNode\n",
        "interface, we'll use the [PyTorch interface](https://pennylane.readthedocs.io/en/stable/introduction/interfaces/torch.html). We'll also\n",
        "replace the `default.qubit` device with a noisy `forest.qvm` device, to\n",
        "see how the optimization responds to noisy qubits. At the end of the\n",
        "demonstration, we will also show a way of how Rigetti's QPU can be used\n",
        "via Amazon Braket.\n",
        "\n",
        "To follow along with this tutorial on your own computer, you will\n",
        "require the following dependencies:\n",
        "\n",
        "-   The [Forest SDK](https://rigetti.com/forest), which contains the\n",
        "    quantum virtual machine (QVM) and quilc quantum compiler. Once\n",
        "    installed, the QVM and quilc can be started by running the commands\n",
        "    `quilc -S` and `qvm -S` in separate terminal windows.\n",
        "-   [PennyLane-Forest plugin](https://pennylane-forest.readthedocs.io),\n",
        "    in order to access the QVM as a PennyLane device. This can be\n",
        "    installed via pip:\n",
        "\n",
        "    ``` {.sourceCode .bash}\n",
        "    pip install pennylane-forest\n",
        "    ```\n",
        "\n",
        "-   [PennyLane-Braket\n",
        "    plugin](https://amazon-braket-pennylane-plugin-python.readthedocs.io/en/latest/),\n",
        "    in order to access the Rigetti QPU as a PennyLane device. This can\n",
        "    be installed via pip:\n",
        "\n",
        "    ``` {.sourceCode .bash}\n",
        "    pip install amazon-braket-pennylane-plugin\n",
        "    ```\n",
        "\n",
        "-   [PyTorch](https://pytorch.org/get-started/locally/), in order to\n",
        "    access the PyTorch QNode interface. Follow the link for instructions\n",
        "    on the best way to install PyTorch for your system.\n",
        "\n",
        "Setting up the device\n",
        "---------------------\n",
        "\n",
        "Once the dependencies above are installed, let's begin importing the\n",
        "required packages and setting up our quantum device.\n",
        "\n",
        "To start with, we import PennyLane, and, as we are using the PyTorch\n",
        "interface, PyTorch as well:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pennylane as qml\n",
        "import torch\n",
        "from torch.autograd import Variable"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we do not need to import the wrapped version of NumPy provided\n",
        "by PennyLane, as we are not using the default QNode NumPy interface. If\n",
        "NumPy is needed, it is fine to import vanilla NumPy for use with PyTorch\n",
        "and TensorFlow.\n",
        "\n",
        "Next, we will create our device:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "dev = qml.device(\"forest.qvm\", device=\"2q\", noisy=True)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we create a noisy two-qubit system, simulated via the QVM. If we\n",
        "wish, we could also build the model on a physical device, such as the\n",
        "`Aspen-1` QPU which can be accessed through Amazon Braket (more details\n",
        "on that will follow).\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constructing the QNode\n",
        "======================\n",
        "\n",
        "Now that we have initialized the device, we can construct our quantum\n",
        "node. Like the other tutorials, we use the \\~.pennylane.qnode decorator\n",
        "to convert our quantum function (encoded by the circuit above) into a\n",
        "quantum node running on the QVM.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def circuit(phi, theta):\n",
        "    qml.RX(theta, wires=0)\n",
        "    qml.RZ(phi, wires=0)\n",
        "    return qml.expval(qml.PauliZ(0))"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make the QNode 'PyTorch aware', we need to specify that the QNode\n",
        "interfaces with PyTorch. This is done by passing the `interface='torch'`\n",
        "keyword argument.\n",
        "\n",
        "As a result, this QNode will be set up to accept and return PyTorch\n",
        "tensors, and will also automatically calculate any analytic gradients\n",
        "when PyTorch performs backpropagation.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization\n",
        "============\n",
        "\n",
        "We can now create our optimization cost function. To introduce some\n",
        "additional complexity into the system, rather than simply training the\n",
        "variational circuit to 'flip a qubit' from state $\\left|0\\right\\rangle$\n",
        "to state $\\left|1\\right\\rangle$, let's also modify the target state\n",
        "every 100 steps. For example, for the first 100 steps, the target state\n",
        "will be $\\left|1\\right\\rangle$; this will then change to\n",
        "$\\left|0\\right\\rangle$ for steps 100 and 200, before changing back to\n",
        "state $\\left|1\\right\\rangle$ for steps 200 to 300, and so on.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def cost(phi, theta, step):\n",
        "    target = -(-1) ** (step // 100)\n",
        "    return torch.abs(circuit(phi, theta) - target) ** 2"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the cost function is defined, we can begin the PyTorch\n",
        "optimization. We create two variables, representing the two free\n",
        "parameters of the variational circuit, and initialize an Adam optimizer:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "phi = Variable(torch.tensor(1.0), requires_grad=True)\n",
        "theta = Variable(torch.tensor(0.05), requires_grad=True)\n",
        "opt = torch.optim.Adam([phi, theta], lr=0.1)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we are using the PyTorch interface, we must use PyTorch optimizers,\n",
        "*not* the built-in optimizers provided by PennyLane. The built-in\n",
        "optimizers only apply to the default NumPy/autograd interface.\n",
        "\n",
        "Optimizing the system for 400 steps:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for i in range(400):\n",
        "    opt.zero_grad()\n",
        "    loss = cost(phi, theta, i)\n",
        "    loss.backward()\n",
        "    opt.step()"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now check the final values of the parameters, as well as the\n",
        "final circuit output and cost function:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(phi)\n",
        "print(theta)\n",
        "print(circuit(phi, theta))\n",
        "print(cost(phi, theta, 400))"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the cost function is step-dependent, this does not provide enough\n",
        "detail to determine if the optimization was successful; instead, let's\n",
        "plot the output state of the circuit over time on a Bloch sphere:\n",
        "\n",
        "![](.img/pytorch_noise_bloch.gif)\n",
        "\n",
        "Here, the red x is the target state of the variational circuit, and the\n",
        "arrow is the variational circuit output state. As the target state\n",
        "changes, the circuit learns to produce the new target state!\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybrid GPU-QPU optimization\n",
        "===========================\n",
        "\n",
        "As PyTorch natively supports GPU-accelerated classical processing, and\n",
        "Amazon Braket provides quantum hardware access in the form of QPUs, we\n",
        "can run the above code as a hybrid GPU-QPU optimization with very little\n",
        "modification.\n",
        "\n",
        "Note that to run the following script, you will need access to Rigetti's\n",
        "QPU. To connect to a QPU, we can use Amazon Braket. For a dedicated\n",
        "demonstration on using Amazon Braket, see our tutorial on [Computing\n",
        "gradients in parallel with Amazon\n",
        "Braket](https://pennylane.ai/qml/demos/braket-parallel-gradients.html)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pennylane as qml\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "my_bucket = \"amazon-braket-Your-Bucket-Name\"  # the name of the bucket\n",
        "my_prefix = \"Your-Folder-Name\"  # the name of the folder in the bucket\n",
        "s3_folder = (my_bucket, my_prefix)\n",
        "\n",
        "device_arn = \"arn:aws:braket:::device/qpu/rigetti/Aspen-9\"\n",
        "\n",
        "qpu = qml.device(\n",
        "    \"braket.aws.qubit\",\n",
        "    device_arn=device_arn,\n",
        "    wires=32,\n",
        "    s3_destination_folder=s3_folder,\n",
        ")\n",
        "\n",
        "# Note: swap dev to qpu here to use the QPU\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def circuit(phi, theta):\n",
        "    qml.RX(theta, wires=0)\n",
        "    qml.RZ(phi, wires=0)\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "\n",
        "def cost(phi, theta, step):\n",
        "    target = -(-1) ** (step // 100)\n",
        "    return torch.abs(circuit(phi, theta) - target) ** 2\n",
        "\n",
        "\n",
        "phi = Variable(torch.tensor(1.0, device=\"cuda\"), requires_grad=True)\n",
        "theta = Variable(torch.tensor(0.05, device=\"cuda\"), requires_grad=True)\n",
        "opt = torch.optim.Adam([phi, theta], lr=0.1)\n",
        "\n",
        "for i in range(400):\n",
        "    opt.zero_grad()\n",
        "    loss = cost(phi, theta, i)\n",
        "    loss.backward()\n",
        "    opt.step()"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When using a classical interface that supports GPUs, the QNode will\n",
        "automatically copy any tensor arguments to the CPU, before applying them\n",
        "on the specified quantum device. Once done, it will return a tensor\n",
        "containing the QNode result, and automatically copy it back to the GPU\n",
        "for any further classical processing.\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> For more details on the PyTorch interface, see\n",
        "> [PyTorch interface](https://pennylane.readthedocs.io/en/stable/introduction/interfaces/torch.html).\n"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PennyLane",
      "language": "python",
      "name": "pennylane"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}