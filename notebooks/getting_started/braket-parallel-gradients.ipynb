{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nComputing gradients in parallel with Amazon Braket\n==================================================\n\n.. meta::\n    :property=\"og:description\": Parallelize gradient calculations with Amazon Braket\n    :property=\"og:image\": https://pennylane.ai/qml/_images/pl-braket.png\n\n.. related::\n\n    tutorial_qaoa_intro Learn how to implement QAOA workflows with PennyLane\n    tutorial_vqe_parallel Evaluate the potential energy surface of H2 with parallel QPUs\n\n\n*Author: PennyLane dev team. Posted: 8 Dec 2020.*\n\nPennyLane integrates with `Amazon Braket <https://aws.amazon.com/braket/>`__ to enable quantum\nmachine learning and optimization on high-performance simulators and quantum processing\nunits (QPUs) through a range of `providers <https://aws.amazon.com/braket/hardware-providers/>`__.\n\nIn PennyLane, Amazon Braket is accessed through the\n`PennyLane-Braket <https://amazon-braket-pennylane-plugin-python.readthedocs.io>`__ plugin. The\nplugin can be installed using\n\n.. code-block:: bash\n\n    pip install amazon-braket-pennylane-plugin\n\nA central feature of Amazon Braket is that its remote simulator can execute multiple circuits\nin parallel. This capability can be harnessed in PennyLane during circuit training,\nwhich requires lots of variations of a circuit to be executed. Hence, the PennyLane-Braket plugin\nprovides a method for scalable optimization of large circuits with many parameters. This tutorial\nwill explain the importance of this feature, allow you to benchmark it yourself, and explore its\nuse for solving a scaled-up graph problem with QAOA.\n\n.. figure:: ../_static/remote-multi-job-simulator.png\n    :align: center\n    :scale: 75%\n    :alt: PennyLane can leverage Braket for parallelized gradient calculations\n    :target: javascript:void(0);\n\nWhy is training circuits so expensive?\n--------------------------------------\n\nQuantum-classical hybrid optimization of quantum circuits is the workhorse algorithm of near-term\nquantum computing. It is not only fundamental for training variational quantum circuits, but also\nmore broadly for applications like quantum chemistry and quantum machine learning. Today's most\npowerful optimization algorithms rely on the efficient computation of gradients\u2014which tell us how\nto adapt parameters a little bit at a time to improve the algorithm.\n\nCalculating the gradient involves multiple device executions: for each\ntrainable parameter we must execute our circuit on the device typically\n:doc:`more than once </glossary/parameter_shift>`. Reasonable applications involve many\ntrainable parameters (just think of a classical neural net with millions of tunable weights). The\nresult is a huge number of device executions for each optimization step.\n\n.. figure:: ../_static/grad-circuits.png\n    :align: center\n    :scale: 75%\n    :alt: Calculating the gradient requires multiple circuit executions\n    :target: javascript:void(0);\n\nIn the standard ``default.qubit`` device, gradients are calculated in PennyLane through\nsequential device executions\u2014in other words, all these circuits have to wait in the same queue\nuntil they can be evaluated. This approach is simpler, but quickly becomes slow as we scale the\nnumber of parameters. Moreover, as the number of qubits, or \"width\", of the circuit is scaled,\neach device execution will slow down and eventually become a noticeable bottleneck. In\nshort\u2014**the future of training quantum circuits relies on high-performance remote simulators and\nhardware devices that are highly parallelized**.\n\nFortunately, the PennyLane-Braket plugin provides a solution for scalable quantum circuit training\nby giving access to the Amazon Braket simulator known as\n`SV1 <https://docs.aws.amazon.com/braket/latest/developerguide/braket-devices.html>`__.\nSV1 is a high-performance state vector simulator that is\ndesigned with parallel execution in mind. Together with PennyLane, we can use SV1 to run in\nparallel all the circuits needed to compute a gradient!\n\nAccessing devices on Amazon Braket\n----------------------------------\n\nThe remote simulator and quantum hardware devices available on Amazon Braket can be found\n`here <https://docs.aws.amazon.com/braket/latest/developerguide/braket-devices.html>`__. Each\ndevice has a unique identifier known as an\n`ARN <https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html>`__. In PennyLane,\nall remote Braket devices are accessed through a single PennyLane device named ``braket.aws.qubit``,\nalong with specification of the corresponding ARN.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>To access remote services on Amazon Braket, you must first create an account on AWS and also\n    follow the `setup instructions\n    <https://github.com/aws/amazon-braket-sdk-python#prerequisites>`__ for accessing Braket from\n    Python.</p></div>\n\nLet's load the SV1 simulator in PennyLane with 25 qubits. We must specify both the ARN and\nthe address of the `S3 bucket <https://aws.amazon.com/s3/>`__ where results are to be stored:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["my_bucket = \"amazon-braket-Your-Bucket-Name\"  # the name of the bucket, keep the 'amazon-braket-' prefix and then include the bucket name\nmy_prefix = \"Your-Folder-Name\"  # the name of the folder in the bucket\ns3_folder = (my_bucket, my_prefix)\n\ndevice_arn = \"arn:aws:braket:::device/quantum-simulator/amazon/sv1\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["SV1 can now be loaded with the standard PennyLane :func:`~.pennylane.device`:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["import pennylane as qml\nfrom pennylane import numpy as np\n\nn_wires = 25\n\ndev_remote = qml.device(\n    \"braket.aws.qubit\",\n    device_arn=device_arn,\n    wires=n_wires,\n    s3_destination_folder=s3_folder,\n    parallel=True,\n)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Note the ``parallel=True`` argument. This setting allows us to unlock the power of parallel\nexecution on SV1 for gradient calculations. We'll also load ``default.qubit`` for comparison.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["dev_local = qml.device(\"default.qubit\", wires=n_wires)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Note that a local Braket device ``braket.local.qubit`` is also available. See the\n`documentation <https://amazon-braket-pennylane-plugin-python.readthedocs.io>`__ for more details.\n\nBenchmarking circuit evaluation\n-------------------------------\n\nWe will now compare the execution time for the remote Braket SV1 device and ``default.qubit``. Our\nfirst step is to create a simple circuit:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def circuit(params):\n    for i in range(n_wires):\n        qml.RX(params[i], wires=i)\n    for i in range(n_wires):\n        qml.CNOT(wires=[i, (i + 1) % n_wires])\n    return qml.expval(qml.PauliZ(n_wires - 1))"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. figure:: ../_static/circuit.png\n    :align: center\n    :scale: 75%\n    :alt: A simple circuit used for benchmarking\n    :target: javascript:void(0);\n\nIn this circuit, each of the 25 qubits has a controllable rotation. A final block of two-qubit\nCNOT gates is added to entangle the qubits. Overall, this circuit has 25 trainable parameters.\nAlthough not particularly relevant for practical problems, we can use this circuit as a testbed\nfor our comparison.\n\nThe next step is to convert the above circuit into a PennyLane :func:`~.pennylane.QNode`.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["qnode_remote = qml.QNode(circuit, dev_remote)\nqnode_local = qml.QNode(circuit, dev_local)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-info\"><h4>Note</h4><p>The above uses :func:`~.pennylane.QNode` to convert the circuit. In other tutorials,\n    you may have seen the :func:`~.pennylane.qnode` decorator being used. These approaches are\n    interchangeable, but we use :func:`~.pennylane.QNode` here because it allows us to pair the\n    same circuit to different devices.</p></div>\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>Running the contents of this tutorial will result in simulation fees charged to your\n    AWS account. We recommend monitoring your usage on the AWS dashboard.</p></div>\n\nLet's now compare the execution time between the two devices:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["import time\n\nparams = np.random.random(n_wires)\n\nt_0_remote = time.time()\nqnode_remote(params)\nt_1_remote = time.time()\n\nt_0_local = time.time()\nqnode_local(params)\nt_1_local = time.time()\n\nprint(\"Execution time on remote device (seconds):\", t_1_remote - t_0_remote)\nprint(\"Execution time on local device (seconds):\", t_1_local - t_0_local)"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. rst-class:: sphx-glr-script-out\n\n Out:\n\n .. code-block:: none\n\n     Execution time on remote device (seconds): 3.5898206680030853\n     Execution time on local device (seconds): 23.50668462700196\n\nNice! These timings highlight the advantage of using the Amazon Braket SV1 device for simulations\nwith large qubit numbers. In general, simulation times scale exponentially with the number of\nqubits, but SV1 is highly optimized and running on AWS remote servers. This allows SV1 to\noutperform ``default.qubit`` in this 25-qubit example. The time you see in practice for the\nremote device will also depend on factors such as your distance to AWS servers.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Given these timings, why would anyone want to use ``default.qubit``? You should consider\n    using local devices when your circuit has few qubits. In this regime, the latency\n    times of communicating the circuit to a remote server dominate over simulation times,\n    allowing local simulators to be faster.</p></div>\n\nBenchmarking gradient calculations\n----------------------------------\n\nNow let us compare the gradient-calculation times between the two devices. Remember that when\nloading the remote device, we set ``parallel=True``. This allows the multiple device executions\nrequired during gradient calculations to be performed in parallel, so we expect the\nremote device to be much faster.\n\nFirst, consider the remote device:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["d_qnode_remote = qml.grad(qnode_remote)\n\nt_0_remote_grad = time.time()\nd_qnode_remote(params)\nt_1_remote_grad = time.time()\n\nprint(\"Gradient calculation time on remote device (seconds):\", t_1_remote_grad - t_0_remote_grad)"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. rst-class:: sphx-glr-script-out\n\n Out:\n\n .. code-block:: none\n\n     Gradient calculation time on remote device (seconds): 20.92005863400118\n\nNow, the local device:\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>Evaluating the gradient with ``default.qubit`` will take a long time, consider\n    commenting-out the following lines unless you are happy to wait.</p></div>\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["d_qnode_local = qml.grad(qnode_local)\n\nt_0_local_grad = time.time()\nd_qnode_local(params)\nt_1_local_grad = time.time()\n\nprint(\"Gradient calculation time on local device (seconds):\", t_1_local_grad - t_0_local_grad)"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. rst-class:: sphx-glr-script-out\n\n Out:\n\n .. code-block:: none\n\n     Gradient calculation time on local device (seconds): 941.8518133479993\n\nWow, the local device needs around 15 minutes or more! Compare this to less than a minute spent\ncalculating the gradient on SV1. This provides a powerful lesson in parallelization.\n\nWhat if we had run on SV1 with ``parallel=False``? It would have taken around 3 minutes\u2014still\nfaster than a local device, but much slower than running SV1 in parallel.\n\nScaling up QAOA for larger graphs\n---------------------------------\n\nThe quantum approximate optimization algorithm (QAOA) is a candidate algorithm for near-term\nquantum hardware that can find approximate solutions to combinatorial optimization\nproblems such as graph-based problems. We have seen in the main\n:doc:`QAOA tutorial<tutorial_qaoa_intro>` how QAOA successfully solves the minimum vertex\ncover problem on a four-node graph.\n\nHere, let's be ambitious and try to solve the maximum cut problem on a twenty-node graph! In\nmaximum cut, the objective is to partition the graph's nodes into two groups so that the number\nof edges crossed or 'cut' by the partition is maximized (see the diagram below). This problem is\nNP-hard, so we expect it to be tough as we increase the number of graph nodes.\n\n.. figure:: ../_static/max-cut.png\n    :align: center\n    :scale: 100%\n    :alt: The maximum cut problem\n    :target: javascript:void(0);\n\nLet's first set the graph:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["import networkx as nx\n\nnodes = n_wires = 20\nedges = 60\nseed = 1967\n\ng = nx.gnm_random_graph(nodes, edges, seed=seed)\npositions = nx.spring_layout(g, seed=seed)\n\nnx.draw(g, with_labels=True, pos=positions)"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. figure:: ../_static/20_node_graph.png\n    :align: center\n    :scale: 100%\n    :target: javascript:void(0);\n\nWe will use the remote SV1 device to help us optimize our QAOA circuit as quickly as possible.\nFirst, the device is loaded again for 20 qubits\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["dev = qml.device(\n    \"braket.aws.qubit\",\n    device_arn=device_arn,\n    wires=n_wires,\n    s3_destination_folder=s3_folder,\n    parallel=True,\n    max_parallel=20,\n    poll_timeout_seconds=30,\n)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Note the specification of ``max_parallel=20``. This means that up to ``20`` circuits will be\nexecuted in parallel on SV1 (the default value is ``10``).\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>Increasing the maximum number of parallel executions can result in a greater rate of\n    spending on simulation fees on Amazon Braket. The value must also be set bearing in mind your\n    service\n    `quota <https://docs.aws.amazon.com/braket/latest/developerguide/braket-quotas.html>`__.</p></div>\n\nThe QAOA problem can then be set up following the standard pattern, as discussed in detail in\nthe :doc:`QAOA tutorial<tutorial_qaoa_intro>`.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["cost_h, mixer_h = qml.qaoa.maxcut(g)\nn_layers = 2\n\n\ndef qaoa_layer(gamma, alpha):\n    qml.qaoa.cost_layer(gamma, cost_h)\n    qml.qaoa.mixer_layer(alpha, mixer_h)\n\n\ndef circuit(params, **kwargs):\n    for i in range(n_wires):  # Prepare an equal superposition over all qubits\n        qml.Hadamard(wires=i)\n\n    qml.layer(qaoa_layer, n_layers, params[0], params[1])\n    return qml.expval(cost_h)\n\n\ncost_function = qml.QNode(circuit, dev)\noptimizer = qml.AdagradOptimizer(stepsize=0.1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We're now set up to train the circuit! Note, if you are training this circuit yourself, you may\nwant to increase the number of iterations in the optimization loop and also investigate changing\nthe number of QAOA layers.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>The following lines are computationally intensive. Remember that running it will result in\n    simulation fees charged to your AWS account. We recommend monitoring your usage on the AWS\n    dashboard.</p></div>\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["import time\n\nnp.random.seed(1967)\nparams = 0.01 * np.random.uniform(size=[2, n_layers], requires_grad=True)\niterations = 10\n\nfor i in range(iterations):\n    t0 = time.time()\n\n    params, cost_before = optimizer.step_and_cost(cost_function, params)\n\n    t1 = time.time()\n\n    if i == 0:\n        print(\"Initial cost:\", cost_before)\n    else:\n        print(f\"Cost at step {i}:\", cost_before)\n\n    print(f\"Completed iteration {i + 1}\")\n    print(f\"Time to complete iteration: {t1 - t0} seconds\")\n\nprint(f\"Cost at step {iterations}:\", cost_function(params))\n\nnp.save(\"params.npy\", params)\nprint(\"Parameters saved to params.npy\")"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. rst-class:: sphx-glr-script-out\n\n Out:\n\n .. code-block:: none\n\n   Initial cost: -29.98570234095951\n   Completed iteration 1\n   Time to complete iteration: 93.96246099472046 seconds\n   Cost at step 1: -27.154071768632154\n   Completed iteration 2\n   Time to complete iteration: 84.80994844436646 seconds\n   Cost at step 2: -29.98726230006233\n   Completed iteration 3\n   Time to complete iteration: 83.13504934310913 seconds\n   Cost at step 3: -29.999163153600062\n   Completed iteration 4\n   Time to complete iteration: 85.61391234397888 seconds\n   Cost at step 4: -30.002158646044307\n   Completed iteration 5\n   Time to complete iteration: 86.70688223838806 seconds\n   Cost at step 5: -30.012058444011906\n   Completed iteration 6\n   Time to complete iteration: 83.26341080665588 seconds\n   Cost at step 6: -30.063709712612443\n   Completed iteration 7\n   Time to complete iteration: 85.25566911697388 seconds\n   Cost at step 7: -30.32522304705352\n   Completed iteration 8\n   Time to complete iteration: 83.55433392524719 seconds\n   Cost at step 8: -31.411030331978186\n   Completed iteration 9\n   Time to complete iteration: 84.08745908737183 seconds\n   Cost at step 9: -33.87153965616938\n   Completed iteration 10\n   Time to complete iteration: 87.4032838344574 seconds\n   Cost at step 10: -36.05424874438809\n   Parameters saved to params.npy\n\nThis example shows us that a 20-qubit QAOA problem can be trained within around 1-2 minutes per\niteration by using parallel executions on the Amazon Braket SV1 device to speed up gradient\ncalculations. If this problem were run on ``default.qubit`` without parallelization, we would\nexpect for training to take much longer.\n\nThe results of this optimization can be investigated by saving the parameters\n:download:`here </demonstrations/braket/params.npy>` to your working directory. See if you can\nanalyze the performance of this optimized circuit following a similar strategy to the\n:doc:`QAOA tutorial<tutorial_qaoa_intro>`. Did we find a large graph cut?\n\n"]}]}