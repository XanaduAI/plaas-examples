{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n# Quantum volume\n\n.. meta::\n    :property=\"og:description\": Learn about quantum volume, and how to\n        compute it.\n    :property=\"og:image\": https://pennylane.ai/qml/_images/quantum_volume_thumbnail.png\n\n.. related::\n\n    qsim_beyond_classical Beyond classical computing with qsim\n\n*Author: PennyLane dev team. Posted: 15 Dec 2020. Last updated: 15 Apr 2021.*\n\nTwice per year, a project called the TOP500 [#top500]_ releases a list of the\n500 most powerful supercomputing systems in the world. However, there is a large\namount of variation in how supercomputers are built. They may run different\noperating systems and have varying amounts of memory. `Some\n<https://en.wikipedia.org/wiki/Fugaku_(supercomputer)>`_ use 48-core processors,\nwhile `others <https://en.wikipedia.org/wiki/Sunway_TaihuLight>`_ use processors\nwith up to 260 cores. The speed of processors will differ, and they may be\nconnected in different ways. We can't rank them by simply counting the number of\nprocessors!\n\nIn order to make a fair comparison, we need benchmarking standards that give us\na holistic view of their performance. To that end, the TOP500 rankings are based\non something called the LINPACK benchmark [#linpack]_. The task of the\nsupercomputers is to solve a dense system of linear equations, and the metric of\ninterest is the rate at which they perform `floating-point operations (FLOPS)\n<https://en.wikipedia.org/wiki/FLOPS>`__. Today's top machines reach speeds well\ninto the regime of hundreds of petaFLOPS! While a single number certainly\ncannot tell the whole story, it still gives us insight into the quality of the\nmachines, and provides a standard so we can compare them.\n\nA similar problem is emerging with quantum computers: we can't judge quantum\ncomputers on the number of qubits alone. Present-day devices have a number of\nlimitations, an important one being gate error rates. Typically\nthe qubits on a chip are not all connected to each other, so it may not be\npossible to perform operations on arbitrary pairs of them.\n\nConsidering this, can we tell if a machine with 20 noisy qubits is better\nthan one with 5 very high-quality qubits? Or if a machine with 8 fully-connected\nqubits is better than one with 16 qubits of comparable error rate, but arranged in\na square lattice?  How can we make comparisons between different\ntypes of qubits?\n\n.. figure:: ../demonstrations/quantum_volume/qubit_graph_variety.svg\n    :align: center\n    :width: 50%\n\n    ..\n\n    Which of these qubit hardware graphs is the best?\n\nTo compare across all these facets, researchers have proposed a metric called\n\"quantum volume\" [#cross]_. Roughly, the quantum volume is a measure of the\neffective number of qubits a processor has. It is calculated by determining the\nlargest number of qubits on which it can reliably run circuits of a prescribed\ntype. You can think of it loosely as a quantum analogue of the LINPACK\nbenchmark. Different quantum computers are tasked with solving the same problem,\nand the success will be a function of many properties: error rates, qubit\nconnectivity, even the quality of the software stack. A single\nnumber won't tell us everything about a quantum computer, but it does establish\na framework for comparing them.\n\nAfter working through this tutorial, you'll be able to define quantum volume,\nexplain the problem on which it's based, and run the protocol to compute it!\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Designing a benchmark for quantum computers\n\nThere are many different properties of a quantum computer\nthat contribute to the successful execution of a computation. Therefore, we\nmust be very explicit about what exactly we are benchmarking, and what is our\nmeasure of success. In general, to set up a benchmark for a quantum computer\nwe need to decide on a number of things [#robin]_:\n\n1. A family of circuits with a well-defined structure and variable size\n2. A set of rules detailing how the circuits can be compiled\n3. A measure of success for individual circuits\n4. A measure of success for the family of circuits\n5. (Optional) An experimental design specifying how the circuits are to be run\n\nWe'll work through this list in order to see how the protocol for computing\nquantum volume fits within this framework.\n\n### The circuits\n\nQuantum volume relates\nto the largest *square* circuit that a quantum processor can run reliably. This benchmark\nuses *random* square circuits with a very particular form:\n\n.. figure:: ../demonstrations/quantum_volume/model_circuit_cross.png\n    :align: center\n    :width: 60%\n\n    ..\n\n    A schematic of the random circuit structure used in the quantum volume protocol.\n    Image source: [#cross]_.\n\nSpecifically, the circuits consist of $d$ sequential layers acting on\n$d$ qubits. Each layer consists of two parts: a random permutation of\nthe qubits, followed by Haar-random SU(4) operations performed on neighbouring\npairs of qubits. (When the number of qubits is odd, the bottom-most qubit is\nidle while the SU(4) operations run on the pairs. However, it will still be\nincorporated by way of the permutations.) These circuits satisfy the criteria\nin item 1 --- they have well-defined structure, and it is clear how they can be\nscaled to different sizes.\n\nAs for the compilation rules of item 2, to compute quantum volume we're\nallowed to do essentially anything we'd like to the circuits in order to\nimprove them. This includes optimization, hardware-aware considerations such\nas qubit placement and routing, and even resynthesis by finding unitaries that\nare close to the target, but easier to implement on the hardware [#cross]_.\n\nBoth the circuit structure and the compilation highlight how quantum volume is\nabout more than just the number of qubits. The error rates will affect the\nachievable depth, and the qubit connectivity contributes through the layers of\npermutations because a very well-connected processor will be able to implement\nthese in fewer steps than a less-connected one. Even the quality of the\nsoftware and the compiler plays a role here: higher-quality compilers will\nproduce circuits that fit better on the target devices, and will thus produce\nhigher quality results.\n\n### The measures of success\n\nNow that we have our circuits, we have to define the quantities that will\nindicate how well we're able to run them. For that, we need a problem\nto solve. The problem used for computing quantum volume is called the *heavy output\ngeneration problem*. It has roots in the proposals for demonstrating quantum\nadvantage [#aaronson]_. Many such proposals make use of the properties of\nvarious random quantum circuit families, as the distribution of the\nmeasurement outcomes may not be easy to sample using classical\ntechniques.\n\nA distribution that is theorized to fulfill this property is the distribution\nof *heavy* output bit strings. Heavy bit strings are those whose outcome\nprobabilities are above the median of the distribution. For example, suppose\nwe run a two-qubit circuit and find that the measurement probabilities for\nthe output states are as follows:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["measurement_probs = {\"00\": 0.558, \"01\": 0.182, \"10\": 0.234, \"11\": 0.026}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The median of this probability distribution is:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["import numpy as np\nprob_array = np.fromiter(measurement_probs.values(), dtype=np.float64)\nprint(f\"Median = {np.median(prob_array):.3f}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. rst-class:: sphx-glr-script-out\n\n Out:\n\n .. code-block:: none\n\n    Median = 0.208\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This means that the heavy bit strings are '00' and '10', because these are\nthe two probabilities above the median. If we were to run this circuit, the\nprobability of obtaining one of the heavy outputs is:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["heavy_output_prob = np.sum(prob_array[prob_array > np.median(prob_array)])\nprint(f\"Heavy output probability = {heavy_output_prob}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. rst-class:: sphx-glr-script-out\n\n Out:\n\n .. code-block:: none\n\n    Heavy output probability = 0.792\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Each circuit in a circuit family has its own heavy output probability. If our\nquantum computer is of high quality, then we should expect to see heavy\noutputs quite often across all the circuits. On the other hand, if it's of\npoor quality and everything is totally decohered, we will end up with output\nprobabilities that are roughly all the same, as noise will reduce the\nprobabilities to the uniform distribution.\n\nThe heavy output generation problem quantifies this --- for our family of\nrandom circuits, do we obtain heavy outputs at least 2/3 of the time on\naverage?  Furthermore, do we obtain this with high confidence? This is the\nbasis for quantum volume. Looking back at the criteria for our benchmarks, for\nitem 3 the measure of success for each circuit is how often we obtain heavy\noutputs when we run the circuit and take a measurement. For item 4 the\nmeasure of success for the whole family is whether or not the mean of these\nprobabilities is greater than 2/3 with high confidence.\n\nOn a related note, it is important to determine what heavy output probability\nwe should *expect* to see on average. The intuition for how this can be\ncalculated is as follows [#aaronson]_, [#cmu]_.  Suppose that our random\nsquare circuits scramble things up enough so that the effective operation\nlooks like a Haar-random unitary $U$. Since in the circuits we are\napplying $U$ to the all-zero ket, the measurement outcome probabilities\nwill be the moduli squared of the entries in the first column of $U$.\n\nNow if $U$ is Haar-random, we can say something about the form of these\nentries. In particular, they are complex numbers for which both the real and\nimaginary parts are normally distributed with mean 0 and variance\n$1/2^m$, where $m$ is the number of qubits. Taking the modulus\nsquared of such numbers and making a histogram yields a distribution\nof probabilities with the form $\\hbox{Pr}(p) \\sim 2^m e^{-2^m p}.$ This\nis also known as the *Porter-Thomas distribution*.\n\nBy looking at the form of the underlying probability distribution, the\nexponential distribution $\\hbox{Pr}(x) = e^{-x}$, we can calculate some\nproperties of the heavy output probabilities. First, we can integrate the exponential\ndistribution to find that the median sits at $\\ln 2$.  We can further\ncompute the expectation value of obtaining something greater than the median\nby integrating $x e^{-x}$ from $\\ln 2$ to $\\infty$ to obtain\n$(1 + \\ln 2)/2$. This is the expected heavy output probability!\nNumerically it is around 0.85, as we will observe later in our results.\n\n\n### The benchmark\n\nNow that we have our circuits and our measures of success, we're ready to\ndefine the quantum volume.\n\n\n.. admonition:: Definition\n    :class: defn\n\n    The quantum volume $V_Q$ of an $n$-qubit processor is defined as [#cross]_\n\n    .. math::\n        \\log_2(V_Q) = \\hbox{argmax}_m \\min (m, d(m))\n\n    where $m \\leq n$ is a number of qubits, and $d(m)$ is the number of\n    qubits in the largest square circuits for which we can reliably sample\n    heavy outputs with probability greater than 2/3.\n\nTo see this more concretely, suppose we have a 20-qubit device and find that\nwe get heavy outputs reliably for up to depth-4 circuits on any set of 4\nqubits, then the quantum volume is $\\log_2 V_Q = 4$. Quantum volume is\nincremental, as shown below --- we gradually work our way up to larger\ncircuits, until we find something we can't do.  Very loosely, quantum volume\nis like an effective number of qubits. Even if we have those 20 qubits, only\ngroups of up to 4 of them work well enough together to sample from\ndistributions that would be considered hard.\n\n.. figure:: ../demonstrations/quantum_volume/qv_square_circuits.svg\n    :align: center\n    :width: 75%\n\n    ..\n\n    This quantum computer has $\\log_2 V_Q = 4$, as the 4-qubit square\n    circuits are the largest ones it can run successfully.\n\n\nThe maximum achieved quantum volume has been doubling at an increasing rate. In\nlate 2020, the most recent announcements have been $\\log_2 V_Q = 6$ on\nIBM's 27-qubit superconducting device `ibmq_montreal` [#qv64]_, and\n$\\log_2 V_Q = 7$ on a Honeywell trapped-ion qubit processor\n[#honeywell]_. A device with an expected quantum volume of $\\log_2 V_Q\n= 22$ has also been announced by IonQ [#ionq]_, though benchmarking results\nhave not yet been published.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In many sources, the quantum volume of processors is reported as\n   $V_Q$ explicitly, rather than $\\log_2 V_Q$ as is the\n   convention in this demo. As such, IonQ's processor has the potential for a\n   quantum volume of $2^{22} > 4000000$. Here we use the $\\log$\n   because it is more straightforward to understand that they have 22\n   high-quality, well-connected qubits than to extract this at first glance from the\n   explicit value of the volume.</p></div>\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Computing the quantum volume\n\nEquipped with our definition of quantum volume, it's time to compute it\nourselves! We'll use the `PennyLane-Qiskit\n<https://pennylaneqiskit.readthedocs.io/en/latest/>`_ plugin to compute the\nvolume of a simulated version of one of the IBM processors, since their properties are easily\naccessible through this plugin.\n\n\nLoosely, the protocol for quantum volume consists of three steps:\n\n1. Construct random square circuits of increasing size\n\n2. Run those circuits on both a simulator and on a noisy hardware device\n\n3. Perform a statistical analysis of the results to determine what size\n   circuits the device can run reliably\n\n\nThe largest reliable size will become the $m$ in the expression for\nquantum volume.\n\n\n### Step 1: construct random square circuits\n\nRecall that the structure of the circuits above is alternating layers of\npermutations and random SU(4) operations on pairs of qubits.  Let's implement\nthe generation of such circuits in PennyLane.\n\nFirst we write a function that randomly permutes qubits. We'll do this by\nusing numpy to generate a permutation, and then apply it with the built-in\n:func:`~.pennylane.Permute` subroutine.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["import pennylane as qml\n\n# Object for random number generation from numpy\nrng = np.random.default_rng()\n\ndef permute_qubits(num_qubits):\n    # A random permutation\n    perm_order = list(rng.permutation(num_qubits))\n    qml.Permute(perm_order, wires=list(range(num_qubits)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Next, we need to apply SU(4) gates to pairs of qubits. PennyLane doesn't have\nbuilt-in functionality to generate these random matrices, however its cousin\n`Strawberry Fields <https://strawberryfields.ai/>`_ does! We will use the\n``random_interferometer`` method, which can generate unitary matrices uniformly\nat random. This function actually generates elements of U(4), but they are\nessentially equivalent up to a global phase.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["from strawberryfields.utils import random_interferometer\n\ndef apply_random_su4_layer(num_qubits):\n    for qubit_idx in range(0, num_qubits, 2):\n        if qubit_idx < num_qubits - 1:\n            rand_haar_su4 = random_interferometer(N=4)\n            qml.QubitUnitary(rand_haar_su4, wires=[qubit_idx, qubit_idx + 1])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Next, let's write a layering method to put the two together --- this is just\nfor convenience and to highlight the fact that these two methods together\nmake up one layer of the circuit depth.\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def qv_circuit_layer(num_qubits):\n    permute_qubits(num_qubits)\n    apply_random_su4_layer(num_qubits)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's take a look! We'll set up an ideal device with 5 qubits, and generate a\ncircuit with 3 qubits. In this demo, we'll work explicitly with `quantum tapes\n<https://pennylane.readthedocs.io/en/latest/code/qml_tape.html>`__ since they\nare not immediately tied to a device. This will be convenient later when we\nneed to run the same random circuit on two devices independently.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["num_qubits = 5\ndev_ideal = qml.device(\"default.qubit\", shots=None, wires=num_qubits)\n\nm = 3  # number of qubits\n\nwith qml.tape.QuantumTape() as tape:\n    qml.layer(qv_circuit_layer, m, num_qubits=m)\n\nexpanded_tape = tape.expand(stop_at=lambda op: isinstance(op, qml.QubitUnitary))\nprint(qml.drawer.tape_text(expanded_tape, wire_order=dev_ideal.wires, show_all_wires=True, show_matrices=True))"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. rst-class:: sphx-glr-script-out\n\n Out:\n\n .. code-block:: none\n\n    0: \u2500\u256dSWAP\u2500\u256dU(M0)\u2500\u256dU(M1)\u2500\u256dSWAP\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256dU(M2)\u2500\u2524\n    1: \u2500\u2570SWAP\u2500\u2570U(M0)\u2500\u2570U(M1)\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u256dSWAP\u2500\u2570U(M2)\u2500\u2524\n    2: \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2570SWAP\u2500\u2570SWAP\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    3: \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    4: \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    M0 =\n    [[-0.17514647+0.00759447j  0.11975927+0.16007614j -0.41793925+0.49643728j\n       0.62304058-0.34640531j]\n     [-0.73367896-0.58079555j -0.11348577+0.00751965j -0.02640159-0.15592112j\n      -0.19507153-0.21998821j]\n     [ 0.02988983+0.09364586j -0.74053162+0.55032455j  0.31350059-0.01305651j\n       0.16283233-0.11885036j]\n     [-0.13103809-0.25850305j  0.18298996+0.2497364j   0.34879438+0.57771772j\n      -0.02385446+0.60346274j]]\n    M1 =\n    [[ 0.14296171+0.28087257j -0.5985737 -0.27489922j -0.43838149+0.10344812j\n       0.04022491+0.51216658j]\n     [-0.21538853+0.02728431j -0.24776721-0.57146257j  0.60975755+0.36241573j\n       0.21787038-0.11953391j]\n     [-0.24405375+0.05780278j -0.11688629-0.17397518j -0.51628349-0.11381455j\n       0.44143429-0.64714776j]\n     [-0.750841  -0.47630904j -0.28666068+0.22820556j -0.09459735+0.07429451j\n      -0.17243398+0.17582253j]]\n   M2 =\n   [[-0.63733359+1.91519046e-01j -0.49615702+9.79920998e-05j\n      0.06949634+4.54968771e-01j  0.21112196-2.33571716e-01j]\n    [ 0.4774216 +5.19692450e-02j -0.2741782 -3.71778068e-01j\n      0.09817361+6.01972062e-01j -0.39517581+1.66741872e-01j]\n    [ 0.14401687-1.53582182e-01j  0.51636466-1.58216631e-01j\n      0.43804144+3.62586089e-01j  0.4473567 -3.74872915e-01j]\n    [ 0.51670588+1.23210608e-01j -0.48982566-9.40288988e-02j\n     -0.19210465-2.36457367e-01j  0.53202679-3.05278186e-01j]]\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The first thing to note is that the last two qubits are never used in the\noperations, since the quantum volume circuits are square. Another important\npoint is that this circuit with 3 layers actually has depth much greater than\n3, since each layer has both SWAPs and SU(4) operations that are further\ndecomposed into elementary gates when run on the actual processor.\n\nOne last thing we'll need before running our circuits is the machinery to\ndetermine the heavy outputs. This is quite an interesting aspect of the\nprotocol --- we're required to compute the heavy outputs classically in order\nto get the results! As a consequence, it will only be possible to calculate\nquantum volume for processors up to a certain point before they become too\nlarge.\n\nThat said, classical simulators are always improving, and can simulate\ncircuits with numbers of qubits well into the double digits (though they may\nneed a supercomputer to do so). Furthermore, the designers of the protocol\ndon't expect this to be an issue until gate error rates decrease below\n$\\approx 10^{-4}$, after which we may need to make adjustments to remove\nthe classical simulation, or even consider new volume metrics [#cross]_.\n\nThe heavy outputs can be retrieved from a classically-obtained probability\ndistribution as follows:\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def heavy_output_set(m, probs):\n    # Compute heavy outputs of an m-qubit circuit with measurement outcome\n    # probabilities given by probs, which is an array with the probabilities\n    # ordered as '000', '001', ... '111'.\n\n    # Sort the probabilities so that those above the median are in the second half\n    probs_ascending_order = np.argsort(probs)\n    sorted_probs = probs[probs_ascending_order]\n\n    # Heavy outputs are the bit strings above the median\n    heavy_outputs = [\n        # Convert integer indices to m-bit binary strings\n        format(x, f\"#0{m+2}b\")[2:] for x in list(probs_ascending_order[2 ** (m - 1) :])\n    ]\n\n    # Probability of a heavy output\n    prob_heavy_output = np.sum(sorted_probs[2 ** (m - 1) :])\n\n    return heavy_outputs, prob_heavy_output"]}, {"cell_type": "markdown", "metadata": {}, "source": ["As an example, let's compute the heavy outputs and probability for our circuit\nabove.\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# Adds a measurement of the first m qubits to the previous circuit\nwith tape:\n    qml.probs(wires=range(m))\n\n# Run the circuit, compute heavy outputs, and print results\noutput_probs = qml.execute([tape], dev_ideal, None)  # returns a list of result !\noutput_probs = output_probs[0].reshape(2 ** m, )\nheavy_outputs, prob_heavy_output = heavy_output_set(m, output_probs)\n\nprint(\"State\\tProbability\")\nfor idx, prob in enumerate(output_probs):\n    bit_string = format(idx, f\"#05b\")[2:]\n    print(f\"{bit_string}\\t{prob:.4f}\")\n\nprint(f\"\\nMedian is {np.median(output_probs):.4f}\")\nprint(f\"Probability of a heavy output is {prob_heavy_output:.4f}\")\nprint(f\"Heavy outputs are {heavy_outputs}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. rst-class:: sphx-glr-script-out\n\n Out:\n\n .. code-block:: none\n\n    State      Probability\n    000        0.0157\n    001        0.0200\n    010        0.0026\n    011        0.2765\n    100        0.0175\n    101        0.4266\n    110        0.0045\n    111        0.2365\n\n    Median is 0.0188\n    Probability of a heavy output is 0.9596\n    Heavy outputs are ['001', '111', '011', '101']\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Step 2: run the circuits\n\nNow it's time to run the protocol. First, let's set up our hardware\ndevice. We'll use a simulated version of the 5-qubit IBM Ourense as an example\n--- the reported quantum volume according to IBM is $V_Q=8$, so we\nendeavour to reproduce that here. This means that we should be able to run our\nsquare circuits reliably on up to $\\log_2 V_Q =3$ qubits.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In order to access the IBM Q backend, users must have an IBM Q account\n   configured. This can be done by running:\n\n        .. code-block:: python3\n\n            from qiskit import IBMQ\n            IBMQ.save_account('MY_API_TOKEN')\n\n   A token can be generated by logging into your IBM Q account `here <https://quantum-computing.ibm.com/login>`_ .</p></div>\n\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In the time since the original release of this demo, the Ourense device is\n   no longer available from IBM Q. However, we leave the original results for\n   expository purposes, and note that the methods are applicable in general.\n   Users can get a list of available IBM Q backends by importing IBM Q,\n   specifying their provider and then calling: ``provider.backends()``</p></div>\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["dev_ourense = qml.device(\"qiskit.ibmq\", wires=5, backend=\"ibmq_bogota\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["First, we can take a look at the arrangement of the qubits on the processor\nby plotting its hardware graph.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["import matplotlib.pyplot as plt\nimport networkx as nx\n\nourense_hardware_graph = nx.Graph(dev_ourense.backend.configuration().coupling_map)\n\nnx.draw_networkx(\n    ourense_hardware_graph,\n    node_color=\"cyan\",\n    labels={x: x for x in range(dev_ourense.num_wires)},\n)"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. figure:: ../demonstrations/quantum_volume/ourense.svg\n    :align: center\n    :width: 75%\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This hardware graph is not fully connected, so the quantum compiler will have\nto make some adjustments when non-connected qubits need to interact.\n\nTo actually perform the simulations, we'll need to access a copy of the\nOurense noise model. Again, we won't be running on Ourense directly ---\nwe'll set up a local device to simulate its behaviour.\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["from qiskit.providers.aer import noise\n\nnoise_model = noise.NoiseModel.from_backend(dev_ourense.backend)\n\ndev_noisy = qml.device(\n    \"qiskit.aer\", wires=dev_ourense.num_wires, shots=1000, noise_model=noise_model\n)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["As a final point, since we are allowed to do as much optimization as we like,\nlet's put the compiler to work. The compiler will perform a number of\noptimizations to simplify our circuit. We'll also specify some high-quality\nqubit placement and routing techniques [#sabre]_ in order to fit the circuits\non the hardware graph in the best way possible.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["coupling_map = dev_ourense.backend.configuration().to_dict()[\"coupling_map\"]\n\ndev_noisy.set_transpile_args(\n    **{\n        \"optimization_level\": 3,\n        \"coupling_map\": coupling_map,\n        \"layout_method\": \"sabre\",\n        \"routing_method\": \"sabre\",\n    }\n)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's run the protocol. We'll start with the smallest circuits on 2\nqubits, and make our way up to 5. At each $m$, we'll look at 200 randomly\ngenerated circuits.\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["min_m = 2\nmax_m = 5\nnum_ms = (max_m - min_m) + 1\n\nnum_trials = 200\n\n# To store the results\nprobs_ideal = np.zeros((num_ms, num_trials))\nprobs_noisy = np.zeros((num_ms, num_trials))\n\nfor m in range(min_m, max_m + 1):\n    for trial in range(num_trials):\n\n        # Simulate the circuit analytically\n        with qml.tape.QuantumTape() as tape:\n            qml.layer(qv_circuit_layer, m, num_qubits=m)\n            qml.probs(wires=range(m))\n\n        output_probs = qml.execute([tape], dev_ideal, None)\n        output_probs = output_probs[0].reshape(2 ** m, )\n        heavy_outputs, prob_heavy_output = heavy_output_set(m, output_probs)\n\n        # Execute circuit on the noisy device\n        qml.execute([tape], dev_noisy, None)\n\n        # Get the output bit strings; flip ordering of qubits to match PennyLane\n        counts = dev_noisy._current_job.result().get_counts()\n        reordered_counts = {x[::-1]: counts[x] for x in counts.keys()}\n\n        device_heavy_outputs = np.sum(\n            [\n                reordered_counts[x] if x[:m] in heavy_outputs else 0\n                for x in reordered_counts.keys()\n            ]\n        )\n        fraction_device_heavy_output = device_heavy_outputs / dev_noisy.shots\n\n        probs_ideal[m - min_m, trial] = prob_heavy_output\n        probs_noisy[m - min_m, trial] = fraction_device_heavy_output"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Step 3: perform a statistical analysis\n\nHaving run our experiments, we can now get to the heart of the quantum volume\nprotocol: what *is* the largest square circuit that our processor can run?\nLet's first check out the means and see how much higher they are than 2/3.\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["probs_mean_ideal = np.mean(probs_ideal, axis=1)\nprobs_mean_noisy = np.mean(probs_noisy, axis=1)\n\nprint(f\"Ideal mean probabilities:\")\nfor idx, prob in enumerate(probs_mean_ideal):\n    print(f\"m = {idx + min_m}: {prob:.6f} {'above' if prob > 2/3 else 'below'} threshold.\")\n\nprint(f\"\\nDevice mean probabilities:\")\nfor idx, prob in enumerate(probs_mean_noisy):\n    print(f\"m = {idx + min_m}: {prob:.6f} {'above' if prob > 2/3 else 'below'} threshold.\")"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. rst-class:: sphx-glr-script-out\n\n Out:\n\n .. code-block:: none\n\n    Ideal mean probabilities:\n    m = 2: 0.797979 above threshold.\n    m = 3: 0.844052 above threshold.\n    m = 4: 0.841203 above threshold.\n    m = 5: 0.856904 above threshold.\n\n    Device mean probabilities:\n    m = 2: 0.773760 above threshold.\n    m = 3: 0.794875 above threshold.\n    m = 4: 0.722860 above threshold.\n    m = 5: 0.692935 above threshold.\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We see that the ideal probabilities are well over 2/3. In fact, they're quite\nclose to the expected value of $(1 + \\ln 2)/2$, which we recall from\nabove is $\\approx 0.85$.  For this experiment, we see that the device\nprobabilities are also above the threshold.  But it isn't enough that just the\nmean of the heavy output probabilities is greater than 2/3. Since we're\ndealing with randomness, we also want to ensure these results were not just a\nfluke! To be confident, we also want to be above 2/3 within 2 standard\ndeviations $(\\sigma)$ of the mean. This is referred to as a 97.5%\nconfidence interval (since roughly 97.5% of a normal distribution sits within\n$2\\sigma$ of the mean.)\n\nAt this point, we're going to do some statistical sorcery and make some\nassumptions about our distributions. Whether or not a circuit is successful\n(in the sense that it produces heavy outputs more the 2/3 of the time) is a\nbinary outcome. When we sample many circuits, it is almost like we are\nsampling from a *binomial distribution* where the outcome probability is\nequivalent to the heavy output probability. In the limit of a large number of\nsamples (in this case 200 circuits), a binomial distribution starts to look\nlike a normal distribution. If we make this approximation, we can compute the standard\ndeviation and use it to make our confidence interval. With the normal\napproximation, the standard deviation is\n\n\\begin{align}\\sigma = \\sqrt{\\frac{p_h(1 - p_h)}{N}},\\end{align}\n\nwhere $p_h$ is the average heavy output probability, and $N$ is\nthe number of circuits.\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["stds_ideal = np.sqrt(probs_mean_ideal * (1 - probs_mean_ideal) / num_trials)\nstds_noisy = np.sqrt(probs_mean_noisy * (1 - probs_mean_noisy) / num_trials)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now that we have our standard deviations, let's see if our means are at least\n$2\\sigma$ away from the threshold!\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["fig, ax = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(9, 6))\nax = ax.ravel()\n\nfor m in range(min_m - 2, max_m + 1 - 2):\n    ax[m].hist(probs_noisy[m, :])\n    ax[m].set_title(f\"m = {m + min_m}\", fontsize=16)\n    ax[m].set_xlabel(\"Heavy output probability\", fontsize=14)\n    ax[m].set_ylabel(\"Occurrences\", fontsize=14)\n    ax[m].axvline(x=2.0 / 3, color=\"black\", label=\"2/3\")\n    ax[m].axvline(x=probs_mean_noisy[m], color=\"red\", label=\"Mean\")\n    ax[m].axvline(\n        x=(probs_mean_noisy[m] - 2 * stds_noisy[m]),\n        color=\"red\",\n        linestyle=\"dashed\",\n        label=\"2\u03c3\",\n    )\n\nfig.suptitle(\"Heavy output distributions for (simulated) Ourense QPU\", fontsize=18)\nplt.legend(fontsize=14)\nplt.tight_layout()"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. figure:: ../demonstrations/quantum_volume/ourense_heavy_output_distributions.svg\n    :align: center\n    :width: 90%\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's verify this numerically:\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["two_sigma_below = probs_mean_noisy - 2 * stds_noisy\n\nfor idx, prob in enumerate(two_sigma_below):\n    print(f\"m = {idx + min_m}: {prob:.6f} {'above' if prob > 2/3 else 'below'} threshold.\")"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. rst-class:: sphx-glr-script-out\n\n Out:\n\n .. code-block:: none\n\n    m = 2: 0.714590 above threshold.\n    m = 3: 0.737770 above threshold.\n    m = 4: 0.659562 below threshold.\n    m = 5: 0.627701 below threshold.\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We see that we are $2\\sigma$ above the threshold only for $m=2$,\nand $m=3$. Thus, we find that the quantum volume of our simulated Ourense is\n$\\log_2 V_Q = 3$, or $V_Q = 8$, as expected.\n\nThis framework and code will allow you to calculate the quantum volume of many\ndifferent processors. Try it yourself! What happens if we don't specify a\nlarge amount of compiler optimization? How does the volume compare across\ndifferent hardware devices? You can even build your own device configurations\nand noise models to explore the extent to which different factors affect the\nvolume.\n\n## Concluding thoughts\n\nQuantum volume is a metric used for comparing the quality of different quantum\ncomputers. By determining the largest square random circuits a processor can\nrun reliably, it provides a measure of the effective number of qubits a\nprocessor has. Furthermore, it goes beyond just gauging quality by a number of\nqubits --- it incorporates many different aspects of a device such as its\ncompiler, qubit connectivity, and gate error rates.\n\nHowever, as with any benchmark, it is not without limitations. A key one\nalready discussed is that the heavy output generation problem requires us to\nsimulate circuits classically in addition to running them on a device. While\nthis is perhaps not an issue now, it will surely become one in the future. The\nnumber of qubits continues to increase and error rates are getting lower,\nboth of which imply that our square circuits will be growing in both width and\ndepth as time goes on. Eventually they will reach a point where they are no\nlonger classical simulable and we will have to design new benchmarks.\n\nAnother limitation is that the protocol only looks at one type of circuit,\ni.e., square circuits. It might be the case that a processor has very few\nqubits, but also very low error rates. For example, what if a processor with 5\nqubits can run circuits with up to 20 layers? Quantum volume would limit us to\n$\\log_2 V_Q = 5$ and the high quality of those qubits is not reflected\nin this.  To that end, a more general *volumetric benchmark* framework was\nproposed that includes not only square circuits, but also rectangular circuits\n[#robin]_. Investigating very deep circuits on few qubits (and very shallow\ncircuits on many qubits) will give us a broader overview of a processor's\nquality. Furthermore, the flexibility of the framework of [#robin]_ will\nsurely inspire us to create new types of benchmarks. Having a variety of\nbenchmarks calculated in different ways is beneficial and gives us a broader\nview of the performance of quantum computers.\n\n\n\n## References\n\n.. [#top500]\n\n    `<https://www.top500.org/>`__\n\n.. [#linpack]\n\n   `<https://www.top500.org/project/linpack/>`__\n\n.. [#cross]\n\n   Cross, A. W., Bishop, L. S., Sheldon, S., Nation, P. D., & Gambetta, J. M.,\n   Validating quantum computers using randomized model circuits, `Physical\n   Review A, 100(3), (2019). <http://dx.doi.org/10.1103/physreva.100.032328>`__\n\n.. [#robin]\n\n   Blume-Kohout, R., & Young, K. C., A volumetric framework for quantum\n   computer benchmarks, `Quantum, 4, 362 (2020).\n   <http://dx.doi.org/10.22331/q-2020-11-15-362>`__\n\n.. [#aaronson]\n\n   Aaronson, S., & Chen, L., Complexity-theoretic foundations of quantum supremacy experiments.\n   `arXiv 1612.05903 quant-ph <https://arxiv.org/abs/1612.05903>`__\n\n.. [#cmu]\n\n   O'Donnell, R. CMU course: Quantum Computation and Quantum Information 2018.\n   `Lecture 25 <https://www.cs.cmu.edu/~odonnell/quantum18/lecture25.pdf>`__\n\n.. [#qv64]\n\n   Jurcevic et al. Demonstration of quantum volume 64 on a superconducting quantum computing system.\n   `arXiv 2008.08571 quant-ph <https://arxiv.org/abs/2008.08571>`__\n\n.. [#honeywell]\n\n   `<https://www.honeywell.com/en-us/newsroom/news/2020/09/achieving-quantum-volume-128-on-the-honeywell-quantum-computer>`__\n\n.. [#ionq]\n\n   `<https://www.prnewswire.com/news-releases/ionq-unveils-worlds-most-powerful-quantum-computer-301143782.html>`__\n\n.. [#sabre]\n\n   Li, G., Ding, Y., & Xie, Y., Tackling the qubit mapping problem for\n   nisq-era quantum devices, `In Proceedings of the Twenty-Fourth\n   International Conference on Architectural Support for Programming Languages\n   and Operating Systems (pp. 1001\u20131014)\n   (2019). <https://dl.acm.org/doi/10.1145/3297858.3304023>`__ New York, NY,\n   USA: Association for Computing Machinery.\n\n"]}], "metadata": {"kernelspec": {"display_name": "PennyLane", "language": "python", "name": "pennylane"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.10"}}, "nbformat": 4, "nbformat_minor": 0}