{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. role:: html(raw)\n   :format: html\n\nUnderstanding the Haar Measure\n==============================\n\n.. meta::\n    :property=\"og:description\": Learn all about the Haar measure and how to randomly sample quantum states.\n\n    :property=\"og:image\": https://pennylane.ai/qml/_images/spherical_int_dtheta.png\n\n.. related::\n\n    tutorial_unitary_designs Unitary designs\n    quantum_volume Quantum volume\n    qsim_beyond_classical Beyond classical computing with qsim\n    tutorial_barren_plateaus Barren plateaus\n\n\n*Author: PennyLane dev team. Posted: 22 March 2021. Last updated: 22 March 2021.*\n\nIf you've ever dug into the literature about random quantum circuits,\nvariational ansatz structure, or anything related to the structure and\nproperties of unitary operations, you've likely come across a statement like the\nfollowing: \"Assume that $U$ is sampled uniformly at random from the Haar\nmeasure\".  In this demo, we're going to unravel this cryptic statement and take\nan in-depth look at what it means. You'll gain an understanding of the general\nconcept of *measure*, the Haar measure and its special properties, and you'll\nlearn how to sample from it using tools available in PennyLane and other\nscientific computing frameworks. By the end of this demo, you'll be able to\ninclude that important statement in your own work with confidence!\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>To get the most out of this demo, it is helpful if you are familiar with\n   `integration of multi-dimensional functions\n   <https://en.wikipedia.org/wiki/Multiple_integral>`__, the `Bloch sphere\n   <https://en.wikipedia.org/wiki/Bloch_sphere>`__, and the conceptual ideas\n   behind `decompositions\n   <https://en.wikipedia.org/wiki/Matrix_decomposition>`__ and factorizations of\n   unitary matrices (see, e.g., 4.5.1 and 4.5.2 of [#NandC2000]_).</p></div>\n\nMeasure\n-------\n\n`Measure theory <https://en.wikipedia.org/wiki/Measure_(mathematics)>`__ is a\nbranch of mathematics that studies things that are measurable---think length,\narea, or volume, but generalized to mathematical spaces and even higher\ndimensions. Loosely, the measure tells you about how \"stuff\" is distributed and\nconcentrated in a mathematical set or space. An intuitive way to understand\nmeasure is to think about a sphere. An arbitrary point on a sphere can be\nparametrized by three numbers---depending on what you're doing, you may use\nCartesian coordinates $(x, y, z)$, or it may be more convenient to use\nspherical coordinates $(\\rho, \\phi, \\theta)$.\n\nSuppose you wanted to compute the volume of a solid sphere with radius\n$r$.  This can be done by integrating over the three coordinates\n$\\rho, \\phi$, and $\\theta$. Your first thought here may be to simply\nintegrate each parameter over its full range, like so:\n\n\\begin{align}V = \\int_0^{r} \\int_0^{2\\pi} \\int_0^{\\pi} d\\rho~ d\\phi~ d\\theta = 2\\pi^2 r\\end{align}\n\nBut, we know that the volume of a sphere of radius $r$ is\n$\\frac{4}{3}\\pi r^3$, so what we got from this integral is clearly wrong!\nTaking the integral naively like this doesn't take into account the structure of\nthe sphere with respect to the parameters. For example, consider\ntwo small, infinitesimal elements of area with the same difference in\n$\\theta$ and $\\phi$, but at different values of $\\theta$:\n\n.. figure:: /demonstrations/haar_measure/spherical_int_dtheta.png\n    :align: center\n    :width: 50%\n\n    |\n\nEven though the differences $d\\theta$ and $d\\phi$ themselves are the\nsame, there is way more \"stuff\" near the equator of the sphere than there is\nnear the poles. We must take into account the value of $\\theta$ when\ncomputing the integral! Specifically, we multiply by the function\n$\\sin\\theta$---the properties of the $\\sin$ function mean that the\nmost weight will occur around the equator where $\\theta=\\pi/2$, and the\nleast weight near the poles where $\\theta=0$ and $\\theta=\\pi$.\n\nSimilar care must be taken for $\\rho$.  The contribution to volume of\nparts of the sphere with a large $\\rho$ is far more than for a small\n$\\rho$---we should expect the contribution to be proportional to\n$\\rho^2$, given that the surface area of a sphere of radius $r$ is\n$4\\pi r^2$.\n\nOn the other hand, for a fixed $\\rho$ and $\\theta$, the length of\nthe $d\\phi$ is the same all around the circle. If put all these facts\ntogether, we find that the actual expression for the integral should look like\nthis:\n\n\\begin{align}V = \\int_0^r \\int_0^{2\\pi} \\int_0^{\\pi} \\rho^2 \\sin \\theta~ d\\rho~ d\\phi~\n    d\\theta = \\frac{4}{3}\\pi r^3\\end{align}\n\nThese extra terms that we had to add to the integral, $\\rho^2 \\sin\n\\theta$, constitute the *measure*. The measure weights portions of the sphere\ndifferently depending on where they are in the space. While we need to know the\nmeasure to properly integrate over the sphere, knowledge of the measure also\ngives us the means to perform another important task, that of sampling points in\nthe space uniformly at random. We can't simply sample each parameter from the\nuniform distribution over its domain---as we experienced already, this doesn't\ntake into account how the sphere is spread out over space. The measure describes\nthe distribution of each parameter and gives a recipe for sampling them in order\nto obtain something properly uniform.\n\nThe Haar measure\n----------------\n\nOperations in quantum computing are described by unitary matrices.\nUnitary matrices, like points on a sphere, can be expressed in terms of a fixed\nset of coordinates, or parameters. For example, the most general single-qubit rotation\nimplemented in PennyLane (:class:`~.pennylane.Rot`) is expressed in terms of three\nparameters like so,\n\n\\begin{align}U(\\phi, \\theta, \\omega) = \\begin{pmatrix} e^{-i(\\phi + \\omega)/2}\n                        \\cos(\\theta/2) & -e^{i(\\phi - \\omega)/2} \\sin(\\theta/2)\n                        \\\\ e^{-i(\\phi - \\omega)/2} \\sin(\\theta/2) & e^{i(\\phi +\n                        \\omega)/2} \\cos(\\theta/2) \\end{pmatrix}.\\end{align}\n\nFor every dimension $N$, the unitary matrices of size $N \\times N$\nconstitute the *unitary group* $U(N)$. We can perform operations on\nelements of this group, such as apply functions to them, integrate over them, or\nsample uniformly over them, just as we can do to points on a sphere. When we do\nsuch tasks with respect to the sphere, we have to add the measure in order to\nproperly weight the different regions of space. The *Haar measure* provides the\nanalogous terms we need for working with the unitary group.\n\nFor an $N$-dimensional system, the Haar measure, often denoted by\n$\\mu_N$, tells us how to weight the elements of $U(N)$. For\nexample, suppose $f$ is a function that acts on elements of $U(N)$,\nand we would like to take its integral over the group. We must write this\nintegral with respect to the Haar measure, like so:\n\n\\begin{align}\\int_{V \\in U(N)} f(V) d\\mu_N(V).\\end{align}\n\nAs with the measure term of the sphere, $d\\mu_N$ itself can be broken down\ninto components depending on individual parameters.  While the Haar\nmeasure can be defined for every dimension $N$, the mathematical form gets\nquite hairy for larger dimensions---in general, an $N$-dimensional unitary\nrequires at least $N^2 - 1$ parameters, which is a lot to keep track of!\nTherefore we'll start with the case of a single qubit $(N=2)$, then show\nhow things generalize.\n\nSingle-qubit Haar measure\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe single-qubit case provides a particularly nice entry point because we can\ncontinue our comparison to spheres by visualizing single-qubit states on the\nBloch sphere. As expressed above, the measure provides a recipe for sampling\nelements of the unitary group in a properly uniform manner, given the structure\nof the group. One useful consequence of this is that it provides a method to\nsample quantum *states* uniformly at random---we simply generate Haar-random\nunitaries, and apply them to a fixed basis state such as $\\vert 0\\rangle$.\n\nWe'll see how this works in good time. First, we'll take a look at what happens\nwhen we ignore the measure and do things *wrong*. Suppose we sample quantum\nstates by applying unitaries obtained by the parametrization above, but sample\nthe angles $\\omega, \\phi$, and $\\theta$ from the flat uniform\ndistribution between $[0, 2\\pi)$ (fun fact: there is a measure implicit in\nthis kind of sampling too! It just has a constant value, because each point is\nequally likely to be sampled).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["import pennylane as qml\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# set the random seed\nnp.random.seed(42)\n\n# Use the mixed state simulator to save some steps in plotting later\ndev = qml.device('default.mixed', wires=1)\n\n@qml.qnode(dev)\ndef not_a_haar_random_unitary():\n    # Sample all parameters from their flat uniform distribution\n    phi, theta, omega = 2 * np.pi * np.random.uniform(size=3)\n    qml.Rot(phi, theta, omega, wires=0)\n    return qml.state()\n\nnum_samples = 2021\n\nnot_haar_samples = [not_a_haar_random_unitary() for _ in range(num_samples)]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In order to plot these on the Bloch sphere, we'll need to do one more\nstep, and convert the quantum states into Bloch vectors.\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["X = np.array([[0, 1], [1, 0]])\nY = np.array([[0, -1j], [1j, 0]])\nZ = np.array([[1, 0], [0, -1]])\n\n# Used the mixed state simulator so we could have the density matrix for this part!\ndef convert_to_bloch_vector(rho):\n    \"\"\"Convert a density matrix to a Bloch vector.\"\"\"\n    ax = np.trace(np.dot(rho, X)).real\n    ay = np.trace(np.dot(rho, Y)).real\n    az = np.trace(np.dot(rho, Z)).real\n    return [ax, ay, az]\n\nnot_haar_bloch_vectors = np.array([convert_to_bloch_vector(s) for s in not_haar_samples])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["With this done, let's find out where our \"uniformly random\" states ended up:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def plot_bloch_sphere(bloch_vectors):\n    \"\"\" Helper function to plot vectors on a sphere.\"\"\"\n    fig = plt.figure(figsize=(6, 6))\n    ax = fig.add_subplot(111, projection='3d')\n    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n\n    ax.grid(False)\n    ax.set_axis_off()\n    ax.view_init(30, 45)\n    ax.dist = 7\n\n    # Draw the axes (source: https://github.com/matplotlib/matplotlib/issues/13575)\n    x, y, z = np.array([[-1.5,0,0], [0,-1.5,0], [0,0,-1.5]])\n    u, v, w = np.array([[3,0,0], [0,3,0], [0,0,3]])\n    ax.quiver(x, y, z, u, v, w, arrow_length_ratio=0.05, color=\"black\", linewidth=0.5)\n\n    ax.text(0, 0, 1.7, r\"|0\u27e9\", color=\"black\", fontsize=16)\n    ax.text(0, 0, -1.9, r\"|1\u27e9\", color=\"black\", fontsize=16)\n    ax.text(1.9, 0, 0, r\"|+\u27e9\", color=\"black\", fontsize=16)\n    ax.text(-1.7, 0, 0, r\"|\u2013\u27e9\", color=\"black\", fontsize=16)\n    ax.text(0, 1.7, 0, r\"|i+\u27e9\", color=\"black\", fontsize=16)\n    ax.text(0,-1.9, 0, r\"|i\u2013\u27e9\", color=\"black\", fontsize=16)\n\n    ax.scatter(\n        bloch_vectors[:,0], bloch_vectors[:,1], bloch_vectors[:, 2], c='#e29d9e', alpha=0.3\n    )\n\nplot_bloch_sphere(not_haar_bloch_vectors)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You can see from this plot that even though our parameters were sampled from a\nuniform distribution, there is a noticeable amount of clustering around the poles\nof the sphere. Despite the input parameters being uniform, the output is very\nmuch *not* uniform. Just like the regular sphere, the measure is larger near\nthe equator, and if we just sample uniformly, we won't end up populating that\narea as much. To take that into account we will need to sample from the proper\nHaar measure, and weight the different parameters appropriately.\n\nFor a single qubit, the Haar measure looks much like the case of a sphere,\nminus the radial component. Intuitively, all qubit state vectors have length\n1, so it makes sense that this wouldn't play a role here. The parameter that\nwe will have to weight differently is $\\theta$, and in fact the\nadjustment in measure is identical to that we had to do with the polar axis of\nthe sphere, i.e., $\\sin \\theta$. In order to sample the $\\theta$\nuniformly at random in this context, we must sample from the distribution\n$\\hbox{Pr}(\\theta) = \\sin \\theta$. We can accomplish this by setting up\na custom probability distribution with \n`rv_continuous <https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.html#scipy.stats.rv_continuous>`__\nin ``scipy``.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["from scipy.stats import rv_continuous\n\nclass sin_prob_dist(rv_continuous):\n    def _pdf(self, theta):\n        # The 0.5 is so that the distribution is normalized\n        return 0.5 * np.sin(theta)\n\n# Samples of theta should be drawn from between 0 and pi\nsin_sampler = sin_prob_dist(a=0, b=np.pi)\n\n@qml.qnode(dev)\ndef haar_random_unitary():\n    phi, omega = 2 * np.pi * np.random.uniform(size=2) # Sample phi and omega as normal\n    theta = sin_sampler.rvs(size=1) # Sample theta from our new distribution\n    qml.Rot(phi, theta, omega, wires=0)\n    return qml.state()\n\nhaar_samples = [haar_random_unitary() for _ in range(num_samples)]\nhaar_bloch_vectors = np.array([convert_to_bloch_vector(s) for s in haar_samples])\n\nplot_bloch_sphere(haar_bloch_vectors)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We see that when we use the correct measure, our qubit states are now\nmuch better distributed over the sphere. Putting this information together,\nwe can now write the explicit form for the single-qubit Haar measure:\n\n\\begin{align}d\\mu_2 = \\sin \\theta d\\theta \\cdot d\\omega \\cdot d\\phi.\\end{align}\n\nShow me more math!\n~~~~~~~~~~~~~~~~~~\n\nWhile we can easily visualize the single-qubit case, this is no longer\npossible when we increase the number of qubits. Regardless, we can still\nobtain a mathematical expression for the Haar measure in arbitrary\ndimensions. In the previous section, we expressed the Haar measure in terms of\na set of parameters that can be used to specify the unitary group\n$U(2)$. Such a parametrization is not unique, and in fact there are\nmultiple ways to *factorize*, or decompose an $N$-dimensional unitary\noperation into a set of parameters.\n\nMany of these parametrizations come to us from the study of photonics.  Here,\narbitrary operations are broken down into elementary operations involving only\na few parameters which correspond directly to parameters of the physical\napparatus used to implement them (beamsplitters and phase shifts). Rather than\nqubits, such operations act on modes, or *qumodes*. They are expressed as\nelements of the $N$-dimensional `special unitary group\n<https://en.wikipedia.org/wiki/Special_unitary_group>`__. This group, written\nas $SU(N)$, is the continuous group consisting of all $N \\times N$\nunitary operations with determinant 1 (essentially like $U(N)$, minus\na potential global phase).\n\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Elements of $SU(N)$ and $U(N)$ can still be considered as\n    multi-qubit operations in the cases where $N$ is a power of 2, but\n    they must be translated from continuous-variable operations into qubit\n    operations. (In PennyLane, this can be done by feeding the unitaries to\n    the :class:`~.pennylane.QubitUnitary` operation directly. Alternatively,\n    one can use *quantum compilation* to express the operations as a sequence\n    of elementary gates such as Pauli rotations and CNOTs.)</p></div>\n\n.. admonition:: Tip\n\n   If you haven't had many opportunities to work in terms of qumodes, the\n   `Strawberry Fields documentation\n   <https://strawberryfields.ai/photonics/concepts/photonics.html>`__ is a\n   good starting point.\n\nFor example, we saw already above that for $N=2$, we can write\n\n\\begin{align}U(\\phi, \\theta, \\omega) = \\begin{pmatrix} e^{-i(\\phi + \\omega)/2}\n                       \\cos(\\theta/2) & -e^{i(\\phi - \\omega)/2} \\sin(\\theta/2)\n                       \\\\ e^{-i(\\phi - \\omega)/2} \\sin(\\theta/2) & e^{i(\\phi +\n                       \\omega)/2} \\cos(\\theta/2) \\end{pmatrix}.\\end{align}\n\n\nThis unitary can be factorized as follows: \n\n\\begin{align}U(\\phi, \\theta, \\omega) =\n       \\begin{pmatrix}\n         e^{-i\\omega/2} & 0 \\\\ 0 & e^{i\\omega/2}\n       \\end{pmatrix}\n       \\begin{pmatrix}\n         \\cos(\\theta/2) & -\\sin(\\theta/2) \\\\ \\sin(\\theta/2) & \\cos(\\theta/2)\n       \\end{pmatrix}\n      \\begin{pmatrix}\n         e^{-i\\phi/2} & 0 \\\\ 0 & e^{i\\phi/2}\n       \\end{pmatrix}\\end{align}\n\nThe middle operation is a beamsplitter; the other two operations are phase\nshifts.  We saw earlier that for $N=2$, $d\\mu_2 = \\sin\\theta\nd\\theta d\\omega d\\phi$---note how the parameter in the beamsplitter\ncontributes to the measure in a different way than those of the phase\nshifts. As mentioned above, for larger values of $N$ there are multiple\nways to decompose the unitary. Such decompositions rewrite elements in\n$SU(N)$ acting on $N$ modes as a sequence of operations acting\nonly on 2 modes, $SU(2)$, and single-mode phase shifts.  Shown below are\nthree examples [#deGuise2018]_, [#Clements2016]_, [#Reck1994]_:\n\n.. figure:: /demonstrations/haar_measure/unitaries.png\n   :align: center\n   :width: 95%\n\n\nIn these graphics, every wire is a different mode. Every box represents an\noperation on one or more modes, and the number in the box indicates the number\nof parameters.  The boxes containing a ``1`` are simply phase shifts on\nindividual modes. The blocks containing a ``3`` are $SU(2)$ transforms\nwith 3 parameters, such as the $U(\\phi, \\theta, \\omega)$ above. Those\ncontaining a ``2`` are $SU(2)$ transforms on pairs of modes with 2\nparameters, similar to the 3-parameter ones but with $\\omega = \\phi$.\n\nAlthough the decompositions all produce the same set of operations, their\nstructure and parametrization may have consequences in practice.  The first [#deGuise2018]_\nhas a particularly convenient form that leads to a recursive definition\nof the Haar measure. The decomposition is formulated recursively such that an\n$SU(N)$ operation can be implemented by sandwiching an $SU(2)$\ntransformation between two $SU(N-1)$ transformations, like so:\n\n|\n\n.. figure:: /demonstrations/haar_measure/sun.svg\n   :align: center\n   :width: 80%\n\n|\n\nThe Haar measure is then constructed recursively as a product of 3\nterms. The first term depends on the parameters in the first $SU(N-1)$\ntransformation; the second depends on the parameters in the lone $SU(2)$\ntransformation; and the third term depends on the parameters in the other\n$SU(N-1)$ transformation.\n\n$SU(2)$ is the \"base case\" of the recursion---we simply have the Haar measure\nas expressed above.\n\n|\n\n.. figure:: /demonstrations/haar_measure/su2_haar.svg\n   :align: center\n   :width: 25%\n\n|\n\nMoving on up, we can write elements of $SU(3)$ as a sequence of three\n$SU(2)$ transformations. The Haar measure $d\\mu_3$ then consists\nof two copies of $d\\mu_2$, with an extra term in between to take into\naccount the middle transformation.\n\n|\n\n.. figure:: /demonstrations/haar_measure/su3_haar.svg\n   :align: center\n   :width: 80%\n\n|\n\nFor $SU(4)$ and upwards, the form changes slightly, but still follows\nthe pattern of two copies of $d\\mu_{N-1}$ with a term in between.\n\n|\n\n.. figure:: /demonstrations/haar_measure/su4_premerge.svg\n   :align: center\n   :width: 90%\n\n|\n\nFor larger systems, however, the recursive composition allows for some of the\n$SU(2)$ transformations on the lower modes to be grouped. We can take\nadvantage of this and aggregate some of the parameters:\n\n|\n\n.. figure:: /demonstrations/haar_measure/su4_triangle_merge.svg\n   :align: center\n   :width: 100%\n\n|\n\nThis leads to one copy of $d\\mu_{N-1}$, which we'll denote as\n$d\\mu_{N-1}^\\prime$, containing only a portion of the full set of terms\n(as detailed in [#deGuise2018]_, this is called a *coset measure*).\n\n|\n\n.. figure:: /demonstrations/haar_measure/su4_haar.svg\n   :align: center\n   :width: 100%\n\n|\n\nPutting everything together, we have that\n\n\\begin{align}d\\mu_N = d\\mu_{N-1}^\\prime \\times \\sin \\theta_{N-1}\n   \\sin^{2(N-2)}\\left(\\frac{\\theta_{N-1}}{2}\\right) d\\theta_{N-1} d\\omega_{N-1} \\times d\\mu_{N-1}\\end{align}\n\nThe middle portion depends on the value of $N$, and the parameters\n$\\theta_{N-1}$ and $\\omega_{N-1}$ contained in the $(N-1)$'th\n$SU(N)$ transformation. This is thus a convenient, systematic way to\nconstruct the $N$-dimensional Haar measure for the unitary group. As a\nfinal note, even though unitaries can be parametrized in different ways, the\nunderlying Haar measure is *unique*. This is a consequence of it being an\ninvariant measure, as will be shown later.\n\nHaar-random matrices from the $QR$ decomposition\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nNice-looking math aside, sometimes you just need to generate a large number of\nhigh-dimensional Haar-random matrices. It would be very cumbersome to sample\nand keep track of the distributions of so many parameters; furthermore, the\nmeasure above requires you to parametrize your operations in a fixed way.\nThere is a much quicker way to perform the sampling by taking a (slightly\nmodified) `QR decomposition\n<https://en.wikipedia.org/wiki/QR_decomposition>`__ of complex-valued\nmatrices.  This algorithm is detailed in [#Mezzadri2006]_, and consists of the\nfollowing steps:\n\n1. Generate an $N \\times N$ matrix $Z$ with complex numbers $a+bi$\n   where both $a$ and $b$ are normally distributed with mean 0 and variance 1\n   (this is sampling from the distribution known as the *Ginibre ensemble*).\n2. Compute a QR decomposition $Z = QR$.\n3. Compute the diagonal matrix $\\Lambda = \\hbox{diag}(R_{ii}/|R_{ii}|)$.\n4. Compute $Q^\\prime = Q \\Lambda$, which will be Haar-random.\n\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["from numpy.linalg import qr\n\ndef qr_haar(N):\n    \"\"\"Generate a Haar-random matrix using the QR decomposition.\"\"\"\n    # Step 1\n    A, B = np.random.normal(size=(N, N)), np.random.normal(size=(N, N))\n    Z = A + 1j * B\n\n    # Step 2\n    Q, R = qr(Z)\n\n    # Step 3\n    Lambda = np.diag([R[i, i] / np.abs(R[i, i]) for i in range(N)])\n\n    # Step 4\n    return np.dot(Q, Lambda)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's check that this method actually generates Haar-random unitaries\nby trying it out for $N=2$ and plotting on the Bloch sphere.\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["@qml.qnode(dev)\ndef qr_haar_random_unitary():\n    qml.QubitUnitary(qr_haar(2), wires=0)\n    return qml.state()\n\nqr_haar_samples = [qr_haar_random_unitary() for _ in range(num_samples)]\nqr_haar_bloch_vectors = np.array([convert_to_bloch_vector(s) for s in qr_haar_samples])\nplot_bloch_sphere(qr_haar_bloch_vectors)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["As expected, we find our qubit states are distributed uniformly over the\nsphere.  This particular method is what's implemented in packages like\n``scipy``'s `unitary_group\n<https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.unitary_group.html>`__\nfunction.\n\nNow, it's clear that this method works, but it is also important to\nunderstand *why* it works.  Step 1 is fairly straightforward---the base of our\nsamples is a matrix full of complex values chosen from a typical\ndistribution. This isn't enough by itself, since unitary matrices also\nhave constraints---their rows and columns must be orthonormal.\nThese constraints are where step 2 comes in---the outcome of a generic\nQR decomposition consists of an *orthonormal* matrix $Q$, and and upper\ntriangular matrix $R$. Since our original matrix was complex-valued, we end\nup with a $Q$ that is in fact already unitary. But why not stop there? Why\ndo we then perform steps 3 and 4?\n\nSteps 3 and 4 are needed because, while the QR decomposition yields a unitary,\nit is not a unitary that is properly Haar-random. In [#Mezzadri2006]_, it is\nexplained that a uniform distribution over unitary matrices should also yield\na uniform distribution over the *eigenvalues* of those matrices, i.e., every\neigenvalue should be equally likely. Just using the QR decomposition out of\nthe box produces an *uneven* distribution of eigenvalues of the unitaries!\nThis discrepancy stems from the fact that the QR decomposition is not unique.\nWe can take any unitary diagonal matrix $\\Lambda$, and re-express the decomposition\nas $QR = Q\\Lambda \\Lambda^\\dagger R = Q^\\prime R^\\prime$. Step 3 removes this\nredundancy by fixing a $\\Lambda$ that depends on $R$, leading to a unique\nvalue of $Q^\\prime = Q \\Lambda$, and a uniform distribution of eigenvalues.\n\n.. admonition:: Try it!\n\n   Use the ``qr_haar`` function above to generate random unitaries and construct\n   a distribution of their eigenvalues. Then, comment out the lines for steps 3 and\n   4 and do the same---you'll find that the distribution is no longer uniform.\n   Check out reference [#Mezzadri2006]_ for additional details and examples.\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fun (and not-so-fun) facts\n--------------------------\n\nWe've now learned what the Haar measure is, and both an analytical and\nnumerical means of sampling quantum states and unitary operations uniformly at\nrandom. The Haar measure also has many neat properties that play a role in\nquantum computing.\n\nInvariance of the Haar measure\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nEarlier, we showed that the Haar measure is used when integrating functions over\nthe unitary group:\n\n\\begin{align}\\int_{V \\in U(N)} f(V) d\\mu_N(V).\\end{align}\n\nOne of the defining features of the Haar measure is that it is both left and\nright *invariant* under unitary transformations. That is,\n\n\\begin{align}\\int_{V \\in U(N)} f(\\color{red}{W}V) d\\mu_N(V) =  \\int_{V \\in U(N)} f(V\\color{red}{W}) d\\mu_N(V) =  \\int_{V \\in U(N)} f(V) d\\mu_N(V).\\end{align}\n\nThis holds true for *any* other $N\\times N$ unitary $W$! A\nconsequence of such invariance is that if $V$ is Haar-random, then so is\n$V^T,$ $V^\\dagger,$ and any product of another unitary matrix and\n$V$ (where the product may be taken on either side).\n\nAnother consequence of this invariance has to do with the structure of the entries\nthemselves: they must all come from the same distribution. This is because the\nmeasure remains invariant under permutations, since permutations are unitary---\nthe whole thing still has to be Haar random no matter how the entries are ordered,\nso all distributions must be the same.  The specific distribution is complex\nnumbers $a+bi$ where both $a$ and $b$ has mean 0 and variance\n$1/N$ [#Meckes2014]_ (so, much like Ginibre ensemble we used in the QR decomposition\nabove, but with a different variance and constraints due to orthonormality).\n\nConcentration of measure\n~~~~~~~~~~~~~~~~~~~~~~~~\n\nAn unfortunate (although interesting) property of the Haar measure is that it\nsuffers from the phenomenon of `concentration of measure\n<https://en.wikipedia.org/wiki/Concentration_of_measure>`__. Most of the\n\"stuff\" in the space concentrates around a certain area, and this gets worse\nas the size of the system increases. You can see the beginnings of by looking\nat the sphere. For the 3-dimensional sphere, we saw graphically how there is\nconcentration around the equator, and how the measure takes that into account\nwith the additional factor of $\\sin \\theta$. This property becomes\nincreasingly prominent for `higher-dimensional spheres\n<https://en.wikipedia.org/wiki/N-sphere>`__.\n\n.. important::\n\n   The concentration described here is not referring to what we witnessed\n   earlier on, when we sampled quantum states (points on the Bloch sphere)\n   incorrectly and found that they clustered around the poles. However, that\n   is not unrelated. Concentration of measure refers to where the measure\n   itself is concentrated, and which parts of the space should be more heavily\n   weighted. For the case of the sphere, it is the equatorial area, and when\n   we didn't sample properly and take that concentration into account, we\n   obtained an uneven distribution.\n\nLet's consider an $N$-dimensional unit sphere. Points on the sphere, or\nvectors in this space, are parametrized by $N-1$ real coordinates.\nSuppose we have some function $f$ that maps points on that sphere to\nreal numbers. Sample a point $x$ on that sphere from the uniform\nmeasure, and compute the value of $f(x)$. How close do you think the\nresult will be to the mean value of the function, $E[f]$, over the\nentire sphere?\n\nA result called `Levy's lemma\n<https://en.wikipedia.org/wiki/Concentration_of_measure#Concentration_on_the_sphere>`__\n[#Gerken2013]_, [#Hayden2006]_ expresses how likely it is that $f(x)$ is a specific\ndistance away from the mean. It states that, for an $x$ selected\nuniformly at random, the probability that $f(x)$ deviates from\n$E[f]$ by some amount $\\epsilon$ is bounded by:\n\n\\begin{align}\\hbox{Pr}(|f(x) - E[f]| \\ge \\epsilon) \\leq 2 \\exp\\left[-\\frac{N\\epsilon^2}{9\\pi^3 \\eta^2}\\right].\\end{align}\n\nA constraint on the function $f$ is that it must be `Lipschitz\ncontinuous <https://en.wikipedia.org/wiki/Lipschitz_continuity>`__, where\n$\\eta$ is the *Lipschitz constant* of the function. The important aspect\nhere is the likelihood of deviating significantly from the mean by an amount\n$\\epsilon$ decreases exponentially with $\\epsilon.$ Furthermore,\nincreasing the dimension $N$ also makes the deviation exponentially less\nlikely.\n\nNow, this result seems unrelated to quantum states---it concerns higher-\ndimensional spheres. However, recall that a quantum state vector is a complex\nvector whose squared values sum to 1, similar to vectors on a sphere. If you\n\"unroll\" a quantum state vector of dimension $N = 2^n$ by stacking its\nreal and complex parts, you end with a vector of length $2 \\cdot 2^{n}$\nwhich ends up behaving just like a unit vector on the sphere in this\ndimension. Given that measure concentrates on spheres, and quantum state\nvectors can be converted to vectors on spheres, functions on random quantum\nstates will also demonstrate concentration.\n\nThis is bad news! To do useful things in quantum computing, we need a lot of\nqubits. But the more qubits we have, the more our randomly sampled states will\nlook the same (specifically, random states will concentrate around the\nmaximally entangled state [#Hayden2006]_). This has important consequences for\nnear-term algorithms (as detailed in the next section), and any algorithm that\ninvolves uniform sampling of quantum states and operations.\n\nHaar measure and barren plateaus\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nSuppose you are venturing out to solve a new problem using an algorithm such\nas the :doc:`variational quantum eigensolver </demos/tutorial_vqe>`. A\ncritical component of such methods is the choice of :doc:`variational ansatz\n</glossary/circuit_ansatz>`. Having now learned a bit about the properties of\nthe Haar measure, you may think it would make sense to use this for the\nparametrization. Variational ansaetze are, after all, parametrized quantum\ncircuits, so why not choose an ansatz that corresponds directly to a\nparametrization for Haar-random unitaries?  The initial parameter selection\nwill give you a state in the Hilbert space uniformly at random. Then, since\nthis ansatz spans the entire Hilbert space, you're guaranteed to be able to\nrepresent the target ground state with your ansatz, and it should be able to\nfind it with no issue ... right?\n\nUnfortunately, while such an ansatz is extremely *expressive* (i.e., it is\ncapable of representing any possible state), these ansaetze actually suffer\nthe most from the barren plateau problem [#McClean2018]_, [#Holmes2021]_.\n:doc:`Barren plateaus </demos/tutorial_barren_plateaus>` are regions in the\ncost landscape of a parametrized circuit where both the gradient and its\nvariance approach 0, leading the optimizer to get stuck in a local minimum.\nThis was explored recently in the work of [#Holmes2021]_, wherein closeness to\nthe Haar measure was actually used as a metric for expressivity. The closer\nthings are to the Haar measure, the more expressive they are, but they are\nalso more prone to exhibiting barren plateaus.\n\n\n.. figure:: /demonstrations/haar_measure/holmes-costlandscapes.png\n   :align: center\n   :width: 50%\n\n   Image source: [#Holmes2021]_. A highly expressive ansatz that can access\n   much of the space of possible unitaries (i.e., an ansatz capable of\n   producing unitaries in something close to a Haar-random manner) is very\n   likely to have flat cost landscapes and suffer from the barren plateau\n   problem.\n\nIt turns out that the types of ansaetze know as *hardware-efficient ansaetze*\nalso suffer from this problem if they are \"random enough\" (this notion will be\nformalized in a future demo). It was shown in [#McClean2018]_ that this is a\nconsequence of the concentration of measure phenomenon described above. The\nvalues of gradients and variances can be computed for classes of circuits on\naverage by integrating with respect to the Haar measure, and it is shown that\nthese values decrease exponentially in the number of qubits, and thus huge\nswaths of the cost landscape are simply and fundamentally flat.\n\nConclusion\n----------\n\nThe Haar measure plays an important role in quantum computing---anywhere\nyou might be dealing with sampling random circuits, or averaging over\nall possible unitary operations, you'll want to do so with respect\nto the Haar measure.\n\nThere are two important aspects of this that we have yet to touch upon,\nhowever. The first is whether it is efficient to sample from the Haar measure---given\nthat the number of parameters to keep track of is exponential in the\nnumber of qubits, certainly not. But a more interesting question is do we\n*need* to always sample from the full Haar measure?  The answer to this is\n\"no\" in a very interesting way. Depending on the task at hand, you may be able\nto take a shortcut using something called a *unitary design*. In an upcoming\ndemo, we will explore the amazing world of unitary designs and their\napplications!\n\nReferences\n----------\n\n.. [#NandC2000]\n\n    M. A. Nielsen, and I. L. Chuang (2000) \"Quantum Computation and Quantum Information\",\n    Cambridge University Press.\n\n.. [#deGuise2018]\n\n    H. de Guise, O. Di Matteo, and L. L. S\u00e1nchez-Soto. (2018) \"Simple factorization\n    of unitary transformations\", `Phys. Rev. A 97 022328\n    <https://journals.aps.org/pra/abstract/10.1103/PhysRevA.97.022328>`__.\n    (`arXiv <https://arxiv.org/abs/1708.00735>`__)\n\n.. [#Clements2016]\n\n    W. R. Clements, P. C. Humphreys, B. J. Metcalf, W. S. Kolthammer, and\n    I. A. Walmsley (2016) \u201cOptimal design for universal multiport\n    interferometers\u201d, \\ `Optica 3, 1460\u20131465\n    <https://www.osapublishing.org/optica/fulltext.cfm?uri=optica-3-12-1460&id=355743>`__.\n    (`arXiv <https://arxiv.org/abs/1603.08788>`__)\n\n.. [#Reck1994]\n\n   M. Reck, A. Zeilinger, H. J. Bernstein, and P. Bertani (1994) \u201cExperimental\n   realization of any discrete unitary operator\u201d, `Phys. Rev. Lett.73, 58\u201361\n   <https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.73.58>`__.\n\n.. [#Mezzadri2006]\n\n    F. Mezzadri (2006) \"How to generate random matrices from the classical compact groups\".\n    (`arXiv <https://arxiv.org/abs/math-ph/0609050>`__)\n\n.. [#Meckes2014]\n\n    E. Meckes (2019) `\"The Random Matrix Theory of the Classical Compact Groups\"\n    <https://case.edu/artsci/math/esmeckes/Haar_book.pdf>`_, Cambridge University Press.\n\n.. [#Gerken2013]\n\n    M. Gerken (2013) \"Measure concentration: Levy's Lemma\"\n    (`lecture notes <http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.679.2560>`__).\n\n\n.. [#Hayden2006]\n\n    P. Hayden, D. W. Leung, and A. Winter (2006) \"Aspects of generic\n    entanglement\", `Comm. Math. Phys. Vol. 265, No. 1, pp. 95-117\n    <https://link.springer.com/article/10.1007%2Fs00220-006-1535-6>`__.\n    (`arXiv <https://arxiv.org/abs/quant-ph/0407049>`__)\n\n.. [#McClean2018]\n\n    J. R. McClean, S. Boixo, V. N. Smelyanskiy, R. Babbush, and H. Neven\n    (2018) \"Barren plateaus in quantum neural network training\n    landscapes\", `Nature Communications, 9(1)\n    <http://dx.doi.org/10.1038/s41467-018-07090-4>`__.\n    (`arXiv <https://arxiv.org/abs/1803.11173>`__)\n\n.. [#Holmes2021]\n\n    Z. Holmes, K. Sharma, M. Cerezo, and P. J. Coles (2021) \"Connecting ansatz\n    expressibility to gradient magnitudes and barren plateaus\". (`arXiv\n    <https://arxiv.org/abs/2101.02138>`__)\n\n\n\n"]}]}