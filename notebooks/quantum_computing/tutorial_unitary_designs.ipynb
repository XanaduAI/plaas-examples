{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["Unitary Designs\n===============\n\n\n\n\n\n*Author: PennyLane dev team. Posted: 7 Sept 2021. Last updated: 7 Sept\n2021.*\n\n> **Note**\n> \n> This demo is intended to be a sequel to the\n> [demo about the Haar measure](../quantum_computing/tutorial_haar_measure.ipynb). If you are not familiar with the Haar measure, we recommend\n> going through that demo first before exploring this one.\n\n\n\nTake a close look at the following mathematical object:\n\n![](https://pennylane.ai/qml/_images/fano_no_labels.svg)\n\n| \n\nThere are many things we can say about it: it consists of seven points\nand seven lines (the circle counts as a line); each line contains three\npoints, and each point is contained in three lines. Furthermore, any\npair of points occur together in exactly one line. This object, called\nthe [Fano plane](https://en.wikipedia.org/wiki/Fano_plane), is an\ninstance of a mathematical structure called a [projective\nplane](https://en.wikipedia.org/wiki/Projective_plane), which is just\none example of a [combinatorial\ndesign](https://en.wikipedia.org/wiki/Combinatorial_design). Designs are\nsets of objects, and groups of those objects, that satisfy certain\nbalance properties and symmetries. They have been studied for hundreds\nof years in a huge variety of contexts, from [error correcting\ncodes](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.50.5465),\nto [card\ngames](https://homepages.warwick.ac.uk/staff/D.Maclagan/papers/set.pdf),\nand even\n[agriculture](http://www-groups.mcs.st-and.ac.uk/~rab/histLShand.pdf).\nSo, what about quantum computing?\n\nDesigns are actually quite prevalent in quantum computing. You\\'ve\nalmost certainly come across one before, though you may not have\nrealized it. At the end of the Haar measure demo, we asked a very\nimportant question: \\\"do we always *need* to sample from the full Haar\nmeasure?\\\". The answer to this is \\\"no\\\", and the reasoning lies in the\nstudy of *unitary designs*.\n\nIn this demo, you\\'ll learn the definition of $t$-designs, what it means\nto generalize them to unitary $t$-designs, and you\\'ll see some\ncanonical examples of designs in quantum computing. You\\'ll also learn\nabout their connection with the Haar measure, what it means to *twirl* a\nquantum channel, and explore how to leverage 2-designs in PennyLane to\ncompute the average fidelity of a noisy channel. You will experience\ndirectly a situation where we can use a $t$-design as a shortcut over\nthe full Haar measure to greatly improve the efficiency of a task \ud83c\udf89.\n\nFrom spheres to unitary $t$-designs\n-----------------------------------\n\n### Spherical designs\n\nBefore diving into unitary designs, let\\'s look at the sphere for some\nintuition. Suppose we have a polynomial in $d$ variables, and we would\nlike to compute its average over the surface of a real, $d$-dimensional\nunit sphere, $S(R^d)$. We can do so by integrating that function over\nthe sphere (using the proper measure), but that would be a lot of\nparameters to keep track of.\n\nOne could alternatively approximate the average by sampling thousands of\npoints uniformly at random on the sphere, evaluating the function at\nthose points, and computing their average value. That will always work,\nand it will get us close, but it will not be exact.\n\nIn fact, both of those approaches may be overkill in some special\ncases\\-\\--if the terms in the polynomial have the same degree of at most\n$t$, you can compute the average **exactly** over the sphere using only\na small set of points rather than integrating over the entire sphere.\nThat set of points is called a spherical $t$-design. More formally,:\n\n> Definition\n> \n> Let $p_t: \\mathcal{S}(R^d)\\rightarrow R$ be a polynomial in $d$\n> variables, with all terms homogeneous in degree at most $t$. A set\n> $X = \\{x: x \\in \\mathcal{S}(R^d)\\}$ is a spherical $t$-design if\n> \n> $$\\frac{1}{|X|} \\sum_{x \\in X} p_t(x) = \\int_{\\mathcal{S}(R^d)} p_t (u) d\\mu(u)$$\n> \n> holds for all possible $p_t$, where $d\\mu$ is the uniform, normalized\n> spherical measure. A spherical $t$-design is also a $k$-design for all\n> $k < t$.\n\n\n\nNow this is a pretty abstract picture, so let\\'s consider the\n3-dimensional sphere. This definition tells us that if we want to take\nthe average of a polynomial over a sphere where all terms have the same\ndegree of at most 2, we can do so using a small, representative set of\npoints called a 2-design, rather than the whole sphere. Similarly, if\nall terms of the polynomial have the same degree of at most 3, we could\nuse a 3-design.\n\nBut what are these representative sets of points? Since we are using\nthese points as a stand-in for averaging over the whole sphere, we\\'d\nwant the points in the set to be distributed in a way that provides\nsufficient \\\"coverage\\\". In the 3-dimensional case, the vertices of some\nfamiliar solids form $t$-designs ,:\n\n![](https://pennylane.ai/qml/_images/shapes.svg)\n\n| \n\nWe see from these illustrations that spherical designs are sets of\n*evenly-spaced points*. As $t$ increases, the configurations become\nincreasingly sphere-like. Looking at this in a different way, the more\ncomplex a function becomes as its degree increases, the closer the\n$t$-design must be to a sphere; we need to evaluate the function at more\npoints in order to gain sufficient information when a function is\nvarying more quickly due to a higher degree. In 3 dimensions, we can\ncompute the average of a polynomial with degree 2 by evaluating it only\nat the points of a tetrahedron, despite the fact that it doesn\\'t look\nspherical at all. More complex functions require more points and thus\nmore intricate configurations for the design. Spherical designs exist\nfor all $t$ and dimension $d$. They are not always unique, and may have\nvarying numbers of points.\n\nTo show that this really works, let\\'s look at an explicit example.\nConsider the following polynomial in 3 variables:\n\n$$f(x, y, z) = x^4 - 4 x^3 y + y^2 z^2$$\n\nWe can compute the average value of $f$ by integrating over a unit\nsphere: the result is $4/15 \\approx 0.26667$. However, this integral is\nnon-trivial to evaluate by hand; the most straightforward way is to\nconvert to polar coordinates, and even then, it involves integrating\nfunctions with 4th and 5th powers of trigonometric functions.\n\nInstead, this is a case where we can leverage the fact that all terms in\nthe polynomial have degree 4, and compute the average exactly using only\na subset of points that form a 4-design. We choose a dodecahedron for\nconvenience; while this is actually a 5 design, it also forms a\n4-design, and is a more familiar shape than the 4-design depicted above.\n\nFirst, we define the set of points that comprise a dodecahedron:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["import numpy as np\n\n# The golden ratio\ng = (1 + np.sqrt(5)) / 2\n\n# A dodecahedron has 20 points\ndodecahedron = np.array([\n    # 8 of them form a cube within the sphere\n    [1, 1, 1], [1, 1, -1], [1, -1, 1], [1, -1, -1],\n    [-1, 1, 1], [-1, 1, -1], [-1, -1, 1], [-1, -1, -1],\n\n    # 4 of them form a rectangle within the y-z plane\n    [0, g, 1/g], [0, g, -1/g], [0, -g, 1/g], [0, -g, -1/g],\n\n    # 4 of them form a rectangle within the x-z plane\n    [1/g, 0, g], [1/g, 0, -g], [-1/g, 0, g], [-1/g, 0, -g],\n\n    # 4 of them form a rectangle within the x-y plane\n    [g, 1/g, 0],[g, -1/g, 0], [-g, 1/g, 0], [-g, -1/g, 0],\n])\n\n# Normalize the points so they all fit in the unit sphere\ndodecahedron = np.array(\n   [point / np.linalg.norm(point) for point in dodecahedron]\n)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we define our function and compute the average over the\ndodecahedron:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def f(x, y, z):\n    return (x ** 4) - 4 * (x ** 3) * y +  y ** 2 * z ** 2\n\ndodeca_average = np.mean([f(*point) for point in dodecahedron])\nprint(dodeca_average)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This is exactly the value we expect. What happens if we try to do this\nusing only a 3-design, the cube?\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# The first 8 points of the dodecahedron are a cube\ncube = dodecahedron[:8]\n\ncube_average = np.mean([f(*point) for point in cube])\nprint(cube_average)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This clearly differs from the true value. We need a design with $t=4$ or\nbetter in order to compute this average, and when such a design is\navailable, we may save significant computational time.\n\nUnitary designs\n===============\n\nWe\\'ve learned now that spherical designs are sets of evenly-spaced\npoints, and saw how they can be used as a shortcut to evaluate the\naverage of a polynomial up to a given degree $t$. However, there was\nnothing quantum about this; there weren\\'t even any complex numbers\ninvolved. A *unitary design* extends this concept from\nevenly-distributed points to evenly-distributed unitaries. More\nformally, instead of averaging polynomials over spheres, we consider\npolynomials that are functions of the entries of unitary matrices,.\n\n> Definition\n> \n> Let $P_{t,t}(U)$ be a polynomial with homogeneous degree at most $t$ in\n> $d$ variables in the entries of a unitary matrix $U$, and degree $t$ in\n> the complex conjugates of those entries. A unitary $t$-design is a set\n> of $K$ unitaries $\\{U_k\\}$ such that\n> \n> $$\\frac{1}{K} \\sum_{k=1}^{K} P_{t,t}(U_k) = \\int_{\\mathcal{U}(d)}\n> P_{t,t} (U) d\\mu(U)$$\n> \n> holds for all possible $P_{t,t}$, and where $d\\mu$ is the uniform *Haar\n> measure*.\n\n\n\nWe stress again that this expression is **exact**. The unitaries in a\nunitary design are a representative set of points that are \\\"evenly\nspaced\\\" across the unitary group. With just a subset of the full group,\nwe can evaluate complex expressions that would be otherwise intractable.\n\nA surprising result about unitary designs is that they exist for all\npossible combinations of $t$ and $d$. There are some known lower bounds\nfor the number of unitaries required; for example, a 2-design in\ndimension $d$ has at least $d^4 - 2d^2 + 2$ elements, . However,\nactually finding the sets (and in particular, finding ones with minimal\nsize), is a challenging problem, though very recently some constructions\nhave been put forward.\n\n> Fun fact\n> \n> Applying the elements of a unitary design to a fixed pure state produces\n> a set of vectors that form a *complex projective design*. These are much\n> like spherical designs, but they live in a complex vector space. If\n> you\\'ve ever studied the characterization of quantum systems, you may\n> have come across some special sets of measurements called mutually\n> unbiased bases (MUBs), or symmetric, informationally complete positive\n> operator valued measurements (SIC-POVMs). Both of these sets of vectors\n> are complex projective 2-designs.\n> \n> ![The vectors of the simplest SIC-POVM in dimension 2, plotted on a\n> Bloch\n> sphere.](https://pennylane.ai/qml/_images/sic-povm.svg)\n\n\n\nUnitary $t$-designs in action\n-----------------------------\n\nUnitary designs come into play in applications that require\nrandomization, or sampling of random unitaries\\-\\--essentially, they can\nbe used as a stand-in for the Haar measure. The way in which the\nunitaries are used in the application may place restrictions on the\nvalue of $t$ that is required; arguably the most common is the unitary\n2-design.\n\nWhile in general unitary designs are hard to construct, there are well\nknown results for unitary 1-, 2-, and 3-designs based on familiar\nobjects in quantum computing. Before we see what those are, let\\'s\nexplore an important use case.\n\nAverage fidelity\n================\n\nA key application of unitary 2-designs is benchmarking quantum\noperations. Suppose we have a noisy quantum channel $\\Lambda$ that\nshould perform something close to the unitary operation $V$. What can we\nsay about the performance of this channel?\n\nOne metric of interest is the *fidelity*. Consider the state\n$|0\\rangle$. In an ideal case, we apply $V$ and obtain $V|0\\rangle$. But\napplying the channel $\\Lambda$ gives us something a little different.\nSince it\\'s noisy, we must consider the state as a density matrix. The\naction of $\\Lambda$ on our starting state is\n$\\Lambda(|0\\rangle \\langle 0|)$. If $\\Lambda$ was perfect, then\n$\\Lambda(|0\\rangle \\langle 0|) = V|0\\rangle \\langle\n0|V^\\dagger$, and the fidelity is\n\n$$F(\\Lambda, V) = \\langle 0 | V^\\dagger \\cdot \\Lambda(|0\\rangle \\langle 0|) \\cdot V|0\\rangle = 1.$$\n\nIn reality, $\\Lambda$ is not going to implement $V$ perfectly, and\n$F < 1$. More importantly though, all we\\'ve computed so far is the\nfidelity when the initial state is $|0\\rangle$. What if the initial\nstate is something different? What is the fidelity *on average*?\n\nTo compute an average fidelity, we must do so with respect to the full\nset of Haar-random states. We usually generate random states by applying\na Haar-random unitary $U$ to $|0\\rangle$. Thus to compute the average\nover all such $U$ we must evaluate\n\n$$\\bar{F}(\\Lambda, V) = \\int_{\\mathcal{U}} d\\mu(U) \\langle 0 | U^\\dagger V^\\dagger \\Lambda(U |0\\rangle \\langle 0| U^\\dagger) V U |0\\rangle.$$\n\nThis is known as *twirling* the channel $\\Lambda$. Computing the average\nfidelity in this way would be a nightmare\\-\\--we\\'d have to compute the\nfidelity with respect to an infinite number of states!\n\nHowever, consider the expression in the integral above. We have an inner\nproduct involving two instances of $U$, and two instances of\n$U^\\dagger$. This means that the expression is a polynomial of degree 2\nin both the elements of $U$ and its complex conjugates\\-\\--this matches\nexactly the definition of a unitary 2-design. This means that if we can\nfind a set of $K$ unitaries that form a 2-design, we can compute the\naverage fidelity using only a finite set of initial states:\n\n$$\\frac{1}{K} \\sum_{j=1}^K \\langle 0 | U_j^\\dagger V^\\dagger \\Lambda(U_j |0\\rangle \\langle 0|\nU_j^\\dagger) V^\\dagger U_j |0\\rangle = \\int_{\\mathcal{U}} d\\mu(U) \\langle 0\n| U^\\dagger V^\\dagger \\Lambda(U |0\\rangle \\langle 0| U^\\dagger) V U |0\\rangle$$\n\nThis is great, but a question remains: what is the representative set of\nunitaries?\n\nThe Clifford group\n==================\n\nA beautiful result in quantum computing is that some special groups you\nmay already be familiar with are unitary designs:\n\n-   the Pauli group forms a unitary 1-design, and\n-   the Clifford group forms a unitary 3-design.\n\nBy the definition of designs, this means the Clifford group is also a\n1-and 2-design.\n\nThe $n$-qubit Pauli group, $\\mathcal{P}(n)$, is the set of all tensor\nproducts of Pauli operations $X$, $Y$, $Z$, and $I$. The $n$-qubit\nClifford group, $\\mathcal{C}(n)$, is the *normalizer* of the Pauli\ngroup. In simpler terms, the Clifford group is the set of operations\nthat send Paulis to Paulis (up to a phase) under conjugation i.e.,\n\n$$C P C^\\dagger = \\pm P^\\prime, \\quad \\forall P, P^\\prime \\in \\mathcal{P}(n), \\quad C \\in \\mathcal{C}(n).$$\n\nThe Clifford group has some profoundly interesting properties and\ncountless uses across quantum computing, from circuit compilation to\nerror correcting codes. For a single qubit, the group is built from just\ntwo operations. One is the Hadamard:\n\n$$H X H^\\dagger = Z, \\quad H Y H^\\dagger = -Y, \\quad H Z H^\\dagger = X.$$\n\nThis clearly maps Paulis to Paulis (up to a phase). The other is the\nphase gate $S$:\n\n$$S X S^\\dagger = Y, \\quad S Y S^\\dagger = -X, \\quad S Z S^\\dagger = Z.$$\n\nIf both $H$ and $S$ map Paulis to Paulis, then products of them do as\nwell. In group theory terms, the single-qubit Clifford group is\ngenerated by $H$ and $S$. For example, consider the action of $HS$:\n\n$$(HS) X (HS)^\\dagger = -Y, \\quad (HS) Y (HS)^\\dagger = -Z, \\quad (HS) Z (HS)^\\dagger = X.$$\n\nSince $Y = iXZ$, it is enough to specify Clifford operations by how they\nact on $X$ and $Z$. For a particular Clifford, there are 6 possible ways\nit can transform $X$, namely $\\pm X, \\pm Y$, or $\\pm Z$. Once that is\ndetermined, there are four remaining options for the transformation of\n$Z$, leading to 24 elements total.\n\nIt takes some work, but you can take combinations of $H$ and $S$ and\nevaluate their action on $X$ and $Z$ (or look at their matrix\nrepresentations) until you find all 24 unique elements. The results of\nthis endeavour are expressed below as strings:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["single_qubit_cliffords = [\n '',\n 'H', 'S',\n 'HS', 'SH', 'SS',\n 'HSH', 'HSS', 'SHS', 'SSH', 'SSS',\n 'HSHS', 'HSSH', 'HSSS', 'SHSS', 'SSHS',\n 'HSHSS', 'HSSHS', 'SHSSH', 'SHSSS', 'SSHSS',\n 'HSHSSH', 'HSHSSS', 'HSSHSS'\n]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To see for yourself how this set of unitaries is evenly distributed, try\napplying each of the Cliffords to the initial state $|0\\rangle$, and\nplot the resulting states on the Bloch sphere. You\\'ll find they are\nsymmetric and evenly spaced; in fact, they are all eigenstates of $X$,\n$Y$, and $Z$. Furthermore, under the full group action, the result is\nbalanced in the sense that each eigenstate is obtained the same number\nof times.\n\nThe multi-qubit Clifford group can also be specified by only a small set\nof generators (in fact, only one more than is needed for the\nsingle-qubit case). Together, $H$, $S$, and CNOT (on every possible\nqubit or pair of qubits) generate the $n$-qubit group. Be careful\nthough\\-\\--the size of the group increases exponentially. The 2-qubit\ngroup alone has 11520 elements! The size can be worked out in a manner\nanalogous to that we used above in the single qubit case: by looking at\nthe combinatorics of the possible ways the gates can map Paulis with\nonly $X$ and $Z$ to other Paulis.\n\nAn experiment\n=============\n\nThe whole idea of unitary designs may sound too good to be true. Can we\n*really* compute the exact average fidelity using just 24 operations? In\nthis section, we put them to the test: we\\'ll compute the average\nfidelity of an operation first with experiments using a large but finite\namount of Haar-random unitaries, and then again with only the Clifford\ngroup.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["import pennylane as qml\n\n# Scipy allows us to sample Haar-random unitaries directly\nfrom scipy.stats import unitary_group\n\n# set the random seed\nnp.random.seed(42)\n\n# Use the mixed state simulator\ndev = qml.device(\"default.mixed\", wires=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let\\'s set up a noisy quantum channel. To keep things simple, assume it\nconsists of applying `SX`,\nthe square-root of $X$ gate, followed by a few different types of noise.\nFirst, write a quantum function for our ideal experiment:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def ideal_experiment():\n    qml.SX(wires=0)\n    return qml.state()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Next, we apply some noise. We do so by making use of a relatively new\nfeature in PennyLane called [quantum function\ntransforms](https://pennylane.readthedocs.io/en/latest/code/qml_transforms.html).\nSuch transforms work by modifying the underlying, low-level quantum\ntapes which queue the quantum operations. Suppose the noisy channel is\ncomposed of the following:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def noisy_operations(damp_factor, depo_factor, flip_prob):\n    qml.AmplitudeDamping(damp_factor, wires=0)\n    qml.DepolarizingChannel(depo_factor, wires=0)\n    qml.BitFlip(flip_prob, wires=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let\\'s create a transform that applies this noise to any quantum\nfunction *after* the original operations, but before the measurements.\nWe use the convenient\n`qfunc_transform()`\ndecorator:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["@qml.qfunc_transform\ndef apply_noise(tape, damp_factor, depo_factor, flip_prob):\n    # Apply the original operations\n    for op in tape.operations:\n        qml.apply(op)\n\n    # Apply the noisy sequence\n    noisy_operations(damp_factor, depo_factor, flip_prob)\n\n    # Apply the original measurements\n    for m in tape.measurements:\n        qml.apply(m)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can now apply this transform to create a noisy version of our ideal\nquantum function:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# The strengths of various types of noise\ndamp_factor = 0.02\ndepo_factor = 0.02\nflip_prob = 0.01\n\nnoisy_experiment = apply_noise(damp_factor, depo_factor, flip_prob)(ideal_experiment)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The last part of the experiment involves applying a random unitary\nmatrix before all the operations, and its inverse right before the\nmeasurements. We can write another transform here to streamline this\nprocess:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["@qml.qfunc_transform\ndef conjugate_with_unitary(tape, matrix):\n    qml.QubitUnitary(matrix, wires=0)\n\n    for op in tape.operations:\n        qml.apply(op)\n\n    qml.QubitUnitary(matrix.conj().T, wires=0)\n\n    for m in tape.measurements:\n        qml.apply(m)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Finally, in order to perform a comparison, we need a function to compute\nthe [fidelity](https://en.wikipedia.org/wiki/Fidelity_of_quantum_states)\ncompared to the ideal operation.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["from scipy.linalg import sqrtm\n\ndef fidelity(rho, sigma):\n    # Inputs rho and sigma are density matrices\n    sqrt_sigma = sqrtm(sigma)\n    fid = np.trace(sqrtm(sqrt_sigma @ rho @ sqrt_sigma))\n    return fid.real"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let\\'s now compute the average fidelity, averaging over 50000\nHaar-random unitaries:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["n_samples = 50000\n\nfidelities = []\n\nfor _ in range(n_samples):\n    # Select a Haar-random unitary\n    U = unitary_group.rvs(2)\n\n    # Apply transform to construct the ideal and noisy quantum functions\n    conjugated_ideal_experiment = conjugate_with_unitary(U)(ideal_experiment)\n    conjugated_noisy_experiment = conjugate_with_unitary(U)(noisy_experiment)\n\n    # Use the functions to create QNodes\n    ideal_qnode = qml.QNode(conjugated_ideal_experiment, dev)\n    noisy_qnode = qml.QNode(conjugated_noisy_experiment, dev)\n\n    # Execute the QNodes\n    ideal_state = ideal_qnode()\n    noisy_state = noisy_qnode()\n\n    # Compute the fidelity\n    fidelities.append(fidelity(ideal_state, noisy_state))\n\nfid_mean = np.mean(fidelities)\nprint(f\"Mean fidelity = {fid_mean}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now let\\'s repeat the procedure using only Clifford group elements.\nFirst, we write a quantum function that performs a Clifford operation\n(or its inverse) based on its string representation.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def apply_single_clifford(clifford_string, inverse=False):\n    for gate in clifford_string:\n        if gate == 'H':\n            qml.Hadamard(wires=0)\n        else:\n            sign = -1 if inverse else 1\n            qml.PhaseShift(sign * np.pi/2, wires=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Next, we write a transform that applies a Clifford in the context of the\nfull experiment, i.e., apply the Clifford, then the operations, followed\nby the inverse of the Clifford.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["@qml.qfunc_transform\ndef conjugate_with_clifford(tape, clifford_string):\n    apply_single_clifford(clifford_string, inverse=False)\n\n    for op in tape.operations:\n        qml.apply(op)\n\n    apply_single_clifford(clifford_string, inverse=True)\n\n    for m in tape.measurements:\n        qml.apply(m)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You may have noticed this transform has exactly the same form as\n`conjugate_with_unitary` from above. Only the input type has changed,\nsince the application of Cliffords here is specified by their string\nrepresentation.\n\nIt\\'s now time to run the experiments:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["fidelities = []\n\nfor C in single_qubit_cliffords:\n    conjugated_ideal_experiment = conjugate_with_clifford(C)(ideal_experiment)\n    conjugated_noisy_experiment = conjugate_with_clifford(C)(noisy_experiment)\n\n    ideal_qnode = qml.QNode(conjugated_ideal_experiment, dev)\n    noisy_qnode = qml.QNode(conjugated_noisy_experiment, dev)\n\n    ideal_state = ideal_qnode()\n    noisy_state = noisy_qnode()\n\n    fidelities.append(fidelity(ideal_state, noisy_state))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let\\'s see how our results compare to the earlier simulation:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["clifford_fid_mean = np.mean(fidelities)\n\nprint(f\"Haar-random mean fidelity = {fid_mean}\")\nprint(f\"Clifford mean fidelity    = {clifford_fid_mean}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Incredible \ud83e\udd2f \ud83e\udd2f \ud83e\udd2f We were able to compute the average fidelity using only\n24 experiments. Furthermore, the mean fidelity obtained from the\nClifford experiments is **exact**; even with 50000 Haar-random\nexperiments, we see deviations starting a few decimal places in.\nConsider the resources that would be saved if you were actually\nimplementing this in a lab! It\\'s not hard to see why the Clifford group\nplays such an important role in characterization procedures.\n\nConclusion\n==========\n\nIn this demo, we\\'ve barely scratched the surface of designs and their\napplications in quantum computing. While benchmarking is a key\napplication area, there are many others. The Pauli group as a unitary\n1-design has applications in the construction of private quantum\nchannels[^1]. *Approximate* unitary $t$-designs (where the equality in\nthe definition is replaced by approximately equal up to some finite\nprecision) are also of interest, as there ways to construct them that\nare more efficient than those of exact designs[^2]. In particular, it\nhas been shown that approximate complex projective 4-designs have\napplications to the state discrimination problem[^3].\n\nFurthermore, unitary designs are not the only designs that you\\'ll\nencounter in quantum computing. The familiar Hadamard gate is just a\n2-dimensional example of a broader family of *Hadamard designs*, on\nwhich there has been extensive research[^4]. Some sets of [mutually\northogonal Latin\nsquares](https://en.wikipedia.org/wiki/Mutually_orthogonal_Latin_squares)\nhave a direct correspondence with mutually unbiased bases, which are\noptimal quantum measurements[^5], as well as complex projective designs;\nand Latin squares themselves have direct correspondence with affine and\nprojective planes, bringing us full circle back to the Fano plane from\nwhich we began.\n\n![An affine plane, Hadamard matrix, and a depiction of mutually\northogonal Latin\nsquares.](https://pennylane.ai/qml/_images/affine-latin.svg)\n\nReferences\n==========\n\n[^1]: A. Ambainis, M. Mosca, A. Tapp, and R. de Wolf (2000) *Private\n    Quantum Channels*. Proc. 41st FOCS, 547-553.\n    [(PDF)](https://homepages.cwi.nl/~rdewolf/publ/qc/AMTW00.pdf).\n\n[^2]: C. Dankert, R. Cleve, J. Emerson, and E. Levine (2009) *Exact and\n    Approximate Unitary 2-Designs: Constructions and Applications.*\n    Phys. Rev. A 80, 012304.\n    [(arXiv)](https://arxiv.org/abs/quant-ph/0606161).\n\n[^3]: A. Ambainis and J. Emerson (2007) *Quantum t-designs: t-wise\n    independence in the quantum world.* Twenty-Second Annual IEEE\n    Conference on Computational Complexity 129-140.\n    [(arXiv)](https://arxiv.org/abs/quant-ph/0701126).\n\n[^4]: J. Seberry and M. Yamada (1992) *Hadamard matrices, sequences, and\n    block designs.* Contemporary Design Theory \\-- A Collection of\n    Surveys (D. J. Stinson and J. Dinitz, Eds.), John Wiley and Sons,\n    431-560. [(PDF)](http://mathscinet.ru/files/YamadaSeberry1992.pdf).\n\n[^5]: M. Gaeta, O. Di Matteo, A. B. Klimov, and H. de Guise (2014)\n    *Discrete phase-space approach to mutually orthogonal Latin\n    squares*. J. Phys. A: Math. Theor. 47 (43) 435303.\n    [(arXiv)](https://arxiv.org/abs/1408.6742).\n"]}], "metadata": {"kernelspec": {"display_name": "PennyLane", "language": "python", "name": "pennylane"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.12"}}, "nbformat": 4, "nbformat_minor": 0}