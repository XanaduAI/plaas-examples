{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. role:: html(raw)\n   :format: html\n\nUnitary Designs\n===============\n\n.. meta::\n    :property=\"og:description\": Learn about designs and their uses in quantum computing.\n\n    :property=\"og:image\": https://pennylane.ai/qml/_images/fano.png\n\n.. related::\n\n    tutorial_haar_measure Understanding the Haar measure\n\n*Author: PennyLane dev team. Posted: 7 Sept 2021. Last updated: 7 Sept 2021.*\n\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This demo is intended to be a sequel to the\n   :doc:`demo about the Haar measure </demos/tutorial_haar_measure>`.\n   If you are not familiar with the Haar measure, we recommend going through\n   that demo first before exploring this one.</p></div>\n\nTake a close look at the following mathematical object:\n\n.. figure:: /demonstrations/unitary_designs/fano_no_labels.svg\n   :align: center\n   :width: 30%\n\n|\n\nThere are many things we can say about it: it consists of seven points and seven\nlines (the circle counts as a line); each line contains three points, and each\npoint is contained in three lines. Furthermore, any pair of points occur\ntogether in exactly one line. This object, called the `Fano plane\n<https://en.wikipedia.org/wiki/Fano_plane>`__, is an instance of a mathematical\nstructure called a `projective plane\n<https://en.wikipedia.org/wiki/Projective_plane>`__, which is just one example\nof a `combinatorial design\n<https://en.wikipedia.org/wiki/Combinatorial_design>`__. Designs are sets of\nobjects, and groups of those objects, that satisfy certain balance properties\nand symmetries. They have been studied for hundreds of years in a huge variety\nof contexts [#Handbook]_, from `error correcting codes\n<http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.50.5465>`__, to `card\ngames <https://homepages.warwick.ac.uk/staff/D.Maclagan/papers/set.pdf>`__, and\neven `agriculture\n<http://www-groups.mcs.st-and.ac.uk/~rab/histLShand.pdf>`__. So, what about\nquantum computing?\n\nDesigns are actually quite prevalent in quantum computing. You've almost\ncertainly come across one before, though you may not have realized it. At the\nend of the Haar measure demo, we asked a very important question: \"do we always\n*need* to sample from the full Haar measure?\". The answer to this is \"no\", and\nthe reasoning lies in the study of *unitary designs*.\n\nIn this demo, you'll learn the definition of $t$-designs, what it means to\ngeneralize them to unitary $t$-designs, and you'll see some canonical\nexamples of designs in quantum computing. You'll also learn about their\nconnection with the Haar measure, what it means to *twirl* a quantum channel,\nand explore how to leverage 2-designs in PennyLane to compute the average\nfidelity of a noisy channel. You will experience directly a situation where we can\nuse a $t$-design as a shortcut over the full Haar measure to greatly improve\nthe efficiency of a task \ud83c\udf89.\n\n\nFrom spheres to unitary $t$-designs\n-----------------------------------------\n\nSpherical designs\n^^^^^^^^^^^^^^^^^\n\nBefore diving into unitary designs, let's look at the sphere for some\nintuition.  Suppose we have a polynomial in $d$ variables, and we would\nlike to compute its average over the surface of a real, $d$-dimensional\nunit sphere, $S(R^d)$. We can do so by integrating that function over the\nsphere (using the proper measure), but that would be a lot of parameters to\nkeep track of. \n\nOne could alternatively approximate the average by sampling thousands of points\nuniformly at random on the sphere, evaluating the function at those points, and\ncomputing their average value. That will always work, and it will get us close,\nbut it will not be exact.\n\nIn fact, both of those approaches may be overkill in some special cases---if the\nterms in the polynomial have the same degree of at most $t$, you can\ncompute the average **exactly** over the sphere using only a small set of points\nrather than integrating over the entire sphere.  That set of points is called a\nspherical $t$-design. More formally [#Handbook]_, [#Delsarte]_:\n\n.. admonition:: Definition\n    :class: defn\n\n    Let $p_t: \\mathcal{S}(R^d)\\rightarrow R$ be a polynomial in $d$\n    variables, with all terms homogeneous in degree at most $t$. A\n    set $X = \\{x: x \\in \\mathcal{S}(R^d)\\}$ is a spherical $t$-design if\n\n    .. math::\n\n        \\frac{1}{|X|} \\sum_{x \\in X} p_t(x) = \\int_{\\mathcal{S}(R^d)} p_t (u) d\\mu(u)\n\n    holds for all possible $p_t$, where $d\\mu$ is the uniform,\n    normalized spherical measure. A spherical $t$-design is also a\n    $k$-design for all $k < t$.\n\n\n\nNow this is a pretty abstract picture, so let's consider the 3-dimensional\nsphere. This definition tells us that if we want to take the average of a\npolynomial over a sphere where all terms have the same degree of at most 2, we\ncan do so using a small, representative set of points called a 2-design,\nrather than the whole sphere. Similarly, if all terms of the polynomial have the\nsame degree of at most 3, we could use a 3-design. \n\nBut what are these representative sets of points?  Since we are using these\npoints as a stand-in for averaging over the whole sphere, we'd want the points\nin the set to be distributed in a way that provides sufficient \"coverage\". In\nthe 3-dimensional case, the vertices of some familiar solids form $t$-designs\n[#Handbook]_, [#sph4design]_:\n\n.. figure:: /demonstrations/unitary_designs/shapes.svg\n   :align: center\n   :width: 80%\n\n|\n\nWe see from these illustrations that spherical designs are sets of\n*evenly-spaced points*. As $t$ increases, the configurations become\nincreasingly sphere-like. Looking at this in a different way, the more complex a\nfunction becomes as its degree increases, the closer the $t$-design must\nbe to a sphere; we need to evaluate the function at more points in order to gain\nsufficient information when a function is varying more quickly due to a higher\ndegree. In 3 dimensions, we can compute the average of a polynomial with degree\n2 by evaluating it only at the points of a tetrahedron, despite the fact that it\ndoesn't look spherical at all. More complex functions require more points\nand thus more intricate configurations for the design.  Spherical designs exist\nfor all $t$ and dimension $d$ [#Handbook]_. They are not always\nunique, and may have varying numbers of points.\n\nTo show that this really works, let's look at an explicit example. Consider the\nfollowing polynomial in 3 variables:\n\n\\begin{align}f(x, y, z) = x^4 - 4 x^3 y + y^2 z^2\\end{align}\n\nWe can compute the average value of $f$ by integrating over a unit sphere:\nthe result is $4/15 \\approx 0.26667$. However, this integral is\nnon-trivial to evaluate by hand; the most straightforward way is to convert to\npolar coordinates, and even then, it involves integrating functions with 4th and\n5th powers of trigonometric functions.\n\nInstead, this is a case where we can leverage the fact that all terms in the\npolynomial have degree 4, and compute the average exactly using only a subset of\npoints that form a 4-design. We choose a dodecahedron for convenience; while\nthis is actually a 5 design, it also forms a 4-design, and is a more familiar\nshape than the 4-design depicted above.\n\nFirst, we define the set of points that comprise a dodecahedron:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["import numpy as np\n\n# The golden ratio\ng = (1 + np.sqrt(5)) / 2\n\n# A dodecahedron has 20 points\ndodecahedron = np.array([\n    # 8 of them form a cube within the sphere\n    [1, 1, 1], [1, 1, -1], [1, -1, 1], [1, -1, -1],\n    [-1, 1, 1], [-1, 1, -1], [-1, -1, 1], [-1, -1, -1],\n\n    # 4 of them form a rectangle within the y-z plane\n    [0, g, 1/g], [0, g, -1/g], [0, -g, 1/g], [0, -g, -1/g],\n\n    # 4 of them form a rectangle within the x-z plane\n    [1/g, 0, g], [1/g, 0, -g], [-1/g, 0, g], [-1/g, 0, -g],\n\n    # 4 of them form a rectangle within the x-y plane\n    [g, 1/g, 0],[g, -1/g, 0], [-g, 1/g, 0], [-g, -1/g, 0],\n])\n\n# Normalize the points so they all fit in the unit sphere\ndodecahedron = np.array(\n   [point / np.linalg.norm(point) for point in dodecahedron]\n)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we define our function and compute the average over the dodecahedron:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def f(x, y, z):\n    return (x ** 4) - 4 * (x ** 3) * y +  y ** 2 * z ** 2\n\ndodeca_average = np.mean([f(*point) for point in dodecahedron])\nprint(dodeca_average)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This is exactly the value we expect. What happens if we try to do this using\nonly a 3-design, the cube?\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# The first 8 points of the dodecahedron are a cube\ncube = dodecahedron[:8]\n\ncube_average = np.mean([f(*point) for point in cube])\nprint(cube_average)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This clearly differs from the true value. We need a design with $t=4$\nor better in order to compute this average, and when such a design is\navailable, we may save significant computational time.\n\nUnitary designs\n^^^^^^^^^^^^^^^\n\nWe've learned now that spherical designs are sets of evenly-spaced points, and\nsaw how they can be used as a shortcut to evaluate the average of a\npolynomial up to a given degree $t$. However, there was nothing quantum\nabout this; there weren't even any complex numbers involved. A *unitary\ndesign* extends this concept from evenly-distributed points to\nevenly-distributed unitaries.  More formally, instead of averaging polynomials\nover spheres, we consider polynomials that are functions of the entries of\nunitary matrices [#Dankert]_, [#Gross]_.\n\n.. admonition:: Definition\n    :class: defn\n\n    Let $P_{t,t}(U)$ be a polynomial with homogeneous degree at most $t$ in\n    $d$ variables in the entries of a unitary matrix $U$, and degree\n    $t$ in the complex conjugates of those entries. A unitary\n    $t$-design is a set of $K$ unitaries $\\{U_k\\}$ such that\n\n    .. math::\n\n        \\frac{1}{K} \\sum_{k=1}^{K} P_{t,t}(U_k) = \\int_{\\mathcal{U}(d)}\n        P_{t,t} (U) d\\mu(U)\n\n    holds for all possible $P_{t,t}$, and where $d\\mu$ is the\n    uniform *Haar measure*.\n\nWe stress again that this expression is **exact**. The unitaries in a unitary\ndesign are a representative set of points that are \"evenly spaced\" across the\nunitary group. With just a subset of the full group, we can evaluate complex\nexpressions that would be otherwise intractable.\n\nA surprising result about unitary designs is that they exist for all possible\ncombinations of $t$ and $d$ [#Roy]_. There are some known lower\nbounds for the number of unitaries required; for example, a 2-design in\ndimension $d$ has at least $d^4 - 2d^2 + 2$ elements [#Gross]_,\n[#Roy]_.  However, actually finding the sets (and in particular, finding ones\nwith minimal size), is a challenging problem [#Bannai]_, though very recently\nsome constructions have been put forward [#Nakata]_.\n\n\n.. admonition:: Fun fact\n\n    Applying the elements of a unitary design to a fixed pure state produces a\n    set of vectors that form a *complex projective design* [#DankertThesis]_.\n    These are much like spherical designs, but they live in a complex vector\n    space. If you've ever studied the characterization of quantum systems, you\n    may have come across some special sets of measurements called mutually\n    unbiased bases (MUBs), or symmetric, informationally complete positive\n    operator valued measurements (SIC-POVMs). Both of these sets of vectors\n    are complex projective 2-designs [#Klappenecker]_.\n\n    .. figure:: /demonstrations/unitary_designs/sic-povm.svg\n       :align: center\n       :width: 80%\n\n       The vectors of the simplest SIC-POVM in dimension 2, plotted on a Bloch sphere.\n\nUnitary $t$-designs in action\n-----------------------------------\n\nUnitary designs come into play in applications that require randomization, or\nsampling of random unitaries---essentially, they can be used as a stand-in for\nthe Haar measure. The way in which the unitaries are used in the application may\nplace restrictions on the value of $t$ that is required; arguably the most\ncommon is the unitary 2-design.\n\nWhile in general unitary designs are hard to construct, there are well known\nresults for unitary 1-, 2-, and 3-designs based on familiar objects in quantum\ncomputing. Before we see what those are, let's explore an important use case.\n\nAverage fidelity\n^^^^^^^^^^^^^^^^\nA key application of unitary 2-designs is benchmarking quantum\noperations. Suppose we have a noisy quantum channel $\\Lambda$ that should\nperform something close to the unitary operation $V$.  What can we say\nabout the performance of this channel?\n\nOne metric of interest is the *fidelity*. Consider the state $|0\\rangle$.\nIn an ideal case, we apply $V$ and obtain $V|0\\rangle$.  But applying the\nchannel $\\Lambda$ gives us something a little different. Since it's noisy,\nwe must consider the state as a density matrix. The action of $\\Lambda$ on\nour starting state is $\\Lambda(|0\\rangle \\langle 0|)$.  If $\\Lambda$\nwas perfect, then $\\Lambda(|0\\rangle \\langle 0|) = V|0\\rangle \\langle\n0|V^\\dagger$, and the fidelity is\n\n\\begin{align}F(\\Lambda, V) = \\langle 0 | V^\\dagger \\cdot \\Lambda(|0\\rangle \\langle 0|) \\cdot V|0\\rangle = 1.\\end{align}\n\nIn reality, $\\Lambda$ is not going to implement $V$ perfectly, and\n$F < 1$. More importantly though, all we've computed so far is the fidelity when\nthe initial state is $|0\\rangle$. What if the initial state is something\ndifferent? What is the fidelity *on average*?\n\nTo compute an average fidelity, we must do so with respect to the full set\nof Haar-random states. We usually generate random states by applying a\nHaar-random unitary $U$ to $|0\\rangle$. Thus to compute the average\nover all such $U$ we must evaluate\n\n\\begin{align}\\bar{F}(\\Lambda, V) = \\int_{\\mathcal{U}} d\\mu(U) \\langle 0 | U^\\dagger V^\\dagger \\Lambda(U |0\\rangle \\langle 0| U^\\dagger) V U |0\\rangle.\\end{align}\n\nThis is known as *twirling* the channel $\\Lambda$. Computing the average\nfidelity in this way would be a nightmare---we'd have to compute the fidelity\nwith respect to an infinite number of states!\n\nHowever, consider the expression in the integral above. We have an inner product\ninvolving two instances of $U$, and two instances of\n$U^\\dagger$. This means that the expression is a polynomial of degree 2 in\nboth the elements of $U$ and its complex conjugates---this matches exactly\nthe definition of a unitary 2-design. This means that if we can find a set of\n$K$ unitaries that form a 2-design, we can compute the average fidelity\nusing only a finite set of initial states:\n\n\\begin{align}\\frac{1}{K} \\sum_{j=1}^K \\langle 0 | U_j^\\dagger V^\\dagger \\Lambda(U_j |0\\rangle \\langle 0|\n    U_j^\\dagger) V^\\dagger U_j |0\\rangle = \\int_{\\mathcal{U}} d\\mu(U) \\langle 0\n    | U^\\dagger V^\\dagger \\Lambda(U |0\\rangle \\langle 0| U^\\dagger) V U |0\\rangle\\end{align}\n\nThis is great, but a question remains: what is the representative set of unitaries?\n\nThe Clifford group\n^^^^^^^^^^^^^^^^^^\n\nA beautiful result in quantum computing is that some special groups you may\nalready be familiar with are unitary designs:\n\n- the Pauli group forms a unitary 1-design, and \n- the Clifford group forms a unitary 3-design. \n\nBy the definition of designs, this means the Clifford group is also a 1-\nand 2-design.\n\nThe $n$-qubit Pauli group, $\\mathcal{P}(n)$, is the set of all tensor\nproducts of Pauli operations $X$, $Y$, $Z$, and $I$. The\n$n$-qubit Clifford group, $\\mathcal{C}(n)$, is the *normalizer* of the\nPauli group. In simpler terms, the Clifford group is the set of operations that\nsend Paulis to Paulis (up to a phase) under conjugation i.e.,\n\n\\begin{align}C P C^\\dagger = \\pm P^\\prime, \\quad \\forall P, P^\\prime \\in \\mathcal{P}(n), \\quad C \\in \\mathcal{C}(n).\\end{align}\n\nThe Clifford group has some profoundly interesting properties and countless uses\nacross quantum computing, from circuit compilation to error correcting\ncodes. For a single qubit, the group is built from just two operations. One is\nthe Hadamard:\n\n\\begin{align}H X H^\\dagger = Z, \\quad H Y H^\\dagger = -Y, \\quad H Z H^\\dagger = X.\\end{align}\n\nThis clearly maps Paulis to Paulis (up to a phase). The other is the phase gate $S$:\n\n\\begin{align}S X S^\\dagger = Y, \\quad S Y S^\\dagger = -X, \\quad S Z S^\\dagger = Z.\\end{align}\n\nIf both $H$ and $S$ map Paulis to Paulis, then products of them do\nas well. In group theory terms, the single-qubit Clifford group is\ngenerated by $H$ and $S$.  For example, consider the action of\n$HS$:\n\n\\begin{align}(HS) X (HS)^\\dagger = -Y, \\quad (HS) Y (HS)^\\dagger = -Z, \\quad (HS) Z (HS)^\\dagger = X.\\end{align}\n\nSince $Y = iXZ$, it is enough to specify Clifford operations by how they\nact on $X$ and $Z$.  For a particular Clifford, there are 6 possible\nways it can transform $X$, namely $\\pm X, \\pm Y$, or $\\pm Z$.  Once\nthat is determined, there are four remaining options for the transformation of\n$Z$, leading to 24 elements total.\n\nIt takes some work, but you can take combinations of $H$ and $S$\nand evaluate their action on $X$ and $Z$ (or look at their matrix\nrepresentations) until you find all 24 unique elements. The results of\nthis endeavour are expressed below as strings:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["single_qubit_cliffords = [\n '',\n 'H', 'S',\n 'HS', 'SH', 'SS',\n 'HSH', 'HSS', 'SHS', 'SSH', 'SSS',\n 'HSHS', 'HSSH', 'HSSS', 'SHSS', 'SSHS',\n 'HSHSS', 'HSSHS', 'SHSSH', 'SHSSS', 'SSHSS',\n 'HSHSSH', 'HSHSSS', 'HSSHSS'\n]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To see for yourself how this set of unitaries is evenly distributed, try\napplying each of the Cliffords to the initial state $|0\\rangle$, and\nplot the resulting states on the Bloch sphere. You'll find they are\nsymmetric and evenly spaced; in fact, they are all eigenstates of $X$,\n$Y$, and $Z$. Furthermore, under the full group action, the result\nis balanced in the sense that each eigenstate is obtained the same number of\ntimes.\n\nThe multi-qubit Clifford group can also be\nspecified by only a small set of generators (in fact, only one more\nthan is needed for the single-qubit case). Together, $H$, $S$, and\nCNOT (on every possible qubit or pair of qubits) generate the $n$-qubit\ngroup. Be careful though---the size of the group increases exponentially. The\n2-qubit group alone has 11520 elements! The size can be worked out in a manner\nanalogous to that we used above in the single qubit case: by looking at the\ncombinatorics of the possible ways the gates can map Paulis with only\n$X$ and $Z$ to other Paulis.\n\nAn experiment\n^^^^^^^^^^^^^\nThe whole idea of unitary designs may sound too good to be true. Can we\n*really* compute the exact average fidelity using just 24 operations? In this\nsection, we put them to the test: we'll compute the average fidelity of an\noperation first with experiments using a large but finite amount of Haar-random\nunitaries, and then again with only the Clifford group.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["import pennylane as qml\n\n# Scipy allows us to sample Haar-random unitaries directly\nfrom scipy.stats import unitary_group\n\n# set the random seed\nnp.random.seed(42)\n\n# Use the mixed state simulator\ndev = qml.device(\"default.mixed\", wires=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's set up a noisy quantum channel. To keep things simple, assume it\nconsists of applying :class:`~.pennylane.SX`, the square-root of\n$X$ gate, followed by a few different types of noise. First, write a\nquantum function for our ideal experiment:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def ideal_experiment():\n    qml.SX(wires=0)\n    return qml.state()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Next, we apply some noise. We do so by making use of a relatively new feature\nin PennyLane called `quantum function transforms <https://pennylane.readthedocs.io/en/latest/code/qml_transforms.html>`__. Such transforms work by\nmodifying the underlying, low-level quantum tapes which queue the quantum\noperations. Suppose the noisy channel is composed of the following:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def noisy_operations(damp_factor, depo_factor, flip_prob):\n    qml.AmplitudeDamping(damp_factor, wires=0)\n    qml.DepolarizingChannel(depo_factor, wires=0)\n    qml.BitFlip(flip_prob, wires=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's create a transform that applies this noise to any quantum function\n*after* the original operations, but before the measurements.  We use the\nconvenient :func:`~.pennylane.transforms.qfunc_transform` decorator:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["@qml.qfunc_transform\ndef apply_noise(tape, damp_factor, depo_factor, flip_prob):\n    # Apply the original operations\n    for op in tape.operations:\n        qml.apply(op)\n\n    # Apply the noisy sequence\n    noisy_operations(damp_factor, depo_factor, flip_prob)\n\n    # Apply the original measurements\n    for m in tape.measurements:\n        qml.apply(m)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can now apply this transform to create a noisy version of our ideal\nquantum function:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# The strengths of various types of noise\ndamp_factor = 0.02\ndepo_factor = 0.02\nflip_prob = 0.01\n\nnoisy_experiment = apply_noise(damp_factor, depo_factor, flip_prob)(ideal_experiment)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The last part of the experiment involves applying a random unitary matrix\nbefore all the operations, and its inverse right before the measurements.  We\ncan write another transform here to streamline this process:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["@qml.qfunc_transform\ndef conjugate_with_unitary(tape, matrix):\n    qml.QubitUnitary(matrix, wires=0)\n\n    for op in tape.operations:\n        qml.apply(op)\n\n    qml.QubitUnitary(matrix.conj().T, wires=0)\n\n    for m in tape.measurements:\n        qml.apply(m)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Finally, in order to perform a comparison, we need a function to compute the\n`fidelity <https://en.wikipedia.org/wiki/Fidelity_of_quantum_states>`__\ncompared to the ideal operation.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["from scipy.linalg import sqrtm\n\ndef fidelity(rho, sigma):\n    # Inputs rho and sigma are density matrices\n    sqrt_sigma = sqrtm(sigma)\n    fid = np.trace(sqrtm(sqrt_sigma @ rho @ sqrt_sigma))\n    return fid.real"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's now compute the average fidelity, averaging over 50000 Haar-random unitaries:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["n_samples = 50000\n\nfidelities = []\n\nfor _ in range(n_samples):\n    # Select a Haar-random unitary\n    U = unitary_group.rvs(2)\n\n    # Apply transform to construct the ideal and noisy quantum functions\n    conjugated_ideal_experiment = conjugate_with_unitary(U)(ideal_experiment)\n    conjugated_noisy_experiment = conjugate_with_unitary(U)(noisy_experiment)\n\n    # Use the functions to create QNodes\n    ideal_qnode = qml.QNode(conjugated_ideal_experiment, dev)\n    noisy_qnode = qml.QNode(conjugated_noisy_experiment, dev)\n\n    # Execute the QNodes\n    ideal_state = ideal_qnode()\n    noisy_state = noisy_qnode()\n\n    # Compute the fidelity\n    fidelities.append(fidelity(ideal_state, noisy_state))\n\nfid_mean = np.mean(fidelities)\nprint(f\"Mean fidelity = {fid_mean}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now let's repeat the procedure using only Clifford group elements. First, we\nwrite a quantum function that performs a Clifford operation (or its inverse)\nbased on its string representation.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def apply_single_clifford(clifford_string, inverse=False):\n    for gate in clifford_string:\n        if gate == 'H':\n            qml.Hadamard(wires=0)\n        else:\n            sign = -1 if inverse else 1\n            qml.PhaseShift(sign * np.pi/2, wires=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Next, we write a transform that applies a Clifford in the context of the full\nexperiment, i.e., apply the Clifford, then the operations, followed by the\ninverse of the Clifford.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["@qml.qfunc_transform\ndef conjugate_with_clifford(tape, clifford_string):\n    apply_single_clifford(clifford_string, inverse=False)\n\n    for op in tape.operations:\n        qml.apply(op)\n\n    apply_single_clifford(clifford_string, inverse=True)\n\n    for m in tape.measurements:\n        qml.apply(m)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You may have noticed this transform has exactly the same form as\n``conjugate_with_unitary`` from above. Only the input type has changed, since\nthe application of Cliffords here is specified by their string representation.\n\nIt's now time to run the experiments:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["fidelities = []\n\nfor C in single_qubit_cliffords:\n    conjugated_ideal_experiment = conjugate_with_clifford(C)(ideal_experiment)\n    conjugated_noisy_experiment = conjugate_with_clifford(C)(noisy_experiment)\n\n    ideal_qnode = qml.QNode(conjugated_ideal_experiment, dev)\n    noisy_qnode = qml.QNode(conjugated_noisy_experiment, dev)\n\n    ideal_state = ideal_qnode()\n    noisy_state = noisy_qnode()\n\n    fidelities.append(fidelity(ideal_state, noisy_state))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's see how our results compare to the earlier simulation:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["clifford_fid_mean = np.mean(fidelities)\n\nprint(f\"Haar-random mean fidelity = {fid_mean}\")\nprint(f\"Clifford mean fidelity    = {clifford_fid_mean}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Incredible \ud83e\udd2f \ud83e\udd2f \ud83e\udd2f We were able to compute the average fidelity using only\n24 experiments. Furthermore, the mean fidelity obtained from the Clifford\nexperiments is **exact**; even with 50000 Haar-random experiments, we see\ndeviations starting a few decimal places in. Consider the resources that would\nbe saved if you were actually implementing this in a lab! It's not hard to see\nwhy the Clifford group plays such an important role in characterization\nprocedures.\n\nConclusion\n----------\n\nIn this demo, we've barely scratched the surface of designs and their\napplications in quantum computing. While benchmarking is a key application\narea, there are many others.  The Pauli group as a unitary 1-design has\napplications in the construction of private quantum channels [#PQC]_.\n*Approximate* unitary $t$-designs (where the equality in the definition\nis replaced by approximately equal up to some finite precision) are also of\ninterest, as there ways to construct them that are more efficient than those\nof exact designs [#Dankert]_. In particular, it has been shown that\napproximate complex projective 4-designs have applications to the state\ndiscrimination problem [#Ambainis]_.\n\nFurthermore, unitary designs are not the only designs that you'll encounter\nin quantum computing. The familiar Hadamard gate is just a 2-dimensional\nexample of a broader family of *Hadamard designs*, on which there has been\nextensive research [#Seberry]_. Some sets of `mutually orthogonal Latin\nsquares <https://en.wikipedia.org/wiki/Mutually_orthogonal_Latin_squares>`__\nhave a direct correspondence with mutually unbiased bases, which are optimal\nquantum measurements [#Gaeta]_, as well as complex projective designs; and Latin\nsquares themselves have direct correspondence with affine and projective\nplanes, bringing us full circle back to the Fano plane from which we began.\n\n\n.. figure:: /demonstrations/unitary_designs/affine-latin.svg\n   :align: center\n   :width: 80%\n\n   An affine plane, Hadamard matrix, and a depiction of mutually orthogonal Latin squares.\n\nReferences\n----------\n\n.. [#Handbook]\n\n    C. J. Colbourn and J. H. Dinitz (2006) *Handbook of Combinatorial Designs,\n    Second Edition*.  Chapman & Hall/CRC.\n\n.. [#Delsarte]\n\n   P. Delsarte, J.M. Goethals, J.J. Seidel (1977) *Spherical Codes and Designs*. Geometriae\n   Dedicata 6 363-388.\n\n.. [#sph4design]\n\n   R. H. Hardin and N. J. A. Sloane (1992) *New spherical 4-designs*. Discrete\n   Mathematics, 106-107 (255-264). `(PDF)\n   <https://www.sciencedirect.com/science/article/pii/0012365X9290552Q>`__.\n\n.. [#Ambainis]\n\n   A. Ambainis and J. Emerson (2007) *Quantum t-designs: t-wise independence\n   in the quantum world.* Twenty-Second Annual IEEE Conference on\n   Computational Complexity 129-140.\n   `(arXiv) <https://arxiv.org/abs/quant-ph/0701126>`__.\n\n.. [#Klappenecker]\n\n   A. Klappenecker and M. Roetteler (2005) *Mutually unbiased bases, spherical\n   designs, and frames.* Proceedings of SPIE Vol. 5914.\n\n.. [#Dankert]\n\n   C. Dankert, R. Cleve, J. Emerson, and E. Levine (2009) *Exact and\n   Approximate Unitary 2-Designs: Constructions and Applications.* Phys. Rev. A 80, 012304.\n   `(arXiv) <https://arxiv.org/abs/quant-ph/0606161>`__.\n\n.. [#DankertThesis]\n\n   C. Dankert (2005) *Efficient Simulation of Random Quantum States and\n   Operators.* MSc Thesis, University of Waterloo. `(arXiv)\n   <https://arxiv.org/abs/quant-ph/0512217>`__.\n\n.. [#Gross]\n\n   D. Gross, K. Audenaert, and J. Eisert (2007) *Evenly distributed unitaries:\n   on the structure of unitary designs*. J. Math. Phys. 48, 052104.\n   `(arXiv) <https://arxiv.org/abs/quant-ph/0611002>`__.\n\n.. [#Roy]\n\n   A. Roy and A. J. Scott (2009) *Unitary designs and codes*. Des. Codes Cryptogr. 53 13-31.\n   `(arXiv) <https://arxiv.org/abs/0809.3813>`__.\n\n.. [#Bannai]\n\n   E. Bannai, M. Nakahara, D. Zhao, and Y. Zhu (2019) *On the explicit constructions of\n   certain unitary t-designs.* J. Phys. A: Math. Theor. 52 495301.\n   `(arXiv) <https://arxiv.org/abs/1906.04583>`__.\n\n.. [#Nakata]\n\n   Y. Nakata et al. (2021) *Quantum circuits for exact unitary t-designs and\n   applications to higher-order randomized benchmarking.* `(arXiv)\n   <https://arxiv.org/abs/2102.12617>`__.\n\n.. [#PQC]\n\n   A. Ambainis, M. Mosca, A. Tapp, and R. de Wolf (2000) *Private Quantum Channels*. Proc.\n   41st FOCS, 547-553. `(PDF) <https://homepages.cwi.nl/~rdewolf/publ/qc/AMTW00.pdf>`__.\n\n.. [#Seberry]\n\n   J. Seberry and M. Yamada (1992) *Hadamard matrices, sequences, and block\n   designs.* Contemporary Design Theory -- A Collection of Surveys\n   (D. J. Stinson and J. Dinitz, Eds.), John Wiley and Sons, 431-560.\n   `(PDF) <http://mathscinet.ru/files/YamadaSeberry1992.pdf>`__.\n\n.. [#Gaeta]\n\n   M. Gaeta, O. Di Matteo, A. B. Klimov, and H. de Guise (2014) *Discrete phase-space\n   approach to mutually orthogonal Latin squares*. J. Phys. A: Math. Theor. 47 (43) 435303.\n   `(arXiv) <https://arxiv.org/abs/1408.6742>`__.\n\n"]}]}