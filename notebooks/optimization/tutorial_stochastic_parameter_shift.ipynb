{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n# The Stochastic Parameter-Shift Rule\n\n.. meta::\n    :property=\"og:description\": Differentiate any qubit gate with the stochastic parameter-shift rule.\n    :property=\"og:image\": https://pennylane.ai/qml/_images/stochastic_parameter_shift_thumbnail.png\n\n.. related::\n\n   parameter_shift Parameter shift rules\n   tutorial_backprop Quantum gradients with backprop\n   tutorial_general_parshift Generalized parameter-shift rules\n\n*Author: PennyLane dev team. Last updated: 15 Jan 2021.*\n\nWe demonstrate how the stochastic parameter-shift rule, discovered by Banchi and Crooks [#banchi2020]_,\ncan be used to differentiate arbitrary qubit gates, generalizing the original\n:doc:`parameter-shift rule </glossary/parameter_shift>`, which applies only for gates of a particular\n(but widely encountered) form.\n\n## Background\n\nOne of the main ideas encountered in near-term quantum machine learning is the\n:doc:`variational circuit </glossary/variational_circuit>`.\nEvolving from earlier concepts pioneered by domain-specific algorithms like the\n:doc:`variational quantum eigensolver </demos/tutorial_vqe>` and the\n:doc:`quantum approximate optimization algorithm </demos/tutorial_qaoa_maxcut>`,\nthis class of quantum algorithms makes heavy use of two distinguishing ingredients:\n\ni) The circuit's gates have free parameters\nii) Expectation values of measurements are built up from samples\n\nThese two ingredients allow one circuit to actually represent an entire *family of circuits*.\nAn objective function---encapsulating some problem-specific goal---is built from the expectation values,\nand the circuit's free parameters are progressively tuned to optimize this function.\nAt each step, the circuit has the same gate layout, but slightly different parameters, making\nthis approach promising to run on constrained near-term devices.\n\nBut how should we actually update the circuit's parameters to move us closer to a good output?\nBorrowing a page from classical optimization and deep learning, we can use\n`gradient descent <https://en.wikipedia.org/wiki/Gradient_descent>`_.\nIn this general-purpose method, we compute the derivative of a (smooth) function $f$ with\nrespect to its parameters $\\theta$, i.e., its gradient $\\nabla_\\theta f$.\nSince the gradient always points in the direction of steepest ascent/descent, if we make small updates\nto the parameters according to\n\n\\begin{align}\\theta \\rightarrow \\theta - \\eta \\nabla_\\theta f,\\end{align}\n\nwe can iteratively progress to lower and lower values of the function.\n\n## The Parameter-Shift Rule\n\nIn the quantum case, the expectation value of a circuit with respect to an measurement operator\n$\\hat{C}$ depends smoothly on the the circuit's gate parameters $\\theta$. We can write this\nexpectation value as $\\langle \\hat{C}(\\theta)\\rangle$. This means that the derivatives\n$\\nabla_\\theta \\langle \\hat{C} \\rangle$ exist and gradient descent can be used.\n\nBefore digging deeper, we will first set establish some basic notation. For simplicity, though a circuit\nmay contain many gates, we can concentrate on just a single gate $\\hat{U}$ that we want to differentiate\n(other gates will follow the same pattern).\n\n.. figure:: ../demonstrations/stochastic_parameter_shift/quantum_circuit.png\n    :align: center\n    :width: 90%\n\nAll gates appearing before $\\hat{U}$ can be absorbed into an initial state preparation\n$\\vert \\psi_0 \\rangle$, and all gates appearing after $\\hat{U}$ can be absorbed with the measurement\noperator $\\hat{C}$ to make a new effective measurement operator $\\hat{A}$.\nThe expectation value $\\hat{A}$ in the simpler one-gate circuit is identical to\nthe expectation value $\\hat{C}$ in the larger circuit.\n\nWe can also write any unitary gate in the form\n\n\\begin{align}\\hat{U}(\\theta) = e^{i\\theta\\hat{V}},\\end{align}\n\nwhere $\\hat{V}$ is the Hermitian *generator* of the gate $\\hat{U}$.\n\nNow, how do we actually obtain the numerical values of the gradient necessary for gradient descent?\n\nThis is where the parameter-shift rule [#li2016]_ [#mitarai2018]_ [#schuld2018]_ enters the story.\nIn short, the parameter-shift rule says that for\nmany gates of interest---including all single-qubit gates---we can obtain the value of the derivative\n$\\nabla_\\theta \\langle \\hat{A}(\\theta) \\rangle$ by subtracting two related\ncircuit evaluations:\n\n\\begin{align}\\nabla_\\theta \\langle \\hat{A} \\rangle =\n   u\\left[\n     \\langle \\hat{A}(\\theta + \\tfrac{\\pi}{4u}) \\rangle -\n     \\langle \\hat{A}(\\theta - \\tfrac{\\pi}{4u}) \\rangle\n   \\right]\\end{align}\n\n.. figure:: ../demonstrations/stochastic_parameter_shift/parameter_shift_rule.png\n    :align: center\n    :width: 80%\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The multiplier $u$ in this formula is arbitrary and can differ between implementations.\n    For example, PennyLane internally uses the convention where $u=\\tfrac{1}{2}$.</p></div>\n\nThe parameter-shift rule is *exact*, i.e., the formula for the gradient doesn't involve any approximations.\nFor quantum hardware, we can only take a finite number of samples, so we can never determine a circuit's\nexpectation values *exactly*. However, the parameter-shift rule provides the guarantee that it is an\n`unbiased estimator <https://en.wikipedia.org/wiki/Bias_of_an_estimator>`_, meaning that if we could take a infinite number of samples, it converges to the\ncorrect gradient value.\n\nLet's jump into some code and take a look at the parameter-shift rule in action.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["import pennylane as qml\nimport matplotlib.pyplot as plt\nfrom pennylane import numpy as np\nfrom scipy.linalg import expm\n\nnp.random.seed(143)\nangles = np.linspace(0, 2 * np.pi, 50)\ndev = qml.device('default.qubit', wires=2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We will consider a very simple circuit, containing just a single-qubit\nrotation about the x-axis, followed by a measurement along the z-axis.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["@qml.qnode(dev)\ndef rotation_circuit(theta):\n    qml.RX(theta, wires=0)\n    return qml.expval(qml.PauliZ(0))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We will examine the gradient with respect to the parameter $\\theta$.\nThe parameter-shift recipe requires taking the difference of two circuit\nevaluations, with forward and backward shifts in angles.\nPennyLane also provides a convenience function :func:`~pennylane.grad`\nto automatically compute the gradient. We can use it here for comparison.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Check out the :mod:`qml.gradients <pennylane.gradients>` module\n    to explore all quantum gradient transforms provided by PennyLane.</p></div>\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def param_shift(theta):\n    # using the convention u=1/2\n    r_plus = rotation_circuit(theta + np.pi / 2)\n    r_minus = rotation_circuit(theta - np.pi / 2)\n    return 0.5 * (r_plus - r_minus)\n\ngradient = qml.grad(rotation_circuit, argnum=0)\n\nexpvals = [rotation_circuit(theta) for theta in angles]\ngrad_vals = [gradient(theta) for theta in angles]\nparam_shift_vals = [param_shift(theta) for theta in angles]\nplt.plot(angles, expvals, 'b', label=\"Expecation value\")\nplt.plot(angles, grad_vals, 'r', label=\"qml.grad function\")\nplt.plot(angles, param_shift_vals, 'mx', label=\"Parameter-shift rule\")\nplt.xlabel(\"theta\")\nplt.legend()\nplt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We have evaluated the expectation value at all possible values for the angle\n$\\theta$. By inspection, we can see that the functional dependence is\n$\\cos(\\theta)$.\n\nThe parameter-shift evaluations are plotted with 'x' markers.\nAgain, by simple inspection, we can see that these have the functional form\n$-\\sin(\\theta)$, the expected derivative of $\\cos(\\theta)$,\nand that they match the values provided by the :func:`~pennylane.grad`\nfunction.\n\nThe parameter-shift works really nicely for many gates---like the rotation\ngate we used in our example above. But it does have constraints. There are\nsome technical conditions that, if a gate satisfies them, we can guarantee\nit has a parameter-shift rule [#schuld2018]_. Concretely, the\nparameter-shift rule holds for any gate of the form\n$e^{i\\theta\\hat{G}}$ where $\\hat{G}^2=\\mathbb{1}$.\nFurthermore, we can derive\nsimilar parameter-shift recipes for some other gates that *don't* meet\nthis technical conditions, on a one-by-one basis.\n\nBut, in general, the parameter-shift rule is not universally applicable.\nIn cases where it does not hold (or is not yet known to hold), we would\neither have to decompose the gate into compatible gates, or use an\nalternate estimator for the gradient, e.g., the finite-difference\napproximation. But both of these alternatives can have drawbacks due\nto increased circuit complexity or potential errors in the gradient\nvalue.\n\nIf only there was a parameter-shift method that could be used\nfor *any* qubit gate. \ud83e\udd14\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## The Stochastic Parameter-Shift Rule\n\nHere's where the stochastic parameter-shift rule makes its appearance\non the stage.\n\nThe stochastic parameter-shift rule introduces two new ingredients to\nthe parameter-shift recipe:\n\ni) A random parameter $s$, sampled uniformly from $[0,1]$\n   (this is the origin of the \"stochastic\" in the name);\nii) Sandwiching the \"shifted\" gate application with one additional\n    gate on each side.\n\nThese additions allow the stochastic parameter-shift rule to work\nfor arbitrary qubit gates.\n\nEvery gate is unitary, which means they\nhave the form $\\hat{U}(\\theta) = e^{i\\theta \\hat{G}}$\nfor some generator $G$.\nAdditionally, every multi-qubit operator can be expressed as a\nsum of tensor products of Pauli operators, so let's assume,\nwithout loss of generality, the following form for $\\hat{G}$:\n\n\\begin{align}\\hat{G} = \\hat{H} + \\theta \\hat{V},\\end{align}\n\nwhere $\\hat{V}$ is a \"Pauli word\", i.e., a tensor\nproduct of Pauli operators (e.g.,\n$\\hat{Z}_0\\otimes\\hat{Y}_1)$ and $\\hat{H}$ can\nbe an arbitrary linear combination of Pauli-operator\ntensor products. For simplicity, we assume that the parameter\n$\\theta$ appears only in front of $\\hat{V}$ (other\ncases can be handled using the chain rule).\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The stochastic parameter-shift rule gives the following recipe for\ncomputing the gradient of the expectation value\n$\\langle \\hat{A} (\\theta) \\rangle$:\n\ni) Sample a value for the variable $s$ uniformly form\n   $[0,1]$.\nii) In place of gate $\\hat{U}(\\theta)$, apply the following\n    three gates:\n\n    a) $e^{i(1-s)(\\hat{H} + \\theta\\hat{V})}$\n    b) $e^{+i\\tfrac{\\pi}{4}\\hat{V}}$\n    c) $e^{is(\\hat{H} + \\theta\\hat{V})}$\n\n    Measure the observable $\\hat{A}$ and call the resulting\n    expectation value of $\\langle r_+\\rangle$.\n\niii) Repeat step ii, but flip the sign of the angle $\\tfrac{\\pi}{4}$\n     in part b. Call the resulting expectation value\n     $\\langle r_-\\rangle$.\n\nThe gradient can be obtained from the average value of\n$\\langle r_+ \\rangle - \\langle r_-\\rangle$, i.e.,\n\n\\begin{align}\\mathbb{E}_{s\\in\\mathcal{U}[0,1]}[\\langle r_+ \\rangle - \\langle r_-\\rangle]\\end{align}\n\n.. figure:: ../demonstrations/stochastic_parameter_shift/stochastic_parameter_shift.png\n   :align: center\n   :width: 90%\n\nLet's see this method in action.\n\nFollowing [#banchi2020]_, we will use the cross-resonance gate as a\nworking example. This gate is defined as\n\n\\begin{align}\\hat{U}_{CR}(\\theta_1, \\theta_2, \\theta_3)\n                       = \\exp\\left[ i(\\theta_1\\hat{X}\\otimes\\hat{\\mathbf{1}} -\n                                      \\theta_2\\hat{Z}\\otimes\\hat{X} +\n                                      \\theta_3\\hat{\\mathbf{1}}\\otimes\\hat{X}\n                                   ) \\right].\\end{align}\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# First we define some basic Pauli matrices\nI = np.eye(2)\nX = np.array([[0, 1], [1, 0]])\nZ = np.array([[1, 0], [0, -1]])\n\ndef Generator(theta1, theta2, theta3):\n    G = theta1.item() * np.kron(X, I) - \\\n        theta2 * np.kron(Z, X) + \\\n        theta3 * np.kron(I, X)\n    return G\n\n# A simple example circuit that contains the cross-resonance gate\n@qml.qnode(dev)\ndef crossres_circuit(gate_pars):\n    G = Generator(*gate_pars)\n    qml.QubitUnitary(expm(-1j * G), wires=[0, 1])\n    return qml.expval(qml.PauliZ(0))\n\n# Subcircuit implementing the gates necessary for the\n# stochastic parameter-shift rule.\n# In this example, we will differentiate the first term of\n# the circuit (i.e., our variable is theta1).\ndef SPSRgates(gate_pars, s, sign):\n    G = Generator(*gate_pars)\n    # step a)\n    qml.QubitUnitary(expm(1j * (1 - s) * G), wires=[0, 1])\n    # step b)\n    qml.QubitUnitary(expm(1j * sign * np.pi / 4 * X), wires=0)\n    # step c)\n    qml.QubitUnitary(expm(1j * s * G), wires=[0,1])\n\n# Function which can obtain all expectation vals needed\n# for the stochastic parameter-shift rule\n@qml.qnode(dev)\ndef spsr_circuit(gate_pars, s=None, sign=+1):\n    SPSRgates(gate_pars, s, sign)\n    return qml.expval(qml.PauliZ(0))\n\n# Fix the other parameters of the gate\ntheta2, theta3 = -0.15, 1.6\n\n# Obtain r+ and r-\n# Even 10 samples gives a good result for this example\npos_vals = np.array([[spsr_circuit([theta1, theta2, theta3], s=s, sign=+1)\n                      for s in np.random.uniform(size=10)]\n                      for theta1 in angles])\nneg_vals = np.array([[spsr_circuit([theta1, theta2, theta3], s=s, sign=-1)\n                      for s in np.random.uniform(size=10)]\n                      for theta1 in angles])\n\n# Plot the results\nevals = [crossres_circuit([theta1, theta2, theta3]) for theta1 in angles]\nspsr_vals = (pos_vals - neg_vals).mean(axis=1)\nplt.plot(angles, evals, 'b', label=\"Expectation Value\")\nplt.plot(angles, spsr_vals, 'r', label=\"Stochastic parameter-shift rule\")\nplt.xlabel(\"theta1\")\nplt.legend()\nplt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["By inspection, we can see that the expectation values of the cross-resonance\ngate lead to a functional form $\\cos(2\\theta_1)$.\nAlso by inspection, the results from the stochastic parameter-shift rule\nhave the functional form $-2\\sin(2\\theta_1)$, which is the derivative\nof $\\cos(2\\theta_1)$!\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Finally, it is interesting to notice when the stochastic parameter-shift rule\nreduces to the regular parameter-shift rule. Consider again the case\nwhere the gate has just a single term:\n\n\\begin{align}\\hat{U}(\\theta) = e^{i\\theta\\hat{V}}.\\end{align}\n\nIn this case, the terms encapsulated in the operator $\\hat{H}$ are all\nzero, and the gates $e^{i(1-s)\\hat{G}}$,\n$e^{\\pm i\\tfrac{\\pi}{4}\\hat{V}}$, and $e^{is\\hat{G}}$ which\nappear in the stochastic parameter-shift rule all commute. Therefore,\nwe can combine them together into a single gate:\n\n\\begin{align}\\begin{align}\n       e^{i(1-s)\\hat{G}}e^{\\pm i\\tfrac{\\pi}{4}\\hat{V}}e^{is\\hat{G}}\n        & = e^{i(1-s)\\hat{G}}e^{is\\hat{G}}e^{\\pm i\\tfrac{\\pi}{4}\\hat{V}} \\\\\n        & = e^{i\\hat{G}}e^{\\pm i\\tfrac{\\pi}{4}\\hat{V}} \\\\\n        & = e^{i\\theta\\hat{V}}e^{\\pm i\\tfrac{\\pi}{4}\\hat{V}} \\\\\n        & = e^{i\\left(\\theta\\pm\\tfrac{\\pi}{4}\\right)\\hat{V}}\n    \\end{align}\\end{align}\n\nSince the random variable $s$ no longer appears in this equation,\naveraging over it has no effect, and the stochastic parameter-shift rule\nnicely reduces back to the ordinary parameter-shift rule!\n\n\\begin{align}\\begin{align}\n       \\mathbb{E}_{s\\in\\mathcal{U}[0,1]}\\left[\n           e^{i(1-s)\\hat{G}}e^{\\pm i\\tfrac{\\pi}{4}\\hat{V}}e^{is\\hat{G}}\n       \\right]\n       = & e^{i\\left(\\theta\\pm\\tfrac{\\pi}{4}\\right)\\hat{V}}\n    \\end{align}\\end{align}\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## References\n\n.. [#banchi2020]\n\n    Leonardo Banchi and Gavin E. Crooks. \"Measuring Analytic Gradients of\n    General Quantum Evolution with the Stochastic Parameter Shift Rule.\"\n    `arXiv:2005.10299 <https://arxiv.org/abs/2005.10299>`__ (2020).\n\n.. [#li2016]\n\n    Jun Li, Xiaodong Yang, Xinhua Peng, and Chang-Pu Sun.\n    \"Hybrid Quantum-Classical Approach to Quantum Optimal Control.\"\n    `arXiv:1608.00677 <https://arxiv.org/abs/1608.00677>`__ (2016).\n\n.. [#mitarai2018]\n\n    Kosuke Mitarai, Makoto Negoro, Masahiro Kitagawa, and Keisuke Fujii.\n    \"Quantum Circuit Learning.\"\n    `arXiv:1803.00745 <https://arxiv.org/abs/1803.00745>`__ (2020).\n\n.. [#schuld2018]\n\n    Maria Schuld, Ville Bergholm, Christian Gogolin, Josh Izaac, and\n    Nathan Killoran. \"Evaluating analytic gradients on quantum hardware.\"\n    `arXiv:1811.11184 <https://arxiv.org/abs/1811.11184>`__ (2019).\n\n"]}], "metadata": {"kernelspec": {"display_name": "PennyLane", "language": "python", "name": "pennylane"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.10"}}, "nbformat": 4, "nbformat_minor": 0}