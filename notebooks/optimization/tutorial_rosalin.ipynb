{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nFrugal shot optimization with Rosalin\n=====================================\n\n.. meta::\n    :property=\"og:description\": The Rosalin optimizer uses a measurement-frugal optimization strategy to minimize the\n         number of times a quantum computer is accessed.\n    :property=\"og:image\": https://pennylane.ai/qml/_images/sphx_glr_tutorial_rosalin_002.png\n\n.. related::\n\n   tutorial_vqe Variational quantum eigensolver\n   tutorial_quantum_natural_gradient Quantum natural gradient\n   tutorial_doubly_stochastic Doubly stochastic gradient descent\n   tutorial_rotoselect Quantum circuit structure learning\n\n*Author: PennyLane dev team. Posted: 19 May 2020. Last updated: 13 April 2021.*\n\nIn this tutorial we investigate and implement the Rosalin (Random Operator Sampling for\nAdaptive Learning with Individual Number of shots) from\nArrasmith et al. [#arrasmith2020]_. In this paper, a strategy\nis introduced for reducing the number of shots required when optimizing variational quantum\nalgorithms, by both:\n\n* Frugally adapting the number of shots used per parameter update, and\n* Performing a weighted sampling of operators from the cost Hamiltonian.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The Rosalin optimizer is available in PennyLane via the\n    :class:`~.pennylane.ShotAdaptiveOptimizer`.</p></div>\n\nBackground\n----------\n\nWhile a large number of papers in variational quantum algorithms focus on the\nchoice of circuit ansatz, cost function, gradient computation, or initialization method,\nthe optimization strategy---an important component affecting both convergence time and\nquantum resource dependence---is not as frequently considered. Instead, common\n'out-of-the-box' classical optimization techniques, such as gradient-free\nmethods (COBLYA, Nelder-Mead), gradient-descent, and Hessian-free methods (L-BFGS) tend to be used.\n\nHowever, for variational algorithms such as :doc:`VQE </demos/tutorial_vqe>`, which involve evaluating\na large number of non-commuting operators in the cost function, decreasing the number of\nquantum evaluations required for convergence, while still minimizing statistical noise, can\nbe a delicate balance.\n\nRecent work has highlighted that 'quantum-aware' optimization techniques\ncan lead to marked improvements when training variational quantum algorithms:\n\n* :doc:`/demos/tutorial_quantum_natural_gradient` descent by Stokes et al. [#stokes2019]_, which\n  takes into account the quantum geometry during the gradient-descent update step.\n\n* The work of Sweke et al. [#sweke2019]_, which shows\n  that quantum gradient descent with a finite number of shots is equivalent to\n  `stochastic gradient descent <https://en.wikipedia.org/wiki/Stochastic_gradient_descent>`_,\n  and has guaranteed convergence. Furthermore, combining a finite number of shots with\n  weighted sampling of the cost function terms leads to :doc:`/demos/tutorial_doubly_stochastic`.\n\n* The iCANS (individual Coupled Adaptive Number of Shots) optimization technique by\n  Jonas Kuebler et al. [#kubler2020]_ adapts the number\n  of shots measurements during training, by maximizing the expected gain per shot.\n\nIn this latest result by Arrasmith et al. [#arrasmith2020]_, the\nidea of doubly stochastic gradient descent has been used to extend the iCANS optimizer,\nresulting in faster convergence.\n\nOver the course of this tutorial, we will explore their results; beginning first with a\ndemonstration of *weighted random sampling* of the cost Hamiltonian operators, before\ncombining this with the shot-frugal iCANS optimizer to perform doubly stochastic\nRosalin optimization.\n\nWeighted random sampling\n------------------------\n\nConsider a Hamiltonian $H$ expanded as a weighted sum of operators $h_i$ that can\nbe directly measured:\n\n\\begin{align}H = \\sum_{i=1}^N c_i h_i.\\end{align}\n\nDue to the linearity of expectation values, the expectation value of this Hamiltonian\ncan be expressed as the weighted sum of each individual term:\n\n\\begin{align}\\langle H\\rangle = \\sum_{i=1}^N c_i \\langle h_i\\rangle.\\end{align}\n\nIn the :doc:`doubly stochastic gradient descent demonstration </demos/tutorial_doubly_stochastic>`,\nwe estimated this expectation value by **uniformly sampling** a subset of the terms\nat each optimization step, and evaluating each term by using the same finite number of shots\n$N$.\n\nHowever, what happens if we use a weighted approach to determine how to distribute\nour samples across the terms of the Hamiltonian? In **weighted random sampling** (WRS),\nthe number of shots used to determine the expectation value $\\langle h_i\\rangle$\nis a discrete random variable distributed according to a\n`multinomial distribution <https://en.wikipedia.org/wiki/Multinomial_distribution>`__,\n\n\\begin{align}S \\sim \\text{Multinomial}(p_i),\\end{align}\n\nwith event probabilities\n\n\\begin{align}p_i = \\frac{|c_i|}{\\sum_i |c_i|}.\\end{align}\n\nThat is, the number of shots assigned to the measurement of the expectation value of the\n$i\\text{th}$ term of the Hamiltonian is drawn from a probability distribution\n*proportional to the magnitude of its coefficient* $c_i$.\n\nTo see this strategy in action, consider the Hamiltonian\n\n\\begin{align}H = 2I\\otimes X + 4 I\\otimes Z  - X\\otimes X + 5Y\\otimes Y + 2 Z\\otimes X.\\end{align}\n\nWe can solve for the ground state energy using the variational quantum eigensolver (VQE) algorithm.\n\nFirst, let's import NumPy and PennyLane, and define our Hamiltonian.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["from pennylane import numpy as np\nimport pennylane as qml\n\n# set the random seed\nnp.random.seed(4)\n\ncoeffs = [2, 4, -1, 5, 2]\n\nobs = [\n  qml.PauliX(1),\n  qml.PauliZ(1),\n  qml.PauliX(0) @ qml.PauliX(1),\n  qml.PauliY(0) @ qml.PauliY(1),\n  qml.PauliZ(0) @ qml.PauliZ(1)\n]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can now create our quantum device (let's use the ``default.qubit`` simulator),\nand begin constructing some QNodes to evaluate each observable. For our ansatz, we'll use the\n:class:`~.pennylane.templates.layers.StronglyEntanglingLayers`.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["from pennylane.templates.layers import StronglyEntanglingLayers\n\nnum_layers = 2\nnum_wires = 2\n\n# create a device that estimates expectation values using a finite number of shots\nnon_analytic_dev = qml.device(\"default.qubit\", wires=num_wires, shots=100)\n\n# create a device that calculates exact expectation values\nanalytic_dev = qml.device(\"default.qubit\", wires=num_wires, shots=None)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We use :func:`~.pennylane.map` to map our ansatz over our list of observables,\nreturning a collection of QNodes, each one evaluating the expectation value\nof each Hamiltonian.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["qnodes = qml.map(StronglyEntanglingLayers, obs, device=non_analytic_dev, diff_method=\"parameter-shift\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now, let's set the total number of shots, and determine the probability\nfor sampling each Hamiltonian term.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["total_shots = 8000\nprob_shots = np.abs(coeffs) / np.sum(np.abs(coeffs))\nprint(prob_shots)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can now use SciPy to create our multinomial distributed random variable\n$S$, using the number of trials (total shot number) and probability values:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["from scipy.stats import multinomial\nsi = multinomial(n=total_shots, p=prob_shots)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Sampling from this distribution will provide the number of shots used to\nsample each term in the Hamiltonian:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["samples = si.rvs()[0]\nprint(samples)\nprint(sum(samples))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["As expected, if we sum the sampled shots per term, we recover the total number of shots.\n\nLet's now create our cost function. Recall that the cost function must do the\nfollowing:\n\n1. It must sample from the multinomial distribution we created above,\n   to determine the number of shots $s_i$ to use to estimate the expectation\n   value of the ith Hamiltonian term.\n\n2. It then must estimate the expectation value $\\langle h_i\\rangle$\n   by querying the required QNode.\n\n3. And, last but not least, estimate the expectation value\n   $\\langle H\\rangle = \\sum_i c_i\\langle h_i\\rangle$.\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def cost(params):\n    # sample from the multinomial distribution\n    shots_per_term = si.rvs()[0]\n\n    result = 0\n\n    for h, c, p, s in zip(qnodes, coeffs, prob_shots, shots_per_term):\n\n        # evaluate the QNode corresponding to\n        # the Hamiltonian term, and add it on to our running sum\n        result += c * h(params, shots=int(s))\n\n    return result"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Evaluating our cost function with some initial parameters, we can test out\nthat our cost function evaluates correctly.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["param_shape = StronglyEntanglingLayers.shape(n_layers=num_layers, n_wires=num_wires)\ninit_params = np.random.uniform(low=0.0, high=2*np.pi, size=param_shape, requires_grad=True)\nprint(cost(init_params))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Performing the optimization, with the number of shots randomly\ndetermined at each optimization step:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["opt = qml.AdamOptimizer(0.05)\nparams = init_params\n\ncost_wrs = []\nshots_wrs = []\n\nfor i in range(100):\n    params, _cost = opt.step_and_cost(cost, params)\n    cost_wrs.append(_cost)\n    shots_wrs.append(total_shots*i)\n    print(\"Step {}: cost = {} shots used = {}\".format(i, cost_wrs[-1], shots_wrs[-1]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's compare this against an optimization not using weighted random sampling.\nHere, we will split the 8000 total shots evenly across all Hamiltonian terms,\nalso known as *uniform deterministic sampling*.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["non_analytic_dev.shots = int(total_shots / len(coeffs))\n\nqnodes = qml.map(StronglyEntanglingLayers, obs, device=non_analytic_dev)\ncost = qml.dot(coeffs, qnodes)\n\nopt = qml.AdamOptimizer(0.05)\nparams = init_params\n\ncost_adam = []\nshots_adam = []\n\nfor i in range(100):\n    params, _cost = opt.step_and_cost(cost, params)\n    cost_adam.append(_cost)\n    shots_adam.append(total_shots*i)\n    print(\"Step {}: cost = {} shots used = {}\".format(i, cost_adam[-1], shots_adam[-1]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Comparing these two techniques:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["from matplotlib import pyplot as plt\n\nplt.style.use(\"seaborn\")\nplt.plot(shots_wrs, cost_wrs, \"b\", label=\"Adam WRS\")\nplt.plot(shots_adam, cost_adam, \"g\", label=\"Adam\")\n\nplt.ylabel(\"Cost function value\")\nplt.xlabel(\"Number of shots\")\nplt.legend()\nplt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can see that weighted random sampling performs just as well as the uniform\ndeterministic sampling. However, weighted random sampling begins to show a\nnon-negligible improvement over deterministic sampling for large Hamiltonians\nwith highly non-uniform coefficients. For example, see Fig (3) and (4) of\nArrasmith et al. [#arrasmith2020]_, comparing weighted random sampling VQE optimization\nfor both $\\text{H}_2$ and $\\text{LiH}$ molecules.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>While not covered here, another approach that could be taken is\n    *weighted deterministic sampling*. Here, the number of shots is distributed\n    across terms as per\n\n    .. math:: s_i = \\left\\lfloor N \\frac{|c_i|}{\\sum_i |c_i|}\\right\\rfloor,\n\n    where $N$ is the total number of shots.</p></div>\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Rosalin: Frugal shot optimization\n---------------------------------\n\nWe can see above that both methods optimize fairly well; weighted random\nsampling converges just as well as evenly distributing the shots across\nall Hamiltonian terms. However, deterministic shot distribution approaches\nwill always have a minimum shot value required per expectation value, as below\nthis threshold they become biased estimators. This is not the case with random\nsampling; as we saw in the\n:doc:`doubly stochastic gradient descent demonstration </demos/tutorial_doubly_stochastic>`,\nthe introduction of randomness allows for as little\nas a single shot per expectation term, while still remaining an unbiased estimator.\n\nUsing this insight, Arrasmith et al. [#arrasmith2020]_ modified the iCANS frugal\nshot-optimization technique [#kubler2020]_ to include weighted random sampling, making it\n'doubly stochastic'.\n\niCANS optimizer\n~~~~~~~~~~~~~~~\n\nTwo variants of the iCANS optimizer were introduced in K\u00fcbler et al., iCANS1 and iCANS2.\nThe iCANS1 optimizer, on which Rosalin is based, frugally distributes a shot budget\nacross the partial derivatives of each parameter, which are computed using the\n:doc:`parameter-shift rule </glossary/quantum_gradient>`. It works roughly as follows:\n\n1. The initial step of the optimizer is performed with some specified minimum\n   number of shots, $s_{min}$, for all partial derivatives.\n\n2. The parameter-shift rule is then used to estimate the gradient $g_i$\n   for each parameter $\\theta_i$, parameters, as well as the *variances*\n   $v_i$ of the estimated gradients.\n\n3. Gradient descent is performed for each parameter $\\theta_i$, using\n   the pre-defined learning rate $\\alpha$ and the gradient information $g_i$:\n\n   .. math:: \\theta_i = \\theta_i - \\alpha g_i.\n\n4. The improvement in the cost function per shot, for a specific parameter value,\n   is then calculated via\n\n   .. math::\n\n       \\gamma_i = \\frac{1}{s_i} \\left[ \\left(\\alpha - \\frac{1}{2} L\\alpha^2\\right)\n                   g_i^2 - \\frac{L\\alpha^2}{2s_i}v_i \\right],\n\n   where:\n\n   * $L \\leq \\sum_i|c_i|$ is the bound on the `Lipschitz constant\n     <https://en.wikipedia.org/wiki/Lipschitz_continuity>`__ of the variational quantum algorithm objective function,\n\n   * $c_i$ are the coefficients of the Hamiltonian, and\n\n   * $\\alpha$ is the learning rate, and *must* be bound such that $\\alpha < 2/L$\n     for the above expression to hold.\n\n5. Finally, the new values of $s_i$ (shots for partial derivative of parameter\n   $\\theta_i$) is given by:\n\n   .. math::\n\n       s_i = \\frac{2L\\alpha}{2-L\\alpha}\\left(\\frac{v_i}{g_i^2}\\right)\\propto\n             \\frac{v_i}{g_i^2}.\n\nIn addition to the above, to counteract the presence of noise in the system, a\nrunning average of $g_i$ and $s_i$ ($\\chi_i$ and $\\xi_i$ respectively)\nare used when computing $\\gamma_i$ and $s_i$.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In classical machine learning, the Lipschitz constant of the cost function is generally\n    unknown. However, for a variational quantum algorithm with cost of the form\n    $f(x) = \\langle \\psi(x) | \\hat{H} |\\psi(x)\\rangle$,\n    an upper bound on the Lipschitz constant is given by $L < \\sum_i|c_i|$,\n    where $c_i$ are the coefficients of $\\hat{H}$ when decomposed\n    into a linear combination of Pauli-operator tensor products.</p></div>\n\nRosalin implementation\n~~~~~~~~~~~~~~~~~~~~~~\n\nLet's now modify iCANS above to incorporate weighted random sampling of Hamiltonian\nterms --- the Rosalin frugal shot optimizer.\n\nRosalin takes several hyper-parameters:\n\n* ``min_shots``: the minimum number of shots used to estimate the expectations\n  of each term in the Hamiltonian. Note that this must be larger than 2 for the variance\n  of the gradients to be computed.\n\n* ``mu``: The running average constant $\\mu\\in[0, 1]$. Used to control how quickly the\n  number of shots recommended for each gradient component changes.\n\n* ``b``: Regularization bias. The bias should be kept small, but non-zero.\n\n* ``lr``: The learning rate. Recall from above that the learning rate *must* be such\n  that $\\alpha < 2/L = 2/\\sum_i|c_i|$.\n\nSince the Rosalin optimizer has a state that must be preserved between optimization steps,\nlet's use a class to create our optimizer.\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["class Rosalin:\n\n    def __init__(self, qnodes, coeffs, min_shots, mu=0.99, b=1e-6, lr=0.07):\n        self.qnodes = qnodes\n        self.coeffs = coeffs\n\n        self.lipschitz = np.sum(np.abs(coeffs))\n\n        if lr > 2 / self.lipschitz:\n            raise ValueError(\"The learning rate must be less than \", 2 / self.lipschitz)\n\n        # hyperparameters\n        self.min_shots = min_shots\n        self.mu = mu  # running average constant\n        self.b = b    # regularization bias\n        self.lr = lr  # learning rate\n\n        # keep track of the total number of shots used\n        self.shots_used = 0\n        # total number of iterations\n        self.k = 0\n        # Number of shots per parameter\n        self.s = np.zeros_like(params, dtype=np.float64) + min_shots\n\n        # Running average of the parameter gradients\n        self.chi = None\n        # Running average of the variance of the parameter gradients\n        self.xi = None\n\n    def estimate_hamiltonian(self, params, shots):\n        \"\"\"Returns an array containing length ``shots`` single-shot estimates\n        of the Hamiltonian. The shots are distributed randomly over\n        the terms in the Hamiltonian, as per a Multinomial distribution.\n\n        Since we are performing single-shot estimates, the QNodes must be\n        set to 'sample' mode.\n        \"\"\"\n\n        # determine the shot probability per term\n        prob_shots = np.abs(coeffs) / np.sum(np.abs(coeffs))\n\n        # construct the multinomial distribution, and sample\n        # from it to determine how many shots to apply per term\n        si = multinomial(n=shots, p=prob_shots)\n        shots_per_term = si.rvs()[0]\n\n        results = []\n        for h, c, p, s in zip(self.qnodes, self.coeffs, prob_shots, shots_per_term):\n\n            # if the number of shots is 0, do nothing\n            if s == 0:\n                continue\n\n            # evaluate the QNode corresponding to\n            # the Hamiltonian term\n            res = h(params, shots=int(s))\n\n            if s == 1:\n                res = np.array([res])\n\n            # Note that, unlike above, we divide each term by the\n            # probability per shot. This is because we are sampling one at a time.\n            results.append(c * res / p)\n\n        return np.concatenate(results)\n\n    def evaluate_grad_var(self, i, params, shots):\n        \"\"\"Evaluate the gradient, as well as the variance in the gradient,\n        for the ith parameter in params, using the parameter-shift rule.\n        \"\"\"\n        shift = np.zeros_like(params)\n        shift[i] = np.pi / 2\n\n        shift_forward = self.estimate_hamiltonian(params + shift, shots)\n        shift_backward = self.estimate_hamiltonian(params - shift, shots)\n\n        g = np.mean(shift_forward - shift_backward) / 2\n        s = np.var((shift_forward - shift_backward) / 2, ddof=1)\n\n        return g, s\n\n    def step(self, params):\n        \"\"\"Perform a single step of the Rosalin optimizer.\"\"\"\n        # keep track of the number of shots run\n        self.shots_used += int(2 * np.sum(self.s))\n\n        # compute the gradient, as well as the variance in the gradient,\n        # using the number of shots determined by the array s.\n        grad = []\n        S = []\n\n        p_ind = list(np.ndindex(*params.shape))\n\n        for l in p_ind:\n            # loop through each parameter, performing\n            # the parameter-shift rule\n            g_, s_ = self.evaluate_grad_var(l, params, self.s[l])\n            grad.append(g_)\n            S.append(s_)\n\n        grad = np.reshape(np.stack(grad), params.shape)\n        S = np.reshape(np.stack(S), params.shape)\n\n        # gradient descent update\n        params = params - self.lr * grad\n\n        if self.xi is None:\n            self.chi = np.zeros_like(params, dtype=np.float64)\n            self.xi = np.zeros_like(params, dtype=np.float64)\n\n        # running average of the gradient variance\n        self.xi = self.mu * self.xi + (1 - self.mu) * S\n        xi = self.xi / (1 - self.mu ** (self.k + 1))\n\n        # running average of the gradient\n        self.chi = self.mu * self.chi + (1 - self.mu) * grad\n        chi = self.chi / (1 - self.mu ** (self.k + 1))\n\n        # determine the new optimum shots distribution for the next\n        # iteration of the optimizer\n        s = np.ceil(\n            (2 * self.lipschitz * self.lr * xi)\n            / ((2 - self.lipschitz * self.lr) * (chi ** 2 + self.b * (self.mu ** self.k)))\n        )\n\n        # apply an upper and lower bound on the new shot distributions,\n        # to avoid the number of shots reducing below min(2, min_shots),\n        # or growing too significantly.\n        gamma = (\n            (self.lr - self.lipschitz * self.lr ** 2 / 2) * chi ** 2\n            - xi * self.lipschitz * self.lr ** 2 / (2 * s)\n        ) / s\n\n        argmax_gamma = np.unravel_index(np.argmax(gamma), gamma.shape)\n        smax = s[argmax_gamma]\n        self.s = np.clip(s, min(2, self.min_shots), smax)\n\n        self.k += 1\n        return params"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Rosalin optimization\n~~~~~~~~~~~~~~~~~~~~\n\nWe are now ready to use our Rosalin optimizer to optimize the initial VQE problem.\nNote that we create our QNodes using ``measure=\"sample\"``, since the Rosalin optimizer\nmust be able to generate single-shot samples from our device.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["rosalin_device = qml.device(\"default.qubit\", wires=num_wires, shots=100)\nqnodes = qml.map(StronglyEntanglingLayers, obs, device=rosalin_device, measure=\"sample\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's also create a separate cost function using an 'exact' quantum device, so that we can keep track of the\n*exact* cost function value at each iteration.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["cost_analytic = qml.dot(coeffs, qml.map(StronglyEntanglingLayers, obs, device=analytic_dev))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Creating the optimizer and beginning the optimization:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["opt = Rosalin(qnodes, coeffs, min_shots=10)\nparams = init_params\n\ncost_rosalin = [cost_analytic(params)]\nshots_rosalin = [0]\n\nfor i in range(60):\n    params = opt.step(params)\n    cost_rosalin.append(cost_analytic(params))\n    shots_rosalin.append(opt.shots_used)\n    print(f\"Step {i}: cost = {cost_rosalin[-1]}, shots_used = {shots_rosalin[-1]}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's compare this to a standard Adam optimization. Using 100 shots per quantum\nevaluation, for each update step there are 2 quantum evaluations per parameter.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["adam_shots_per_eval = 100\nadam_shots_per_step = 2 * adam_shots_per_eval * len(params.flatten())\nprint(adam_shots_per_step)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Thus, Adam is using 2400 shots per update step.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["params = init_params\nopt = qml.AdamOptimizer(0.07)\n\nnon_analytic_dev.shots = adam_shots_per_eval\ncost = qml.dot(\n  coeffs,\n  qml.map(StronglyEntanglingLayers, obs, device=non_analytic_dev, diff_method=\"parameter-shift\")\n)\n\ncost_adam = [cost_analytic(params)]\nshots_adam = [0]\n\nfor i in range(100):\n    params = opt.step(cost, params)\n    cost_adam.append(cost_analytic(params))\n    shots_adam.append(adam_shots_per_step * (i + 1))\n    print(\"Step {}: cost = {} shots_used = {}\".format(i, cost_adam[-1], shots_adam[-1]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plotting both experiments:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["plt.style.use(\"seaborn\")\nplt.plot(shots_rosalin, cost_rosalin, \"b\", label=\"Rosalin\")\nplt.plot(shots_adam, cost_adam, \"g\", label=\"Adam\")\n\nplt.ylabel(\"Cost function value\")\nplt.xlabel(\"Number of shots\")\nplt.legend()\nplt.xlim(0, 300000)\nplt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The Rosalin optimizer performs significantly better than the Adam optimizer,\napproaching the ground state energy of the Hamiltonian with strikingly\nfewer shots.\n\nWhile beyond the scope of this demonstration, the Rosalin optimizer can be\nmodified in various other ways; for instance, by incorporating *weighted hybrid\nsampling* (which distributes some shots deterministically, with the remainder\ndone randomly), or by adapting the variant iCANS2 optimizer. Download\nthis demonstration from the sidebar \ud83d\udc49 and give it a go! \u269b\ufe0f\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["References\n----------\n\n.. [#arrasmith2020]\n\n    Andrew Arrasmith, Lukasz Cincio, Rolando D. Somma, and Patrick J. Coles. \"Operator Sampling\n    for Shot-frugal Optimization in Variational Algorithms.\" `arXiv:2004.06252\n    <https://arxiv.org/abs/2004.06252>`__ (2020).\n\n.. [#stokes2019]\n\n    James Stokes, Josh Izaac, Nathan Killoran, and Giuseppe Carleo. \"Quantum Natural Gradient.\"\n    `arXiv:1909.02108 <https://arxiv.org/abs/1909.02108>`__ (2019).\n\n.. [#sweke2019]\n\n    Ryan Sweke, Frederik Wilde, Johannes Jakob Meyer, Maria Schuld, Paul K. F\u00e4hrmann, Barth\u00e9l\u00e9my\n    Meynard-Piganeau, and Jens Eisert. \"Stochastic gradient descent for hybrid quantum-classical\n    optimization.\" `arXiv:1910.01155 <https://arxiv.org/abs/1910.01155>`__ (2019).\n\n.. [#kubler2020]\n\n    Jonas M. K\u00fcbler, Andrew Arrasmith, Lukasz Cincio, and Patrick J. Coles. \"An Adaptive Optimizer\n    for Measurement-Frugal Variational Algorithms.\" `Quantum 4, 263\n    <https://quantum-journal.org/papers/q-2020-05-11-263/>`__ (2020).\n\n"]}]}