{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n# Ensemble classification with Forest and Qiskit devices\n\n.. meta::\n    :property=\"og:description\": We demonstrate how two QPUs can be\n        combined in parallel to help solve a machine learning classification problem,\n        using PyTorch and PennyLane.\n    :property=\"og:image\": https://pennylane.ai/qml/_images/ensemble_diagram.png\n\n.. related\n\n   tutorial_variational_classifier Variational quantum classifier\n\n*Author: PennyLane dev team. Last updated: 13 Dec 2021.*\n\nThis tutorial outlines how two QPUs can be combined in parallel to help solve a machine learning\nclassification problem.\n\nWe use the ``forest.qvm`` device to simulate one QPU and the ``qiskit.aer`` device to\nsimulate another. Each QPU makes an independent prediction, and an ensemble model is\nformed by choosing the prediction of the most confident QPU. The iris dataset is used in this\ntutorial, consisting of three classes of iris flower. Using a pre-trained model and the PyTorch\ninterface, we'll see that ensembling allows the QPUs to specialize towards\ndifferent classes.\n\nLet's begin by importing the prerequisite libraries:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["from collections import Counter\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pennylane as qml\nimport sklearn.datasets\nimport sklearn.decomposition\nimport torch\nfrom matplotlib.lines import Line2D\nfrom matplotlib.patches import Patch"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This tutorial requires the ``pennylane-forest`` and ``pennylane-qiskit`` packages, which can be\ninstalled by following the instructions `here <https://pennylane.ai/install.html>`__. We also\nmake use of the `PyTorch interface <https://pennylane.readthedocs.io/en/stable/introduction\n/interfaces.html>`_, which can be installed from `here\n<https://pytorch.org/get-started/locally/>`__.\n\n## Load data\n\nThe next step is to load the iris dataset.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["n_features = 2\nn_classes = 3\nn_samples = 150\n\ndata = sklearn.datasets.load_iris()\nx = data[\"data\"]\ny = data[\"target\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We shuffle the data and then embed the four features into a two-dimensional space for ease of\nplotting later on. The first two principal components of the data are used.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["np.random.seed(1967)\nx, y = zip(*np.random.permutation(list(zip(x, y))))\n\npca = sklearn.decomposition.PCA(n_components=n_features)\npca.fit(x)\nx = pca.transform(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We will be encoding these two features into quantum circuits using :class:`~.pennylane.RX`\nrotations, and hence renormalize our features to be between $[-\\pi, \\pi]$.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["x_min = np.min(x, axis=0)\nx_max = np.max(x, axis=0)\n\nx = 2 * np.pi * (x - x_min) / (x_max - x_min) - np.pi"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The data is split between a training and a test set. This tutorial uses a model that is\npre-trained on the training set.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["split = 125\n\nx_train = x[:split]\nx_test = x[split:]\ny_train = y[:split]\ny_test = y[split:]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Finally, let's take a quick look at our data:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["colours = [\"#ec6f86\", \"#4573e7\", \"#ad61ed\"]\n\n\ndef plot_points(x_train, y_train, x_test, y_test):\n    c_train = []\n    c_test = []\n\n    for y in y_train:\n        c_train.append(colours[y])\n\n    for y in y_test:\n        c_test.append(colours[y])\n\n    plt.scatter(x_train[:, 0], x_train[:, 1], c=c_train)\n    plt.scatter(x_test[:, 0], x_test[:, 1], c=c_test, marker=\"x\")\n\n    plt.xlabel(\"Feature 1\", fontsize=16)\n    plt.ylabel(\"Feature 2\", fontsize=16)\n\n    ax = plt.gca()\n    ax.set_aspect(1)\n\n    c_transparent = \"#00000000\"\n\n    custom_lines = [\n        Patch(facecolor=colours[0], edgecolor=c_transparent, label=\"Class 0\"),\n        Patch(facecolor=colours[1], edgecolor=c_transparent, label=\"Class 1\"),\n        Patch(facecolor=colours[2], edgecolor=c_transparent, label=\"Class 2\"),\n        Line2D([0], [0], marker=\"o\", color=c_transparent, label=\"Train\",\n               markerfacecolor=\"black\", markersize=10),\n        Line2D([0], [0], marker=\"x\", color=c_transparent, label=\"Test\",\n               markerfacecolor=\"black\", markersize=10),\n    ]\n\n    ax.legend(handles=custom_lines, bbox_to_anchor=(1.0, 0.75))\n\n\nplot_points(x_train, y_train, x_test, y_test)\nplt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. figure:: /demonstrations/ensemble_multi_qpu/ensemble_multi_qpu_001.png\n   :width: 80%\n   :align: center\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This plot shows us that class 0 points can be nicely separated, but that there is an overlap\nbetween points from classes 1 and 2.\n\n## Define model\n\nOur model is summarized in the figure below. We use two 4-qubit devices: ``4q-qvm``\nfrom the PennyLane-Forest plugin and ``qiskit.aer`` from the PennyLane-Qiskit plugin.\n\nData is input using :class:`~.pennylane.RX` rotations and then a different circuit is enacted\nfor each device with a unique set of trainable parameters. The output of both circuits is a\n:class:`~.pennylane.PauliZ` measurement on three of the qubits. This is then fed through a\nsoftmax function, resulting in two 3-dimensional probability vectors corresponding to the 3\nclasses.\n\nFinally, the ensemble model chooses the QPU which is most confident about its prediction\n(i.e., the class with the highest overall probability over all QPUs) and uses that to make a\nprediction.\n\n.. figure:: /demonstrations/ensemble_multi_qpu/ensemble_diagram.png\n   :width: 80%\n   :align: center\n\n### Quantum nodes\n\nWe begin by defining the two quantum devices and the circuits to be run on them.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["n_wires = 4\n\ndev0 = qml.device(\"forest.qvm\", device=\"4q-qvm\")\ndev1 = qml.device(\"qiskit.aer\", wires=4)\ndevs = [dev0, dev1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-info\"><h4>Note</h4><p>If you have access to Rigetti hardware, you can swap out ``forest.qvm`` for ``forest.qpu``\n   and specify the hardware device to run on. Users with access to the IBM Q Experience can\n   swap ``qiskit.aer`` for ``qiskit.ibmq`` and specify their chosen backend (see `here\n   <https://pennylane-qiskit.readthedocs.io/en/latest/gettingstarted.html#ibm-q-experience>`__).</p></div>\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>Rigetti's QVM and Quil Compiler services must be running for this tutorial to execute. They\n   can be installed by consulting the `Rigetti documentation\n   <http://docs.rigetti.com/qcs/>`__ or, for users with Docker, by running:\n\n   .. code-block:: bash\n\n       docker run -d -p 5555:5555 rigetti/quilc -R -p 5555\n       docker run -d -p 5000:5000 rigetti/qvm -S -p 5000</p></div>\n\nThe circuits for both QPUs are shown in the figure below:\n\n.. figure:: /demonstrations/ensemble_multi_qpu/diagram_circuits.png\n   :width: 80%\n   :align: center\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def circuit0(params, x=None):\n    for i in range(n_wires):\n        qml.RX(x[i % n_features], wires=i)\n        qml.Rot(*params[1, 0, i], wires=i)\n\n    qml.CZ(wires=[1, 0])\n    qml.CZ(wires=[1, 2])\n    qml.CZ(wires=[3, 0])\n\n    for i in range(n_wires):\n        qml.Rot(*params[1, 1, i], wires=i)\n    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2))\n\n\ndef circuit1(params, x=None):\n    for i in range(n_wires):\n        qml.RX(x[i % n_features], wires=i)\n        qml.Rot(*params[0, 0, i], wires=i)\n\n    qml.CZ(wires=[0, 1])\n    qml.CZ(wires=[1, 2])\n    qml.CZ(wires=[1, 3])\n\n    for i in range(n_wires):\n        qml.Rot(*params[0, 1, i], wires=i)\n    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We finally combine the two devices into a :class:`~.pennylane.QNodeCollection` that uses the\nPyTorch interface:\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["qnodes = qml.QNodeCollection(\n    [qml.QNode(circuit0, dev0, interface=\"torch\"),\n     qml.QNode(circuit1, dev1, interface=\"torch\")]\n)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Postprocessing into a prediction\n\nThe ``predict_point`` function below allows us to find the ensemble prediction, as well as keeping\ntrack of the individual predictions from each QPU.\n\nWe include a ``parallel`` keyword argument for evaluating the :class:`~.pennylane.QNodeCollection`\nin a parallel asynchronous manner. This feature requires the ``dask`` library, which can be\ninstalled using ``pip install \"dask[delayed]\"``. When ``parallel=True``, we are able to make\npredictions faster because we do not need to wait for one QPU to output before running on the\nother.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def decision(softmax):\n    return int(torch.argmax(softmax))\n\n\ndef predict_point(params, x_point=None, parallel=True):\n    results = qnodes(params, x=x_point, parallel=parallel)\n    softmax = torch.nn.functional.softmax(results, dim=1)\n    choice = torch.where(softmax == torch.max(softmax))[0][0]\n    chosen_softmax = softmax[choice]\n    return decision(chosen_softmax), decision(softmax[0]), decision(softmax[1]), int(choice)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Next, let's define a function to make a predictions over multiple data points.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def predict(params, x=None, parallel=True):\n    predictions_ensemble = []\n    predictions_0 = []\n    predictions_1 = []\n    choices = []\n\n    for i, x_point in enumerate(x):\n        if i % 10 == 0 and i > 0:\n            print(\"Completed up to iteration {}\".format(i))\n        results = predict_point(params, x_point=x_point, parallel=parallel)\n        predictions_ensemble.append(results[0])\n        predictions_0.append(results[1])\n        predictions_1.append(results[2])\n        choices.append(results[3])\n\n    return predictions_ensemble, predictions_0, predictions_1, choices"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Make predictions\n\nTo test our model, we first load a pre-trained set of parameters which can also be downloaded\nby clicking :download:`here <../demonstrations/ensemble_multi_qpu/params.npy>`.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["params = np.load(\"ensemble_multi_qpu/params.npy\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can then make predictions for the training and test datasets.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["print(\"Predicting on training dataset\")\np_train, p_train_0, p_train_1, choices_train = predict(params, x=x_train)\nprint(\"Predicting on test dataset\")\np_test, p_test_0, p_test_1, choices_test = predict(params, x=x_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. rst-class:: sphx-glr-script-out\n\n Out:\n\n .. code-block:: none\n\n   Predicting on training dataset\n   Completed up to iteration 10\n   Completed up to iteration 20\n   Completed up to iteration 30\n   Completed up to iteration 40\n   Completed up to iteration 50\n   Completed up to iteration 60\n   Completed up to iteration 70\n   Completed up to iteration 80\n   Completed up to iteration 90\n   Completed up to iteration 100\n   Completed up to iteration 110\n   Completed up to iteration 120\n   Predicting on test dataset\n   Completed up to iteration 10\n   Completed up to iteration 20\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Analyze performance\n\nThe last thing to do is test how well the model performs. We begin by looking at the accuracy.\n\n### Accuracy\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def accuracy(predictions, actuals):\n    count = 0\n\n    for i in range(len(predictions)):\n        if predictions[i] == actuals[i]:\n            count += 1\n\n    accuracy = count / (len(predictions))\n    return accuracy"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["print(\"Training accuracy (ensemble): {}\".format(accuracy(p_train, y_train)))\nprint(\"Training accuracy (QPU0):  {}\".format(accuracy(p_train_0, y_train)))\nprint(\"Training accuracy (QPU1):  {}\".format(accuracy(p_train_1, y_train)))"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. rst-class:: sphx-glr-script-out\n\n Out:\n\n .. code-block:: none\n\n   Training accuracy (ensemble): 0.824\n   Training accuracy (QPU0):  0.648\n   Training accuracy (QPU1):  0.28\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["print(\"Test accuracy (ensemble): {}\".format(accuracy(p_test, y_test)))\nprint(\"Test accuracy (QPU0):  {}\".format(accuracy(p_test_0, y_test)))\nprint(\"Test accuracy (QPU1):  {}\".format(accuracy(p_test_1, y_test)))"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. rst-class:: sphx-glr-script-out\n\n Out:\n\n .. code-block:: none\n\n   Test accuracy (ensemble): 0.72\n   Test accuracy (QPU0):  0.56\n   Test accuracy (QPU1):  0.24\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["These numbers tell us a few things:\n\n- On both training and test datasets, the ensemble model outperforms the predictions from each\n  QPU. This provides a nice example of how QPUs can be used in parallel to gain a performance\n  advantage.\n\n- The accuracy of QPU0 is much higher than the accuracy of QPU1. This does not mean that one\n  device is intrinsically better than the other. In fact, another set of parameters can lead to\n  QPU1 becoming more accurate. We will see in the next section that the difference in accuracy\n  is due to specialization of each QPU, which leads to overall better performance of the\n  ensemble model.\n\n- The test accuracy is lower than the training accuracy. Here our focus is on analyzing the\n  performance of the ensemble model, rather than minimizing the generalization error.\n\n### Choice of QPU\n\nIs there a link between the class of a datapoint and the QPU chosen to make the prediction in\nthe ensemble model? Let's investigate.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# Combine choices_train and choices_test to simplify analysis\nchoices = np.append(choices_train, choices_test)\nprint(\"Choices: {}\".format(choices))\nprint(\"Choices counts: {}\".format(Counter(choices)))"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. rst-class:: sphx-glr-script-out\n\n Out:\n\n .. code-block:: none\n\n   Choices: [0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0\n    0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0\n    0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n    1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0\n    0 0]\n   Choices counts: Counter({0: 110, 1: 40})\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The following lines keep track of choices and corresponding predictions in the ensemble model.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["predictions = np.append(p_train, p_test)\nchoice_vs_prediction = np.array([(choices[i], predictions[i]) for i in range(n_samples)])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can hence find the predictions each QPU was responsible for.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["choices_vs_prediction_0 = choice_vs_prediction[choice_vs_prediction[:, 0] == 0]\nchoices_vs_prediction_1 = choice_vs_prediction[choice_vs_prediction[:, 0] == 1]\npredictions_0 = choices_vs_prediction_0[:, 1]\npredictions_1 = choices_vs_prediction_1[:, 1]\n\n\nexpl = \"When QPU{} was chosen by the ensemble, it made the following distribution of \" \\\n       \"predictions:\\n{}\"\nprint(expl.format(\"0\", Counter(predictions_0)))\nprint(\"\\n\" + expl.format(\"1\", Counter(predictions_1)))\nprint(\"\\nDistribution of classes in iris dataset: {}\".format(Counter(y)))"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. rst-class:: sphx-glr-script-out\n\n Out:\n\n .. code-block:: none\n\n   When QPU0 was chosen by the ensemble, it made the following distribution of predictions:\n   Counter({0: 55, 2: 55})\n\n   When QPU1 was chosen by the ensemble, it made the following distribution of predictions:\n   Counter({1: 37, 0: 3})\n\n   Distribution of classes in iris dataset: Counter({0: 50, 2: 50, 1: 50})\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["These results show us that QPU0 specializes to making predictions on classes 0 and 2,\nwhile QPU1 specializes to class 1.\n\n### Visualization\n\nWe conclude by visualizing the correct and incorrect predictions on the dataset. The following\nfunction plots correctly predicted points in green and incorrectly predicted points in red.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["colours_prediction = {\"correct\": \"#83b5b9\", \"incorrect\": \"#f98d91\"}\nmarkers = [\"o\", \"v\", \"d\"]\n\n\ndef plot_points_prediction(x, y, p, title):\n    c = {0: [], 1: [], 2: []}\n    x_ = {0: [], 1: [], 2: []}\n\n    for i in range(n_samples):\n        x_[y[i]].append(x[i])\n        if p[i] == y[i]:\n            c[y[i]].append(colours_prediction[\"correct\"])\n        else:\n            c[y[i]].append(colours_prediction[\"incorrect\"])\n\n    for i in range(n_classes):\n        x_class = np.array(x_[i])\n        plt.scatter(x_class[:, 0], x_class[:, 1], c=c[i], marker=markers[i])\n\n    plt.xlabel(\"Feature 1\", fontsize=16)\n    plt.ylabel(\"Feature 2\", fontsize=16)\n    plt.title(\"Predictions from {} model\".format(title))\n\n    ax = plt.gca()\n    ax.set_aspect(1)\n\n    c_transparent = \"#00000000\"\n\n    custom_lines = [\n        Patch(\n            facecolor=colours_prediction[\"correct\"],\n            edgecolor=c_transparent, label=\"Correct\"\n        ),\n        Patch(\n            facecolor=colours_prediction[\"incorrect\"],\n            edgecolor=c_transparent, label=\"Incorrect\"\n        ),\n        Line2D([0], [0], marker=markers[0], color=c_transparent, label=\"Class 0\",\n               markerfacecolor=\"black\", markersize=10),\n        Line2D([0], [0], marker=markers[1], color=c_transparent, label=\"Class 1\",\n               markerfacecolor=\"black\", markersize=10),\n        Line2D([0], [0], marker=markers[2], color=c_transparent, label=\"Class 2\",\n               markerfacecolor=\"black\", markersize=10),\n    ]\n\n    ax.legend(handles=custom_lines, bbox_to_anchor=(1.0, 0.75))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can again compare the ensemble model with the individual models from each QPU.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["plot_points_prediction(x, y, predictions, \"ensemble\")  # ensemble\nplt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. figure:: /demonstrations/ensemble_multi_qpu/ensemble_multi_qpu_002.png\n   :width: 80%\n   :align: center\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["plot_points_prediction(x, y, np.append(p_train_0, p_test_0), \"QPU0\")  # QPU 0\nplt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. figure:: /demonstrations/ensemble_multi_qpu/ensemble_multi_qpu_003.png\n   :width: 80%\n   :align: center\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["plot_points_prediction(x, y, np.append(p_train_1, p_test_1), \"QPU1\")  # QPU 1\nplt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": [".. figure:: /demonstrations/ensemble_multi_qpu/ensemble_multi_qpu_004.png\n   :width: 80%\n   :align: center\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["These plots reinforce the specialization of the two QPUs. QPU1 concentrates on doing a good job\nat predicting class 1, while QPU0 is focused on classes 0 and 2. By combining together,\nthe resultant ensemble performs better.\n\nThis tutorial shows how QPUs can work in parallel to realize a performance advantage. Check out\nour :doc:`tutorial_vqe_parallel` tutorial to see how multiple QPUs can be\nevaluated asynchronously to speed up calculating the potential energy surface of molecular\nhydrogen!\n\n"]}], "metadata": {"kernelspec": {"display_name": "PennyLane", "language": "python", "name": "pennylane"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.10"}}, "nbformat": 4, "nbformat_minor": 0}