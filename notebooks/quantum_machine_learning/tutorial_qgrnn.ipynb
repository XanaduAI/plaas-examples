{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nThe Quantum Graph Recurrent Neural Network\n===========================================\n\n.. meta::\n    :property=\"og:description\": Using a quantum graph recurrent neural network to learn quantum dynamics.\n    :property=\"og:image\": https://pennylane.ai/qml/_images/qgrnn_thumbnail.png\n\n*Author: Jack Ceroni. Posted: 27 July 2020. Last updated: 25 March 2021.*\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This demonstration investigates quantum graph\nrecurrent neural networks (QGRNN), which are the quantum analogue of a\nclassical graph recurrent neural network, and a subclass of the more\ngeneral quantum graph\nneural network ansatz. Both the QGNN and QGRNN were introduced in\n`this paper (2019) <https://arxiv.org/abs/1909.12264>`__.\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The Idea\n--------\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A graph is defined as a set of *nodes* along with a set of\n**edges**, which represent connections between nodes.\nInformation can be encoded into graphs by assigning numbers\nto nodes and edges, which we call **weights**.\nIt is usually convenient to think of a graph visually:\n\n![](https://pennylane.ai/qml/_images/graph.png)\n\n    :width: 70%\n    :align: center\n\nIn recent years, the concept of a\n`graph neural network <https://arxiv.org/abs/1812.08434>`__ (GNN) has been\nreceiving a lot of attention from the machine learning community.\nA GNN seeks\nto learn a representation (a mapping of data into a\nlow-dimensional vector space) of a given graph with feature vectors assigned\nto nodes and edges. Each of the vectors in the learned\nrepresentation preserves not only the features, but also the overall\ntopology of the graph, i.e., which nodes are connected by edges. The\nquantum graph neural network attempts to do something similar, but for\nfeatures that are quantum-mechanical; for instance, a\ncollection of quantum states.\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Consider the class of qubit Hamiltonians that are *quadratic*, meaning that\nthe terms of the Hamiltonian represent either interactions between two\nqubits, or the energy of individual qubits.\nThis class of Hamiltonians is naturally described by graphs, with\nsecond-order terms between qubits corresponding to weighted edges between\nnodes, and first-order terms corresponding to node weights.\n\nA well known example of a quadratic Hamiltonian is the transverse-field\nIsing model, which is defined as\n\n\\begin{align}\\hat{H}_{\\text{Ising}}(\\boldsymbol\\theta) \\ = \\ \\displaystyle\\sum_{(i, j) \\in E}\n    \\theta_{ij}^{(1)} Z_{i} Z_{j} \\ + \\ \\displaystyle\\sum_{i} \\theta_{i}^{(2)} Z_{i} \\ + \\\n    \\displaystyle\\sum_{i} X_{i},\\end{align}\n\nwhere $\\boldsymbol\\theta \\ = \\ \\{\\theta^{(1)}, \\ \\theta^{(2)}\\}$.\nIn this Hamiltonian, the set $E$ that determines which pairs of qubits\nhave $ZZ$ interactions can be represented by the set of edges for some graph. With\nthe qubits as nodes, this graph is called the *interaction graph*.\nThe $\\theta^{(1)}$ parameters correspond to the edge weights and\nthe $\\theta^{(2)}$\nparameters correspond to weights on the nodes.\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This result implies that we can think about *quantum circuits* with\ngraph-theoretic properties. Recall that the time-evolution operator\nwith respect to some Hamiltonian $H$ is defined as:\n\n\\begin{align}U \\ = \\ e^{-it H}.\\end{align}\n\nThus, we have a clean way of taking quadratic Hamiltonians and turning\nthem into unitaries (quantum circuits) that preserve the same correspondance to a graph.\nIn the case of the Ising Hamiltonian, we have:\n\n\\begin{align}U_{\\text{Ising}} \\ = \\ e^{-it \\hat{H}_{\\text{Ising}} (\\boldsymbol\\theta)} \\ = \\ \\exp \\Big[ -it\n    \\Big( \\displaystyle\\sum_{(i, j) \\in E} \\theta_{ij}^{(1)} Z_{i} Z_{j} \\ + \\\n    \\displaystyle\\sum_{i} \\theta_{i}^{(2)} Z_{i} \\ + \\ \\displaystyle\\sum_{i} X_{i} \\Big) \\Big]\\end{align}\n\nIn general, this kind of unitary is very difficult to implement on a quantum computer.\nHowever, we can approximate it using the `Trotter-Suzuki decomposition\n<https://en.wikipedia.org/wiki/Time-evolving_block_decimation#The_Suzuki-Trotter_expansion>`__:\n\n\\begin{align}\\exp \\Big[ -it \\Big( \\displaystyle\\sum_{(i, j) \\in E} \\theta_{ij}^{(1)} Z_{i} Z_{j} \\ + \\\n    \\displaystyle\\sum_{i} \\theta_{i}^{(2)} Z_{i} \\ + \\ \\displaystyle\\sum_{i} X_{i} \\Big) \\Big]\n    \\ \\approx \\ \\displaystyle\\prod_{k \\ = \\ 1}^{t / \\Delta} \\Bigg[ \\displaystyle\\prod_{j \\ = \\\n    1}^{Q} e^{-i \\Delta \\hat{H}_{\\text{Ising}}^{j}(\\boldsymbol\\theta)} \\Bigg]\\end{align}\n\nwhere $\\hat{H}_{\\text{Ising}}^{j}(\\boldsymbol\\theta)$ is the $j$-th term of the\nIsing Hamiltonian and $\\Delta$ is some small number.\n\nThis circuit is a specific instance of the **Quantum Graph\nRecurrent Neural Network**, which in general is defined as a variational ansatz of\nthe form\n\n\\begin{align}U_{H}(\\boldsymbol\\mu, \\ \\boldsymbol\\gamma) \\ = \\ \\displaystyle\\prod_{i \\ = \\ 1}^{P} \\Bigg[\n    \\displaystyle\\prod_{j \\ = \\ 1}^{Q} e^{-i \\gamma_j H^{j}(\\boldsymbol\\mu)} \\Bigg],\\end{align}\n\nfor some parametrized quadratic Hamiltonian, $H(\\boldsymbol\\mu)$.\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Using the QGRNN\n^^^^^^^^^^^^^^^^\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Since the QGRNN ansatz is equivalent to the\napproximate time evolution of some quadratic Hamiltonian, we can use it\nto learn the dynamics of a quantum system.\n\nContinuing with the Ising model example, let's imagine we have some system\ngoverned by $\\hat{H}_{\\text{Ising}}(\\boldsymbol\\alpha)$ for an unknown set of\ntarget parameters,\n$\\boldsymbol\\alpha$ and an unknown interaction graph $G$. Let's also\nsuppose we have access to copies of some\nlow-energy, non-ground state of the target Hamiltonian, $|\\psi_0\\rangle$. In addition,\nwe have access to a collection of time-evolved states,\n$\\{ |\\psi(t_1)\\rangle, \\ |\\psi(t_2)\\rangle, \\ ..., \\ |\\psi(t_N)\\rangle \\}$, defined by:\n\n\\begin{align}|\\psi(t_k)\\rangle \\ = \\ e^{-i t_k \\hat{H}_{\\text{Ising}}(\\boldsymbol\\alpha)} |\\psi_0\\rangle.\\end{align}\n\nWe call the low-energy states and the collection of time-evolved states *quantum data*.\nFrom here, we randomly pick a number of time-evolved states\nfrom our collection. For any state that we choose, which is\nevolved to some time $t_k$, we compare it\nto\n\n\\begin{align}U_{\\hat{H}_{\\text{Ising}}}(\\boldsymbol\\mu, \\ \\Delta) |\\psi_0\\rangle \\ \\approx \\ e^{-i t_k\n    \\hat{H}_{\\text{Ising}}(\\boldsymbol\\mu)} |\\psi_0\\rangle.\\end{align}\n\nThis is done by feeding one of the copies of $|\\psi_0\\rangle$ into a quantum circuit\nwith the QGRNN ansatz, with some guessed set of parameters $\\boldsymbol\\mu$\nand a guessed interaction graph, $G'$.\nWe then use a classical optimizer to maximize the average\n\"similarity\" between the time-evolved states and the states prepared\nwith the QGRNN.\n\nAs the QGRNN states becomes more similar to\neach time-evolved state for each sampled time, it follows that\n$\\boldsymbol\\mu \\ \\rightarrow \\ \\boldsymbol\\alpha$\nand we are able to learn the unknown parameters of the Hamiltonian.\n\n.. figure:: ../demonstrations/qgrnn/qgrnn3.png\n    :width: 90%\n    :align: center\n\n    A visual representation of one execution of the QGRNN for one piece of quantum data.\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Learning an Ising Model with the QGRNN\n---------------------------------------\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We now attempt to use the QGRNN to learn the parameters corresponding\nto an arbitrary transverse-field Ising model Hamiltonian.\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Getting Started\n^^^^^^^^^^^^^^^^\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We begin by importing the necessary dependencies:\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["import pennylane as qml\nfrom matplotlib import pyplot as plt\nfrom pennylane import numpy as np\nimport scipy\nimport networkx as nx\nimport copy"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We also define some fixed values that are used throughout\nthe simulation.\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["qubit_number = 4\nqubits = range(qubit_number)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In this\nsimulation, we don't have quantum data readily available to pass into\nthe QGRNN, so we have to generate it ourselves. To do this, we must\nhave knowledge of the target interaction graph and the target Hamiltonian.\n\nLet us use the following cyclic graph as the target interaction graph\nof the Ising Hamiltonian:\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["ising_graph = nx.cycle_graph(qubit_number)\n\nprint(f\"Edges: {ising_graph.edges}\")\nnx.draw(ising_graph)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can then initialize the \u201cunknown\u201d target parameters that describe the\ntarget Hamiltonian, $\\boldsymbol\\alpha \\ = \\ \\{\\alpha^{(1)}, \\ \\alpha^{(2)}\\}$.\nRecall from the introduction that we have defined our parametrized\nIsing Hamiltonian to be of the form:\n\n\\begin{align}\\hat{H}_{\\text{Ising}}(\\boldsymbol\\theta) \\ = \\ \\displaystyle\\sum_{(i, j) \\in E}\n    \\theta_{ij}^{(1)} Z_{i} Z_{j} \\ + \\ \\displaystyle\\sum_{i} \\theta_{i}^{(2)} Z_{i} \\ + \\\n    \\displaystyle\\sum_{i} X_{i},\\end{align}\n\nwhere $E$ is the set of edges in the interaction graph, and\n$X_i$ and $Z_i$ are the Pauli-X and Pauli-Z on the\n$i$-th qubit.\n\nFor this tutorial, we choose the target parameters by sampling from\na uniform probability distribution ranging from $-2$ to $2$, with\ntwo-decimal precision.\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["target_weights = [0.56, 1.24, 1.67, -0.79]\ntarget_bias = [-1.44, -1.43, 1.18, -0.93]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In theory, these parameters can\nbe any value we want, provided they are reasonably small enough that the QGRNN can reach them\nin a tractable number of optimization steps.\nIn ``matrix_params``, the first list represents the $ZZ$ interaction parameters and\nthe second list represents the single-qubit $Z$ parameters.\n\nFinally,\nwe use this information to generate the matrix form of the\nIsing model Hamiltonian in the computational basis:\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def create_hamiltonian_matrix(n_qubits, graph, weights, bias):\n\n    full_matrix = np.zeros((2 ** n_qubits, 2 ** n_qubits))\n\n    # Creates the interaction component of the Hamiltonian\n    for i, edge in enumerate(graph.edges):\n        interaction_term = 1\n        for qubit in range(0, n_qubits):\n            if qubit in edge:\n                interaction_term = np.kron(interaction_term, qml.matrix(qml.PauliZ)(0))\n            else:\n                interaction_term = np.kron(interaction_term, np.identity(2))\n        full_matrix += weights[i] * interaction_term\n\n    # Creates the bias components of the matrix\n    for i in range(0, n_qubits):\n        z_term = x_term = 1\n        for j in range(0, n_qubits):\n            if j == i:\n                z_term = np.kron(z_term, qml.matrix(qml.PauliZ)(0))\n                x_term = np.kron(x_term, qml.matrix(qml.PauliX)(0))\n            else:\n                z_term = np.kron(z_term, np.identity(2))\n                x_term = np.kron(x_term, np.identity(2))\n        full_matrix += bias[i] * z_term + x_term\n\n    return full_matrix\n\n\n# Prints a visual representation of the Hamiltonian matrix\nham_matrix = create_hamiltonian_matrix(qubit_number, ising_graph, target_weights, target_bias)\nplt.matshow(ham_matrix, cmap=\"hot\")\nplt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Preparing Quantum Data\n^^^^^^^^^^^^^^^^^^^^^^\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The collection of quantum data needed to run the QGRNN has two components:\n(i) copies of a low-energy state, and (ii) a collection of time-evolved states, each of which are\nsimply the low-energy state evolved to different times.\nThe following is a low-energy state of the target Hamiltonian:\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["low_energy_state = [\n    (-0.054661080280306085 + 0.016713907320174026j),\n    (0.12290003656489545 - 0.03758500591109822j),\n    (0.3649337966440005 - 0.11158863596657455j),\n    (-0.8205175732627094 + 0.25093231967092877j),\n    (0.010369790825776609 - 0.0031706387262686003j),\n    (-0.02331544978544721 + 0.007129899300113728j),\n    (-0.06923183949694546 + 0.0211684344103713j),\n    (0.15566094863283836 - 0.04760201916285508j),\n    (0.014520590919500158 - 0.004441887836078486j),\n    (-0.032648113364535575 + 0.009988590222879195j),\n    (-0.09694382811137187 + 0.02965579457620536j),\n    (0.21796861485652747 - 0.06668776658411019j),\n    (-0.0027547112135013247 + 0.0008426289322652901j),\n    (0.006193695872468649 - 0.0018948418969390599j),\n    (0.018391279795405405 - 0.005625722994009138j),\n    (-0.041350974715649635 + 0.012650711602265649j),\n]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This state can be obtained by using a decoupled version of the\n:doc:`Variational Quantum Eigensolver </demos/tutorial_vqe>` algorithm (VQE).\nEssentially, we choose a\nVQE ansatz such that the circuit cannot learn the exact ground state,\nbut it can get fairly close. Another way to arrive at the same result is\nto perform VQE with a reasonable ansatz, but to terminate the algorithm\nbefore it converges to the ground state. If we used the exact ground state\n$|\\psi_0\\rangle$, the time-dependence would be trivial and the\ndata would not provide enough information about the Hamiltonian parameters.\n\nWe can verify that this is a low-energy\nstate by numerically finding the lowest eigenvalue of the Hamiltonian\nand comparing it to the energy expectation of this low-energy state:\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["res = np.vdot(low_energy_state, (ham_matrix @ low_energy_state))\nenergy_exp = np.real_if_close(res)\nprint(f\"Energy Expectation: {energy_exp}\")\n\n\nground_state_energy = np.real_if_close(min(np.linalg.eig(ham_matrix)[0]))\nprint(f\"Ground State Energy: {ground_state_energy}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We have in fact found a low-energy, non-ground state,\nas the energy expectation is slightly greater than the energy of the true ground\nstate. This, however, is only half of the information we need. We also require\na collection of time-evolved, low-energy states.\nEvolving the low-energy state forward in time is fairly straightforward: all we\nhave to do is multiply the initial state by a time-evolution unitary. This operation\ncan be defined as a custom gate in PennyLane:\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def state_evolve(hamiltonian, qubits, time):\n\n    U = scipy.linalg.expm(-1j * hamiltonian * time)\n    qml.QubitUnitary(U, wires=qubits)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We don't actually generate time-evolved quantum data quite yet,\nbut we now have all the pieces required for its preparation.\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Learning the Hamiltonian\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["With the quantum data defined, we are able to construct the QGRNN and\nlearn the target Hamiltonian.\nEach of the exponentiated\nHamiltonians in the QGRNN ansatz,\n$\\hat{H}^{j}_{\\text{Ising}}(\\boldsymbol\\mu)$, are the\n$ZZ$, $Z$, and $X$ terms from the Ising\nHamiltonian. This gives:\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def qgrnn_layer(weights, bias, qubits, graph, trotter_step):\n\n    # Applies a layer of RZZ gates (based on a graph)\n    for i, edge in enumerate(graph.edges):\n        qml.MultiRZ(2 * weights[i] * trotter_step, wires=(edge[0], edge[1]))\n\n    # Applies a layer of RZ gates\n    for i, qubit in enumerate(qubits):\n        qml.RZ(2 * bias[i] * trotter_step, wires=qubit)\n\n    # Applies a layer of RX gates\n    for qubit in qubits:\n        qml.RX(2 * trotter_step, wires=qubit)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["As was mentioned in the first section, the QGRNN has two\nregisters. In one register, some piece of quantum data\n$|\\psi(t)\\rangle$ is prepared and in the other we have\n$U_{H}(\\boldsymbol\\mu, \\ \\Delta) |\\psi_0\\rangle$. We need a\nway to measure the similarity between these states.\nThis can be done by using the fidelity, which is\nsimply the modulus squared of the inner product between the states,\n$| \\langle \\psi(t) | U_{H}(\\Delta, \\ \\boldsymbol\\mu) |\\psi_0\\rangle |^2$.\nTo calculate this value, we use a `SWAP\ntest <https://en.wikipedia.org/wiki/Swap_test>`__ between the registers:\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def swap_test(control, register1, register2):\n\n    qml.Hadamard(wires=control)\n    for reg1_qubit, reg2_qubit in zip(register1, register2):\n        qml.CSWAP(wires=(control, reg1_qubit, reg2_qubit))\n    qml.Hadamard(wires=control)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["After performing this procedure, the value returned from a measurement of the circuit is\n$\\langle Z \\rangle$, with respect to the ``control`` qubit.\nThe probability of measuring the $|0\\rangle$ state\nin this control qubit is related to both the fidelity\nbetween registers and $\\langle Z \\rangle$. Thus, with a bit of algebra,\nwe find that $\\langle Z \\rangle$ is equal to the fidelity.\n\nBefore creating the full QGRNN and the cost function, we\ndefine a few more fixed values. Among these is a \"guessed\"\ninteraction graph, which we set to be a\n`complete graph <https://en.wikipedia.org/wiki/Complete_graph>`__. This choice is\nmotivated by the fact that any target interaction graph will be a subgraph\nof this initial guess. Part of the idea behind the QGRNN is that\nwe don\u2019t know the interaction graph, and it has to be learned. In this case, the graph\nis learned *automatically* as the target parameters are optimized. The\n$\\boldsymbol\\mu$ parameters that correspond to edges that don't exist in\nthe target graph will simply approach $0$.\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# Defines some fixed values\n\nreg1 = tuple(range(qubit_number))  # First qubit register\nreg2 = tuple(range(qubit_number, 2 * qubit_number))  # Second qubit register\n\ncontrol = 2 * qubit_number  # Index of control qubit\ntrotter_step = 0.01  # Trotter step size\n\n# Defines the interaction graph for the new qubit system\n\nnew_ising_graph = nx.complete_graph(reg2)\n\nprint(f\"Edges: {new_ising_graph.edges}\")\nnx.draw(new_ising_graph)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["With this done, we implement the QGRNN circuit for some given time value:\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["def qgrnn(weights, bias, time=None):\n\n    # Prepares the low energy state in the two registers\n    qml.QubitStateVector(np.kron(low_energy_state, low_energy_state), wires=reg1 + reg2)\n\n    # Evolves the first qubit register with the time-evolution circuit to\n    # prepare a piece of quantum data\n    state_evolve(ham_matrix, reg1, time)\n\n    # Applies the QGRNN layers to the second qubit register\n    depth = time / trotter_step  # P = t/Delta\n    for _ in range(0, int(depth)):\n        qgrnn_layer(weights, bias, reg2, new_ising_graph, trotter_step)\n\n    # Applies the SWAP test between the registers\n    swap_test(control, reg1, reg2)\n\n    # Returns the results of the SWAP test\n    return qml.expval(qml.PauliZ(control))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We have the full QGRNN circuit, but we still need to define a cost function.\nWe know that\n$| \\langle \\psi(t) | U_{H}(\\boldsymbol\\mu, \\ \\Delta) |\\psi_0\\rangle |^2$\napproaches $1$ as the states become more similar and approaches\n$0$ as the states become orthogonal. Thus, we choose\nto minimize the quantity\n$-| \\langle \\psi(t) | U_{H}(\\boldsymbol\\mu, \\ \\Delta) |\\psi_0\\rangle |^2$.\nSince we are interested in calculating this value for many different\npieces of quantum data, the final cost function is the average\nnegative fidelity* between registers:\n\n\\begin{align}\\mathcal{L}(\\boldsymbol\\mu, \\ \\Delta) \\ = \\ - \\frac{1}{N} \\displaystyle\\sum_{i \\ = \\ 1}^{N} |\n    \\langle \\psi(t_i) | \\ U_{H}(\\boldsymbol\\mu, \\ \\Delta) \\ |\\psi_0\\rangle |^2,\\end{align}\n\nwhere we use $N$ pieces of quantum data.\n\nBefore creating the cost function, we must define a few more fixed\nvariables:\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["N = 15  # The number of pieces of quantum data that are used for each step\nmax_time = 0.1  # The maximum value of time that can be used for quantum data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We then define the negative fidelity cost function:\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["rng = np.random.default_rng(seed=42)\n\ndef cost_function(weight_params, bias_params):\n\n    # Randomly samples times at which the QGRNN runs\n    times_sampled = rng.random(size=N) * max_time\n\n    # Cycles through each of the sampled times and calculates the cost\n    total_cost = 0\n    for dt in times_sampled:\n        result = qgrnn_qnode(weight_params, bias_params, time=dt)\n        total_cost += -1 * result\n\n    return total_cost / N"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Next we set up for optimization.\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# Defines the new device\nqgrnn_dev = qml.device(\"default.qubit\", wires=2 * qubit_number + 1)\n\n# Defines the new QNode\nqgrnn_qnode = qml.QNode(qgrnn, qgrnn_dev)\n\nsteps = 300\n\noptimizer = qml.AdamOptimizer(stepsize=0.5)\n\nweights = rng.random(size=len(new_ising_graph.edges), requires_grad=True) - 0.5\nbias = rng.random(size=qubit_number, requires_grad=True) - 0.5\n\ninitial_weights = copy.copy(weights)\ninitial_bias = copy.copy(bias)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["All that remains is executing the optimization loop.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["for i in range(0, steps):\n    (weights, bias), cost = optimizer.step_and_cost(cost_function, weights, bias)\n\n    # Prints the value of the cost function\n    if i % 5 == 0:\n        print(f\"Cost at Step {i}: {cost}\")\n        print(f\"Weights at Step {i}: {weights}\")\n        print(f\"Bias at Step {i}: {bias}\")\n        print(\"---------------------------------------------\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["With the learned parameters, we construct a visual representation\nof the Hamiltonian to which they correspond and compare it to the\ntarget Hamiltonian, and the initial guessed Hamiltonian:\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["new_ham_matrix = create_hamiltonian_matrix(\n    qubit_number, nx.complete_graph(qubit_number), weights, bias\n)\n\ninit_ham = create_hamiltonian_matrix(\n    qubit_number, nx.complete_graph(qubit_number), initial_weights, initial_bias\n)\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(6, 6))\n\naxes[0].matshow(ham_matrix, vmin=-7, vmax=7, cmap=\"hot\")\naxes[0].set_title(\"Target\", y=1.13)\n\naxes[1].matshow(init_ham, vmin=-7, vmax=7, cmap=\"hot\")\naxes[1].set_title(\"Initial\", y=1.13)\n\naxes[2].matshow(new_ham_matrix, vmin=-7, vmax=7, cmap=\"hot\")\naxes[2].set_title(\"Learned\", y=1.13)\n\nplt.subplots_adjust(wspace=0.3, hspace=0.3)\nplt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["These images look very similar, indicating that the QGRNN has done a good job\nlearning the target Hamiltonian.\n\nWe can also look\nat the exact values of the target and learned parameters.\nRecall how the target\ninteraction graph has $4$ edges while the complete graph has $6$.\nThus, as the QGRNN converges to the optimal solution, the weights corresponding to\nedges $(1, 3)$ and $(2, 0)$ in the complete graph should go to $0$, as\nthis indicates that they have no effect, and effectively do not exist in the learned\nHamiltonian.\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["# We first pick out the weights of edges (1, 3) and (2, 0)\n# and then remove them from the list of target parameters\n\nweights_noedge = []\nweights_edge = []\nfor ii, edge in enumerate(new_ising_graph.edges):\n    if (edge[0] - qubit_number, edge[1] - qubit_number) in ising_graph.edges:\n        weights_edge.append(weights[ii])\n    else:\n        weights_noedge.append(weights[ii])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Then, we print all of the weights:\n\n\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": false}, "outputs": [], "source": ["print(\"Target parameters     Learned parameters\")\nprint(\"Weights\")\nprint(\"-\" * 41)\nfor ii_target, ii_learned in zip(target_weights, weights_edge):\n    print(f\"{ii_target : <20}|{ii_learned : >20}\")\n\nprint(\"\\nBias\")\nprint(\"-\"*41)\nfor ii_target, ii_learned in zip(target_bias, bias):\n    print(f\"{ii_target : <20}|{ii_learned : >20}\")\n\nprint(f\"\\nNon-Existing Edge Parameters: {[val.unwrap() for val in weights_noedge]}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The weights of edges $(1, 3)$ and $(2, 0)$\nare very close to $0$, indicating we have learned the cycle graph\nfrom the complete graph. In addition, the remaining learned weights\nare fairly close to those of the target Hamiltonian.\nThus, the QGRNN is functioning properly, and has learned the target\nIsing Hamiltonian to a high\ndegree of accuracy!\n\n\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["References\n----------\n\n1. Verdon, G., McCourt, T., Luzhnica, E., Singh, V., Leichenauer, S., &\n   Hidary, J. (2019). Quantum Graph Neural Networks. arXiv preprint\n   `arXiv:1909.12264 <https://arxiv.org/abs/1909.12264>`__.\n\n\n"]}]}